{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Fine-Tune LLMs with Together AI\n",
    "\n",
    "This notebook guides you through fine-tuning a Large Language Model using Together AI.\n",
    "\n",
    "**Why Together AI?**\n",
    "- Wide selection of open-source models (Llama, Mistral, Qwen, etc.)\n",
    "- Competitive pricing for fine-tuning\n",
    "- Good documentation and community\n",
    "- Serverless deployment after fine-tuning\n",
    "\n",
    "**What you'll learn:**\n",
    "1. Prepare and validate your training dataset\n",
    "2. Upload to Together AI\n",
    "3. Configure and launch fine-tuning\n",
    "4. Deploy and test your model\n",
    "\n",
    "**Prerequisites:**\n",
    "- Together AI account (https://together.ai)\n",
    "- API key from Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install together pandas jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import together\n",
    "from together import Together\n",
    "\n",
    "# Set your Together API key\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')\n",
    "except:\n",
    "    TOGETHER_API_KEY = input(\"Enter your Together API key: \")\n",
    "\n",
    "os.environ['TOGETHER_API_KEY'] = TOGETHER_API_KEY\n",
    "client = Together(api_key=TOGETHER_API_KEY)\n",
    "\n",
    "print(\"‚úÖ Together AI client configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Preparation\n",
    "\n",
    "Together AI expects data in **JSONL format** with conversation-style messages.\n",
    "\n",
    "### Format:\n",
    "```json\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "```\n",
    "\n",
    "### Dataset Requirements:\n",
    "- Minimum 10 examples (recommended: 50-1000+)\n",
    "- Each example should be a complete conversation\n",
    "- Consistent formatting across examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Sample Dataset: SQL Query Assistant\n",
    "# Replace with your own domain-specific data!\n",
    "# ============================================================\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert SQL assistant. You help users write efficient, correct SQL queries.\n",
    "When writing queries:\n",
    "- Use clear table aliases\n",
    "- Add comments explaining complex logic\n",
    "- Suggest indexes when relevant\n",
    "- Follow best practices for the specific database type\"\"\"\n",
    "\n",
    "sample_data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": \"Write a query to find the top 10 customers by total order value\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"\"\"Here's a query to find the top 10 customers by total order value:\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    c.customer_id,\n",
    "    c.customer_name,\n",
    "    c.email,\n",
    "    SUM(o.total_amount) AS total_order_value,\n",
    "    COUNT(o.order_id) AS order_count\n",
    "FROM customers c\n",
    "INNER JOIN orders o ON c.customer_id = o.customer_id\n",
    "WHERE o.status = 'completed'  -- Only count completed orders\n",
    "GROUP BY c.customer_id, c.customer_name, c.email\n",
    "ORDER BY total_order_value DESC\n",
    "LIMIT 10;\n",
    "```\n",
    "\n",
    "**Performance tip:** Ensure you have indexes on:\n",
    "- `orders.customer_id` (for the join)\n",
    "- `orders.status` (for filtering)\n",
    "\n",
    "Would you like me to modify this for a specific time period or add additional filters?\"\"\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": \"How do I find duplicate records in a table?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"\"\"Here are several approaches to find duplicate records:\n",
    "\n",
    "**Method 1: Using GROUP BY and HAVING**\n",
    "```sql\n",
    "-- Find duplicate emails\n",
    "SELECT email, COUNT(*) as duplicate_count\n",
    "FROM users\n",
    "GROUP BY email\n",
    "HAVING COUNT(*) > 1;\n",
    "```\n",
    "\n",
    "**Method 2: Get all rows with duplicates**\n",
    "```sql\n",
    "SELECT *\n",
    "FROM users u1\n",
    "WHERE EXISTS (\n",
    "    SELECT 1 FROM users u2\n",
    "    WHERE u2.email = u1.email\n",
    "    AND u2.id != u1.id\n",
    ");\n",
    "```\n",
    "\n",
    "**Method 3: Using window functions (keeps all columns)**\n",
    "```sql\n",
    "WITH duplicates AS (\n",
    "    SELECT *,\n",
    "           ROW_NUMBER() OVER (PARTITION BY email ORDER BY created_at) as rn\n",
    "    FROM users\n",
    ")\n",
    "SELECT * FROM duplicates WHERE rn > 1;  -- Shows duplicate rows\n",
    "```\n",
    "\n",
    "Which method works best depends on:\n",
    "- Whether you need to see all duplicate rows or just counts\n",
    "- Your database's support for window functions\n",
    "- Table size (window functions can be slower on large tables)\n",
    "\n",
    "What specific columns do you want to check for duplicates?\"\"\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": \"Explain the difference between INNER JOIN and LEFT JOIN\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"\"\"Great question! Here's a clear comparison:\n",
    "\n",
    "## INNER JOIN\n",
    "Returns only rows where there's a match in **both** tables.\n",
    "\n",
    "```sql\n",
    "SELECT c.name, o.order_id\n",
    "FROM customers c\n",
    "INNER JOIN orders o ON c.id = o.customer_id;\n",
    "-- Only returns customers WHO HAVE orders\n",
    "```\n",
    "\n",
    "## LEFT JOIN (or LEFT OUTER JOIN)\n",
    "Returns **all rows from the left table**, plus matches from the right table (NULL if no match).\n",
    "\n",
    "```sql\n",
    "SELECT c.name, o.order_id\n",
    "FROM customers c\n",
    "LEFT JOIN orders o ON c.id = o.customer_id;\n",
    "-- Returns ALL customers, even those without orders\n",
    "-- order_id will be NULL for customers with no orders\n",
    "```\n",
    "\n",
    "## Visual Example\n",
    "```\n",
    "Customers: [A, B, C]     Orders: [A has 2, B has 1]\n",
    "\n",
    "INNER JOIN result: A, A, B    (3 rows - only matching)\n",
    "LEFT JOIN result:  A, A, B, C (4 rows - C has NULL order_id)\n",
    "```\n",
    "\n",
    "## When to use which:\n",
    "- **INNER JOIN**: When you only want records that exist in both tables\n",
    "- **LEFT JOIN**: When you want all records from the main table, regardless of matches\n",
    "\n",
    "Need help deciding which to use for a specific query?\"\"\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìä Sample dataset with {len(sample_data)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Your Contribution: Define Training Examples\n",
    "\n",
    "**Why this matters:** The quality of your fine-tuned model depends entirely on your training data. You need to provide examples that represent:\n",
    "- The types of questions users will ask\n",
    "- The response style and format you want\n",
    "- Edge cases and tricky scenarios\n",
    "\n",
    "**Your task:** Add at least 10 more training examples below. Consider:\n",
    "- What domain expertise should the model have?\n",
    "- What's the ideal response length and format?\n",
    "- What common mistakes should it avoid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TODO: Add your training examples here\n",
    "# ============================================================\n",
    "\n",
    "def create_example(user_query: str, assistant_response: str) -> dict:\n",
    "    \"\"\"Helper to create a training example with consistent system prompt.\"\"\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_query},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_response}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Add your examples here:\n",
    "my_training_examples = [\n",
    "    # Example: Uncomment and modify\n",
    "    # create_example(\n",
    "    #     user_query=\"How do I optimize a slow query?\",\n",
    "    #     assistant_response=\"Here's how to optimize...\"\n",
    "    # ),\n",
    "]\n",
    "\n",
    "# Combine all data\n",
    "all_training_data = sample_data + my_training_examples\n",
    "print(f\"üìä Total training examples: {len(all_training_data)}\")\n",
    "\n",
    "if len(all_training_data) < 10:\n",
    "    print(\"‚ö†Ô∏è  Recommendation: Add more examples for better results (10+ minimum, 50+ recommended)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate dataset format\n",
    "\n",
    "def validate_dataset(data: list) -> bool:\n",
    "    \"\"\"Validate that dataset follows Together AI format requirements.\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    for i, example in enumerate(data):\n",
    "        if \"messages\" not in example:\n",
    "            errors.append(f\"Example {i}: Missing 'messages' key\")\n",
    "            continue\n",
    "            \n",
    "        messages = example[\"messages\"]\n",
    "        \n",
    "        if len(messages) < 2:\n",
    "            errors.append(f\"Example {i}: Need at least 2 messages (user + assistant)\")\n",
    "            \n",
    "        for j, msg in enumerate(messages):\n",
    "            if \"role\" not in msg:\n",
    "                errors.append(f\"Example {i}, message {j}: Missing 'role'\")\n",
    "            if \"content\" not in msg:\n",
    "                errors.append(f\"Example {i}, message {j}: Missing 'content'\")\n",
    "            if msg.get(\"role\") not in [\"system\", \"user\", \"assistant\"]:\n",
    "                errors.append(f\"Example {i}, message {j}: Invalid role '{msg.get('role')}'\")\n",
    "    \n",
    "    if errors:\n",
    "        print(\"‚ùå Validation errors:\")\n",
    "        for error in errors[:10]:  # Show first 10 errors\n",
    "            print(f\"   - {error}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"‚úÖ Dataset validation passed!\")\n",
    "        return True\n",
    "\n",
    "validate_dataset(all_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSONL file\n",
    "\n",
    "TRAIN_FILE = \"training_data.jsonl\"\n",
    "\n",
    "with open(TRAIN_FILE, 'w') as f:\n",
    "    for example in all_training_data:\n",
    "        f.write(json.dumps(example) + '\\n')\n",
    "\n",
    "print(f\"‚úÖ Saved {len(all_training_data)} examples to {TRAIN_FILE}\")\n",
    "\n",
    "# Show file size\n",
    "import os\n",
    "file_size = os.path.getsize(TRAIN_FILE)\n",
    "print(f\"   File size: {file_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload Dataset to Together AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training file\n",
    "\n",
    "print(\"üì§ Uploading dataset to Together AI...\")\n",
    "\n",
    "file_response = client.files.upload(\n",
    "    file=open(TRAIN_FILE, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "FILE_ID = file_response.id\n",
    "print(f\"‚úÖ Upload complete!\")\n",
    "print(f\"   File ID: {FILE_ID}\")\n",
    "print(f\"   Status: {file_response.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check file processing status\n",
    "\n",
    "import time\n",
    "\n",
    "def wait_for_file_processing(file_id: str, timeout: int = 300):\n",
    "    \"\"\"Wait for file to be processed.\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    while time.time() - start < timeout:\n",
    "        file_info = client.files.retrieve(file_id)\n",
    "        status = file_info.status\n",
    "        \n",
    "        print(f\"   Status: {status}\")\n",
    "        \n",
    "        if status == \"processed\":\n",
    "            print(\"‚úÖ File processed successfully!\")\n",
    "            return True\n",
    "        elif status == \"error\":\n",
    "            print(f\"‚ùå Processing error: {file_info.error}\")\n",
    "            return False\n",
    "            \n",
    "        time.sleep(5)\n",
    "    \n",
    "    print(\"‚è∞ Timeout waiting for file processing\")\n",
    "    return False\n",
    "\n",
    "wait_for_file_processing(FILE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start Fine-Tuning Job\n",
    "\n",
    "### Available Base Models on Together:\n",
    "\n",
    "| Model | Size | Best For | Cost |\n",
    "|-------|------|----------|------|\n",
    "| `meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo` | 8B | General, fast | $$ |\n",
    "| `meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo` | 70B | High quality | $$$$ |\n",
    "| `mistralai/Mistral-7B-Instruct-v0.3` | 7B | Good balance | $$ |\n",
    "| `Qwen/Qwen2.5-7B-Instruct-Turbo` | 7B | Multilingual | $$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Configure Fine-Tuning Job\n",
    "# ============================================================\n",
    "\n",
    "# Your model's name (will be used for deployment)\n",
    "MODEL_SUFFIX = \"sql-assistant-v1\"  # Change this!\n",
    "\n",
    "# Base model to fine-tune\n",
    "BASE_MODEL = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "\n",
    "# Training hyperparameters\n",
    "config = {\n",
    "    \"n_epochs\": 3,                    # Number of training epochs\n",
    "    \"learning_rate\": 1e-5,            # Learning rate\n",
    "    \"batch_size\": 4,                  # Batch size (adjust based on model size)\n",
    "    \"warmup_ratio\": 0.1,              # Warmup steps as ratio of total\n",
    "    \"n_checkpoints\": 1,               # Save checkpoints\n",
    "}\n",
    "\n",
    "print(\"üìã Fine-tuning configuration:\")\n",
    "print(f\"   Base model: {BASE_MODEL}\")\n",
    "print(f\"   Output suffix: {MODEL_SUFFIX}\")\n",
    "for k, v in config.items():\n",
    "    print(f\"   {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fine-tuning job\n",
    "\n",
    "print(\"üöÄ Starting fine-tuning job...\")\n",
    "\n",
    "job = client.fine_tuning.create(\n",
    "    model=BASE_MODEL,\n",
    "    training_file=FILE_ID,\n",
    "    suffix=MODEL_SUFFIX,\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": config[\"n_epochs\"],\n",
    "        \"learning_rate\": config[\"learning_rate\"],\n",
    "        \"batch_size\": config[\"batch_size\"],\n",
    "        \"warmup_ratio\": config[\"warmup_ratio\"],\n",
    "        \"n_checkpoints\": config[\"n_checkpoints\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "JOB_ID = job.id\n",
    "print(f\"‚úÖ Fine-tuning job created!\")\n",
    "print(f\"   Job ID: {JOB_ID}\")\n",
    "print(f\"   Status: {job.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Monitor Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_job_status(job_id: str):\n",
    "    \"\"\"Check fine-tuning job status.\"\"\"\n",
    "    job = client.fine_tuning.retrieve(job_id)\n",
    "    return job\n",
    "\n",
    "def monitor_job(job_id: str, poll_interval: int = 60):\n",
    "    \"\"\"Monitor job until completion.\"\"\"\n",
    "    print(f\"üìä Monitoring job {job_id}...\")\n",
    "    print(\"   (Fine-tuning typically takes 10-60 minutes)\\n\")\n",
    "    \n",
    "    while True:\n",
    "        job = check_job_status(job_id)\n",
    "        status = job.status\n",
    "        \n",
    "        print(f\"   [{time.strftime('%H:%M:%S')}] Status: {status}\")\n",
    "        \n",
    "        if hasattr(job, 'events') and job.events:\n",
    "            latest_event = job.events[-1]\n",
    "            print(f\"                  Event: {latest_event.message}\")\n",
    "        \n",
    "        if status == \"completed\":\n",
    "            print(f\"\\n‚úÖ Fine-tuning completed!\")\n",
    "            print(f\"   Model: {job.output_name}\")\n",
    "            return job\n",
    "        elif status in [\"failed\", \"cancelled\"]:\n",
    "            print(f\"\\n‚ùå Job {status}\")\n",
    "            if hasattr(job, 'error'):\n",
    "                print(f\"   Error: {job.error}\")\n",
    "            return job\n",
    "        \n",
    "        time.sleep(poll_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick status check\n",
    "job_status = check_job_status(JOB_ID)\n",
    "print(f\"Job ID: {JOB_ID}\")\n",
    "print(f\"Status: {job_status.status}\")\n",
    "if hasattr(job_status, 'output_name') and job_status.output_name:\n",
    "    print(f\"Model: {job_status.output_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor until completion (uncomment to run)\n",
    "# completed_job = monitor_job(JOB_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Your Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your fine-tuned model name\n",
    "job_info = check_job_status(JOB_ID)\n",
    "FINE_TUNED_MODEL = job_info.output_name if hasattr(job_info, 'output_name') else None\n",
    "\n",
    "if FINE_TUNED_MODEL:\n",
    "    print(f\"üéØ Fine-tuned model: {FINE_TUNED_MODEL}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Model not ready yet - check job status above\")\n",
    "    # You can manually set it if you know the name:\n",
    "    # FINE_TUNED_MODEL = \"your-username/Meta-Llama-3.1-8B-Instruct-Turbo-sql-assistant-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(model: str, user_message: str, system_prompt: str = None) -> str:\n",
    "    \"\"\"Send a message to a model and get the response.\"\"\"\n",
    "    messages = []\n",
    "    \n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=1024,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model\n",
    "\n",
    "test_queries = [\n",
    "    \"How do I write a query to get the average order value per month?\",\n",
    "    \"What's the difference between WHERE and HAVING?\",\n",
    "    \"Write a query to find users who haven't logged in for 30 days\"\n",
    "]\n",
    "\n",
    "if FINE_TUNED_MODEL:\n",
    "    print(\"üß™ Testing fine-tuned model\\n\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\nüë§ User: {query}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        response = chat(\n",
    "            model=FINE_TUNED_MODEL,\n",
    "            user_message=query,\n",
    "            system_prompt=SYSTEM_PROMPT\n",
    "        )\n",
    "        print(f\"ü§ñ Assistant:\\n{response}\")\n",
    "        print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please set FINE_TUNED_MODEL first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare Base vs Fine-Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(query: str):\n",
    "    \"\"\"Compare responses from base and fine-tuned models.\"\"\"\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\nüìå BASE MODEL:\")\n",
    "    print(\"-\" * 50)\n",
    "    base_response = chat(BASE_MODEL, query, SYSTEM_PROMPT)\n",
    "    print(base_response)\n",
    "    \n",
    "    if FINE_TUNED_MODEL:\n",
    "        print(f\"\\nüéØ FINE-TUNED MODEL:\")\n",
    "        print(\"-\" * 50)\n",
    "        ft_response = chat(FINE_TUNED_MODEL, query, SYSTEM_PROMPT)\n",
    "        print(ft_response)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Compare\n",
    "compare_models(\"Write a query to calculate customer lifetime value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Resources\n",
    "\n",
    "- [Together AI Documentation](https://docs.together.ai/)\n",
    "- [Fine-Tuning Guide](https://docs.together.ai/docs/fine-tuning)\n",
    "- [Model Catalog](https://together.ai/models)\n",
    "- [Pricing](https://together.ai/pricing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
