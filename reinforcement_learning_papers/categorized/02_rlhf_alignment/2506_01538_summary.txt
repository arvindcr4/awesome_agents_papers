Here is the extracted information:

**PAPER:** LAMARL: LLM-Aided Multi-Agent Reinforcement Learning for Cooperative Policy Generation

**TITLE:** LAMARL: LLM-Aided Multi-Agent Reinforcement Learning for Cooperative Policy Generation

**ARXIV_ID:** 2506.01538v2 [cs.RO]

**RESEARCH_METHOD:** 02_rlhf_alignment

**METHOD_DESCRIPTION:** This paper proposes a novel approach called LAMARL, which combines Large Language Models (LLMs) with Multi-Agent Reinforcement Learning (MARL) to achieve fully autonomous policy generation for multi-robot tasks. The LAMARL approach consists of two modules: the first module leverages LLMs to fully automate the generation of prior policy and reward functions, and the second module is MARL, which uses the generated functions to guide robot policy training effectively.

**KEY_CONTRIBUTIONS:**

* The authors propose a novel approach that integrates LLMs with MARL to achieve fully autonomous policy generation for multi-robot tasks.
* The LAMARL approach consists of two modules: LLM-aided function generation and MARL.
* The authors demonstrate the effectiveness of LAMARL through simulation and real-world experiments on a shape assembly task.
* The authors show that LAMARL achieves comparable performance to the state-of-the-art Mean-shift method without manual design or expert data.
* The authors highlight the importance of prior policies and structured prompts in achieving good performance with LAMARL.
