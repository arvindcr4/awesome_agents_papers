Here is the extracted information:

**PAPER:** Model-based Reinforcement Learning for Parameterized Action Spaces
**TITLE:** Model-based Reinforcement Learning for Parameterized Action Spaces
**RESEARCH_METHOD:** 07_model_based_rl
**METHOD_DESCRIPTION:** The paper proposes a novel model-based reinforcement learning algorithm, called Dynamics Learning and Predictive Control with Parameterized Actions (DLPA), for parameterized action Markov decision processes (PAMDPs). DLPA learns a parameterized-action-conditioned dynamics model and plans with a modified Model Predictive Path Integral control. The algorithm is designed to handle large action spaces and achieve better sample efficiency and asymptotic performance than state-of-the-art PAMDP methods.
**KEY_CONTRIBUTIONS:**
* Proposes a model-based RL algorithm for PAMDPs, which can handle large action spaces and achieve better sample efficiency and asymptotic performance.
* Introduces a novel planning method for parameterized actions, which keeps updating and sampling from the distribution over discrete actions and continuous parameters.
* Provides theoretical analysis and bounds for the performance of DLPA, including the regret of the rollout trajectory and the multi-step prediction error.
* Evaluates DLPA on 8 standard PAMDP benchmarks and achieves significantly better sample efficiency and asymptotic performance than state-of-the-art PAMDP algorithms.
* Conducts ablation studies to investigate the importance of different components of the algorithm, including the planning algorithm, inference models, and separate reward predictors.
