Here is the extracted information in the required format:

**PAPER:** Hierarchical Task Network Planning for Facilitating Cooperative Multi-Agent Reinforcement Learning
**TITLE:** Hierarchical Task Network Planning for Facilitating Cooperative Multi-Agent Reinforcement Learning
**ARXIV_ID:** 2306.08359v1
**RESEARCH_METHOD:** 02_rlhf_alignment
**METHOD_DESCRIPTION:** The paper proposes a framework called SOMARL, which combines Hierarchical Task Network (HTN) planning with multi-agent reinforcement learning (MARL) to facilitate cooperative learning in sparse reward environments with traps. The framework uses a tree structure to represent the symbolic knowledge of the environment and defines a set of symbolic options to guide the exploration of the agents. The HTN planner solves the planning problem, and the meta-controller selects the symbolic options to assign to the agents.
**KEY_CONTRIBUTIONS:**
* Proposes a novel framework that combines HTN planning with MARL for cooperative multi-agent sparse reward environments with traps.
* Defines a method for generating symbolic knowledge on the MARL environment using a tree structure.
* Introduces a set of symbolic options to guide the exploration of the agents and computes intrinsic rewards to constrain agent behavior.
* Evaluates the framework on two environments, FindTreasure and MoveBox, and shows its effectiveness in terms of performance, interpretability, and success rate stability.
