Here is the extracted information in the requested format:

**PAPER:** TTRL: Test-Time Reinforcement Learning
**TITLE:** Test-Time Reinforcement Learning
**RESEARCH_METHOD:** 02_rlhf_alignment
**METHOD_DESCRIPTION:** Test-Time Reinforcement Learning (TTRL) is a novel method for training large language models using reinforcement learning on unlabeled data. TTRL combines test-time scaling and test-time training, utilizing majority voting to estimate labels and compute rule-based rewards. The approach enables self-improvement of language models during inference, without requiring ground-truth labels.
**KEY_CONTRIBUTIONS:**
* TTRL achieves consistent improvements across various models and tasks, demonstrating its potential for self-supervised learning.
* The approach surpasses the traditional self-training upper bound and approaches the performance of direct training on test data with ground-truth labels.
* TTRL is compatible with different reinforcement learning algorithms and can be applied to various models, including large language models.
* The method exhibits a high-performance ceiling and can be used for lifelong learning on large-scale datasets.
