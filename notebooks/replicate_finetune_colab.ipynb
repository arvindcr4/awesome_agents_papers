{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîÑ Fine-Tune LLMs with Replicate\n",
    "\n",
    "This notebook guides you through fine-tuning a Large Language Model using Replicate.\n",
    "\n",
    "**Why Replicate?**\n",
    "- Pay-per-use pricing (no upfront costs)\n",
    "- Simple API and deployment\n",
    "- Good for experimentation\n",
    "- Automatic model hosting after training\n",
    "\n",
    "**What you'll learn:**\n",
    "1. Prepare training data in Replicate's format\n",
    "2. Create a fine-tuning training\n",
    "3. Monitor training progress\n",
    "4. Use your fine-tuned model\n",
    "\n",
    "**Prerequisites:**\n",
    "- Replicate account (https://replicate.com)\n",
    "- API token from Replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install replicate pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import replicate\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Set your Replicate API token\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    REPLICATE_API_TOKEN = userdata.get('REPLICATE_API_TOKEN')\n",
    "except:\n",
    "    REPLICATE_API_TOKEN = input(\"Enter your Replicate API token: \")\n",
    "\n",
    "os.environ['REPLICATE_API_TOKEN'] = REPLICATE_API_TOKEN\n",
    "\n",
    "print(\"‚úÖ Replicate client configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Preparation\n",
    "\n",
    "Replicate uses a simple **JSONL format** for fine-tuning:\n",
    "\n",
    "```json\n",
    "{\"prompt\": \"<prompt text>\", \"completion\": \"<completion text>\"}\n",
    "```\n",
    "\n",
    "Or for chat-style models:\n",
    "```json\n",
    "{\"text\": \"<s>[INST] <<SYS>>\\nSystem prompt\\n<</SYS>>\\n\\nUser message [/INST] Assistant response </s>\"}\n",
    "```\n",
    "\n",
    "### Key Requirements:\n",
    "- JSONL format (one JSON object per line)\n",
    "- Publicly accessible URL (we'll use GitHub or upload service)\n",
    "- Minimum ~10 examples, recommended 100+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Sample Dataset: Code Review Assistant\n",
    "# Replace with your own domain-specific data!\n",
    "# ============================================================\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert code reviewer. You provide constructive, actionable feedback on code.\n",
    "Focus on:\n",
    "- Code correctness and potential bugs\n",
    "- Performance considerations\n",
    "- Readability and maintainability\n",
    "- Security concerns\n",
    "Be specific and provide examples when suggesting improvements.\"\"\"\n",
    "\n",
    "# Llama 2/3 chat format\n",
    "def format_for_llama(system: str, user: str, assistant: str) -> dict:\n",
    "    \"\"\"Format data for Llama-style fine-tuning.\"\"\"\n",
    "    text = f\"<s>[INST] <<SYS>>\\n{system}\\n<</SYS>>\\n\\n{user} [/INST] {assistant} </s>\"\n",
    "    return {\"text\": text}\n",
    "\n",
    "# Alternative: Simple prompt/completion format\n",
    "def format_simple(user: str, assistant: str) -> dict:\n",
    "    \"\"\"Simple prompt-completion format.\"\"\"\n",
    "    return {\n",
    "        \"prompt\": f\"### Instruction:\\n{user}\\n\\n### Response:\\n\",\n",
    "        \"completion\": assistant\n",
    "    }\n",
    "\n",
    "sample_data = [\n",
    "    format_for_llama(\n",
    "        system=SYSTEM_PROMPT,\n",
    "        user=\"\"\"Review this Python function:\n",
    "```python\n",
    "def get_user(id):\n",
    "    conn = sqlite3.connect('db.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SELECT * FROM users WHERE id = {id}\")\n",
    "    return cursor.fetchone()\n",
    "```\"\"\",\n",
    "        assistant=\"\"\"I've identified several critical issues with this code:\n",
    "\n",
    "## üî¥ Critical: SQL Injection Vulnerability\n",
    "The f-string interpolation makes this vulnerable to SQL injection:\n",
    "```python\n",
    "# Dangerous - an attacker could pass: \"1; DROP TABLE users--\"\n",
    "cursor.execute(f\"SELECT * FROM users WHERE id = {id}\")\n",
    "```\n",
    "\n",
    "**Fix:** Use parameterized queries:\n",
    "```python\n",
    "cursor.execute(\"SELECT * FROM users WHERE id = ?\", (id,))\n",
    "```\n",
    "\n",
    "## üü° Resource Leak\n",
    "The connection is never closed, which can exhaust database connections.\n",
    "\n",
    "**Fix:** Use a context manager:\n",
    "```python\n",
    "def get_user(user_id: int) -> Optional[tuple]:\n",
    "    with sqlite3.connect('db.sqlite') as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT * FROM users WHERE id = ?\", (user_id,))\n",
    "        return cursor.fetchone()\n",
    "```\n",
    "\n",
    "## üü¢ Minor Improvements\n",
    "- Rename `id` to `user_id` (shadows built-in)\n",
    "- Add type hints\n",
    "- Consider returning `None` explicitly when not found\"\"\"\n",
    "    ),\n",
    "    format_for_llama(\n",
    "        system=SYSTEM_PROMPT,\n",
    "        user=\"\"\"Review this JavaScript code:\n",
    "```javascript\n",
    "async function fetchData() {\n",
    "    const response = await fetch('/api/data');\n",
    "    const data = await response.json();\n",
    "    return data;\n",
    "}\n",
    "```\"\"\",\n",
    "        assistant=\"\"\"This code works but lacks important error handling. Here's my review:\n",
    "\n",
    "## üü° Missing Error Handling\n",
    "The function doesn't handle failed requests or invalid JSON.\n",
    "\n",
    "**Issues:**\n",
    "1. No check for `response.ok` (HTTP errors like 404, 500)\n",
    "2. No try-catch for network failures or JSON parse errors\n",
    "3. No timeout handling for slow responses\n",
    "\n",
    "**Improved version:**\n",
    "```javascript\n",
    "async function fetchData() {\n",
    "    try {\n",
    "        const response = await fetch('/api/data');\n",
    "        \n",
    "        if (!response.ok) {\n",
    "            throw new Error(`HTTP error! status: ${response.status}`);\n",
    "        }\n",
    "        \n",
    "        const data = await response.json();\n",
    "        return data;\n",
    "    } catch (error) {\n",
    "        console.error('Failed to fetch data:', error);\n",
    "        throw error; // Re-throw to let caller handle\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "## üü¢ Good Practices Already Present\n",
    "- Uses async/await (readable)\n",
    "- Simple, single-purpose function\n",
    "\n",
    "Consider adding a timeout with `AbortController` for production code.\"\"\"\n",
    "    ),\n",
    "    format_for_llama(\n",
    "        system=SYSTEM_PROMPT,\n",
    "        user=\"\"\"Review this React component:\n",
    "```jsx\n",
    "function UserList({ users }) {\n",
    "    return (\n",
    "        <ul>\n",
    "            {users.map(user => (\n",
    "                <li>{user.name}</li>\n",
    "            ))}\n",
    "        </ul>\n",
    "    );\n",
    "}\n",
    "```\"\"\",\n",
    "        assistant=\"\"\"This is a clean component with one important fix needed:\n",
    "\n",
    "## üü° Missing Key Prop\n",
    "React requires a unique `key` prop when rendering lists for efficient reconciliation.\n",
    "\n",
    "**Current issue:**\n",
    "```jsx\n",
    "<li>{user.name}</li>  // Missing key - React will warn\n",
    "```\n",
    "\n",
    "**Fix:**\n",
    "```jsx\n",
    "<li key={user.id}>{user.name}</li>\n",
    "```\n",
    "\n",
    "## üü° Edge Case: Empty/Null Users\n",
    "Consider handling cases where `users` might be undefined or empty.\n",
    "\n",
    "**Improved version:**\n",
    "```jsx\n",
    "function UserList({ users = [] }) {\n",
    "    if (users.length === 0) {\n",
    "        return <p>No users found.</p>;\n",
    "    }\n",
    "    \n",
    "    return (\n",
    "        <ul>\n",
    "            {users.map(user => (\n",
    "                <li key={user.id}>{user.name}</li>\n",
    "            ))}\n",
    "        </ul>\n",
    "    );\n",
    "}\n",
    "```\n",
    "\n",
    "## üü¢ What's Good\n",
    "- Functional component (modern React)\n",
    "- Props destructuring\n",
    "- Simple, focused responsibility\"\"\"\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"üìä Sample dataset with {len(sample_data)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Your Contribution: Add Training Examples\n",
    "\n",
    "`‚òÖ Insight ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ`\n",
    "**Why your examples matter for fine-tuning:**\n",
    "- The model learns your specific style and domain expertise\n",
    "- Edge cases teach the model what to do in unusual situations\n",
    "- Consistency in format leads to consistent outputs\n",
    "`‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ`\n",
    "\n",
    "**Your task:** Add examples that cover code you commonly review. Think about:\n",
    "- Languages your team uses most\n",
    "- Common mistakes you see in PRs\n",
    "- Your team's specific style guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TODO: Add your training examples\n",
    "# ============================================================\n",
    "\n",
    "def create_review_example(code_snippet: str, review_response: str) -> dict:\n",
    "    \"\"\"Helper to create a code review training example.\"\"\"\n",
    "    user_message = f\"Review this code:\\n```\\n{code_snippet}\\n```\"\n",
    "    return format_for_llama(SYSTEM_PROMPT, user_message, review_response)\n",
    "\n",
    "# Add your examples:\n",
    "my_examples = [\n",
    "    # Example: Uncomment and customize\n",
    "    # create_review_example(\n",
    "    #     code_snippet=\"\"\"def process(data):\n",
    "    #         for item in data:\n",
    "    #             print(item)\"\"\",\n",
    "    #     review_response=\"Here's my review...\"\n",
    "    # ),\n",
    "]\n",
    "\n",
    "# Combine all data\n",
    "all_training_data = sample_data + my_examples\n",
    "print(f\"üìä Total training examples: {len(all_training_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSONL file\n",
    "\n",
    "TRAIN_FILE = \"replicate_training_data.jsonl\"\n",
    "\n",
    "with open(TRAIN_FILE, 'w') as f:\n",
    "    for example in all_training_data:\n",
    "        f.write(json.dumps(example) + '\\n')\n",
    "\n",
    "print(f\"‚úÖ Saved {len(all_training_data)} examples to {TRAIN_FILE}\")\n",
    "\n",
    "# Preview\n",
    "print(\"\\nüìÑ First example preview:\")\n",
    "print(json.dumps(all_training_data[0], indent=2)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload Training Data\n",
    "\n",
    "Replicate needs a publicly accessible URL for your training data. Options:\n",
    "\n",
    "1. **GitHub Gist** (free, easy)\n",
    "2. **AWS S3** (private, scalable)\n",
    "3. **Google Cloud Storage** (if using GCP)\n",
    "4. **Replicate's file upload** (via API)\n",
    "\n",
    "We'll use Replicate's built-in file hosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Upload to a temporary file hosting service\n",
    "# For production, use your own cloud storage\n",
    "\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "def upload_to_github_gist(filename: str, content: str, description: str = \"Training data\") -> str:\n",
    "    \"\"\"Upload content to a GitHub Gist and return the raw URL.\n",
    "    \n",
    "    Note: Requires GITHUB_TOKEN environment variable with 'gist' scope.\n",
    "    \"\"\"\n",
    "    token = os.environ.get('GITHUB_TOKEN')\n",
    "    if not token:\n",
    "        return None\n",
    "    \n",
    "    url = \"https://api.github.com/gists\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {token}\",\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"description\": description,\n",
    "        \"public\": True,\n",
    "        \"files\": {\n",
    "            filename: {\"content\": content}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code == 201:\n",
    "        gist = response.json()\n",
    "        raw_url = gist['files'][filename]['raw_url']\n",
    "        return raw_url\n",
    "    else:\n",
    "        print(f\"Failed to create gist: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Read the training file\n",
    "with open(TRAIN_FILE, 'r') as f:\n",
    "    training_content = f.read()\n",
    "\n",
    "# Try to upload to Gist\n",
    "TRAINING_URL = upload_to_github_gist(TRAIN_FILE, training_content)\n",
    "\n",
    "if TRAINING_URL:\n",
    "    print(f\"‚úÖ Training data uploaded to: {TRAINING_URL}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Could not auto-upload. Please:\")\n",
    "    print(\"   1. Create a GitHub Gist manually at https://gist.github.com\")\n",
    "    print(\"   2. Paste your training data content\")\n",
    "    print(\"   3. Get the 'Raw' URL and set TRAINING_URL below\")\n",
    "    \n",
    "    # Manual URL entry\n",
    "    # TRAINING_URL = \"https://gist.githubusercontent.com/...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Upload directly to Replicate via files API\n",
    "# This creates a temporary URL valid for the training\n",
    "\n",
    "def upload_to_replicate(file_path: str) -> str:\n",
    "    \"\"\"Upload a file to Replicate and return the URL.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        file_response = replicate.files.create(f)\n",
    "    return file_response.urls['get']\n",
    "\n",
    "# Upload if Gist didn't work\n",
    "if not TRAINING_URL:\n",
    "    try:\n",
    "        TRAINING_URL = upload_to_replicate(TRAIN_FILE)\n",
    "        print(f\"‚úÖ Uploaded to Replicate: {TRAINING_URL}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Upload failed: {e}\")\n",
    "        print(\"   Please manually set TRAINING_URL to a publicly accessible URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start Fine-Tuning\n",
    "\n",
    "### Available Base Models on Replicate:\n",
    "\n",
    "| Model | Replicate Name | Best For |\n",
    "|-------|---------------|----------|\n",
    "| Llama 3.1 8B | `meta/meta-llama-3.1-8b-instruct` | General purpose |\n",
    "| Llama 3.1 70B | `meta/meta-llama-3.1-70b-instruct` | High quality |\n",
    "| Mistral 7B | `mistralai/mistral-7b-instruct-v0.2` | Fast, efficient |\n",
    "| Code Llama | `meta/codellama-34b-instruct` | Code generation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Configure Fine-Tuning\n",
    "# ============================================================\n",
    "\n",
    "# Destination for your fine-tuned model\n",
    "# Format: \"your-username/model-name\"\n",
    "REPLICATE_USERNAME = input(\"Enter your Replicate username: \")\n",
    "MODEL_NAME = \"code-reviewer-llama\"  # Change this!\n",
    "\n",
    "DESTINATION = f\"{REPLICATE_USERNAME}/{MODEL_NAME}\"\n",
    "\n",
    "# Base model to fine-tune\n",
    "BASE_MODEL = \"meta/meta-llama-3-8b-instruct\"  # Good balance of speed/quality\n",
    "\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"   Base model: {BASE_MODEL}\")\n",
    "print(f\"   Destination: {DESTINATION}\")\n",
    "print(f\"   Training data: {TRAINING_URL[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the fine-tuning training\n",
    "\n",
    "print(\"üöÄ Starting fine-tuning...\")\n",
    "\n",
    "training = replicate.trainings.create(\n",
    "    version=\"meta/meta-llama-3-8b-instruct:5b8a5c1e1f3b1e5e5c3e1b5a5c1e1f3b1e5e5c3e\",  # Check Replicate for latest version\n",
    "    input={\n",
    "        \"train_data\": TRAINING_URL,\n",
    "        \"num_train_epochs\": 3,\n",
    "        \"train_batch_size\": 4,\n",
    "        \"learning_rate\": 1e-5,\n",
    "    },\n",
    "    destination=DESTINATION\n",
    ")\n",
    "\n",
    "TRAINING_ID = training.id\n",
    "print(f\"‚úÖ Training created!\")\n",
    "print(f\"   Training ID: {TRAINING_ID}\")\n",
    "print(f\"   Status: {training.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Use Replicate's Web UI\n",
    "\n",
    "If the API approach has issues, you can also fine-tune via Replicate's web interface:\n",
    "\n",
    "1. Go to https://replicate.com/create-training\n",
    "2. Select your base model\n",
    "3. Upload or link your training data\n",
    "4. Configure hyperparameters\n",
    "5. Start training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Monitor Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def check_training_status(training_id: str):\n",
    "    \"\"\"Check the status of a training.\"\"\"\n",
    "    training = replicate.trainings.get(training_id)\n",
    "    return training\n",
    "\n",
    "def monitor_training(training_id: str, poll_interval: int = 60):\n",
    "    \"\"\"Monitor training until completion.\"\"\"\n",
    "    print(f\"üìä Monitoring training {training_id}...\")\n",
    "    print(\"   (Fine-tuning can take 15-120+ minutes)\\n\")\n",
    "    \n",
    "    while True:\n",
    "        training = check_training_status(training_id)\n",
    "        status = training.status\n",
    "        \n",
    "        print(f\"   [{time.strftime('%H:%M:%S')}] Status: {status}\")\n",
    "        \n",
    "        if training.logs:\n",
    "            # Show last few lines of logs\n",
    "            recent_logs = training.logs.split('\\n')[-3:]\n",
    "            for log in recent_logs:\n",
    "                if log.strip():\n",
    "                    print(f\"                  {log[:80]}\")\n",
    "        \n",
    "        if status == \"succeeded\":\n",
    "            print(f\"\\n‚úÖ Training completed!\")\n",
    "            print(f\"   Model version: {training.output}\")\n",
    "            return training\n",
    "        elif status in [\"failed\", \"canceled\"]:\n",
    "            print(f\"\\n‚ùå Training {status}\")\n",
    "            if training.error:\n",
    "                print(f\"   Error: {training.error}\")\n",
    "            return training\n",
    "        \n",
    "        time.sleep(poll_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick status check\n",
    "if 'TRAINING_ID' in dir():\n",
    "    training_status = check_training_status(TRAINING_ID)\n",
    "    print(f\"Training ID: {TRAINING_ID}\")\n",
    "    print(f\"Status: {training_status.status}\")\n",
    "    \n",
    "    if training_status.status == \"succeeded\":\n",
    "        print(f\"Model: {training_status.output}\")\n",
    "else:\n",
    "    print(\"No training ID found. Set TRAINING_ID manually if you have one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor until completion (uncomment to run)\n",
    "# completed_training = monitor_training(TRAINING_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Your Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your fine-tuned model\n",
    "if 'TRAINING_ID' in dir():\n",
    "    training_info = check_training_status(TRAINING_ID)\n",
    "    if training_info.status == \"succeeded\":\n",
    "        FINE_TUNED_MODEL = training_info.output\n",
    "        print(f\"üéØ Fine-tuned model: {FINE_TUNED_MODEL}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Training not complete. Status: {training_info.status}\")\n",
    "        FINE_TUNED_MODEL = None\n",
    "else:\n",
    "    # Manually set if you know your model version\n",
    "    FINE_TUNED_MODEL = f\"{DESTINATION}:latest\"  # Or specific version hash\n",
    "    print(f\"üéØ Using model: {FINE_TUNED_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_version: str, prompt: str, system_prompt: str = None) -> str:\n",
    "    \"\"\"Run inference on a Replicate model.\"\"\"\n",
    "    \n",
    "    # Format for Llama chat\n",
    "    if system_prompt:\n",
    "        full_prompt = f\"<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{prompt} [/INST]\"\n",
    "    else:\n",
    "        full_prompt = f\"<s>[INST] {prompt} [/INST]\"\n",
    "    \n",
    "    output = replicate.run(\n",
    "        model_version,\n",
    "        input={\n",
    "            \"prompt\": full_prompt,\n",
    "            \"max_new_tokens\": 1024,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.9,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Collect streaming output\n",
    "    result = \"\".join(output)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model\n",
    "\n",
    "test_code_snippets = [\n",
    "    \"\"\"def calculate_total(items):\n",
    "    total = 0\n",
    "    for i in range(len(items)):\n",
    "        total = total + items[i]['price'] * items[i]['quantity']\n",
    "    return total\"\"\",\n",
    "    \n",
    "    \"\"\"const getUserData = async (userId) => {\n",
    "    const response = await fetch(`/api/users/${userId}`);\n",
    "    return response.json();\n",
    "}\"\"\",\n",
    "]\n",
    "\n",
    "if FINE_TUNED_MODEL:\n",
    "    print(\"üß™ Testing fine-tuned model\\n\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for code in test_code_snippets:\n",
    "        prompt = f\"Review this code:\\n```\\n{code}\\n```\"\n",
    "        \n",
    "        print(f\"\\nüìù Code to review:\")\n",
    "        print(code)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        response = run_model(FINE_TUNED_MODEL, prompt, SYSTEM_PROMPT)\n",
    "        print(f\"ü§ñ Review:\\n{response}\")\n",
    "        print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please set FINE_TUNED_MODEL first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Deploy as API\n",
    "\n",
    "Your fine-tuned model is automatically deployed on Replicate. You can use it via:\n",
    "\n",
    "### Python\n",
    "```python\n",
    "import replicate\n",
    "\n",
    "output = replicate.run(\n",
    "    \"your-username/code-reviewer-llama:version-hash\",\n",
    "    input={\"prompt\": \"Review this code...\"}\n",
    ")\n",
    "```\n",
    "\n",
    "### cURL\n",
    "```bash\n",
    "curl -s -X POST \\\n",
    "  -H \"Authorization: Token $REPLICATE_API_TOKEN\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"version\": \"...\", \"input\": {\"prompt\": \"...\"}}' \\\n",
    "  https://api.replicate.com/v1/predictions\n",
    "```\n",
    "\n",
    "### JavaScript\n",
    "```javascript\n",
    "const Replicate = require('replicate');\n",
    "const replicate = new Replicate();\n",
    "\n",
    "const output = await replicate.run(\n",
    "  \"your-username/code-reviewer-llama:version-hash\",\n",
    "  { input: { prompt: \"Review this code...\" } }\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate deployment code snippet\n",
    "\n",
    "if FINE_TUNED_MODEL:\n",
    "    print(\"üöÄ Your model is ready to use!\")\n",
    "    print(f\"\\nModel: {FINE_TUNED_MODEL}\")\n",
    "    print(f\"\\nüìã Quick usage:\")\n",
    "    print(f\"\"\"\n",
    "import replicate\n",
    "\n",
    "output = replicate.run(\n",
    "    \"{FINE_TUNED_MODEL}\",\n",
    "    input={{\n",
    "        \"prompt\": \"<s>[INST] Review this code: ... [/INST]\",\n",
    "        \"max_new_tokens\": 1024,\n",
    "        \"temperature\": 0.7\n",
    "    }}\n",
    ")\n",
    "\n",
    "print(\"\".join(output))\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Resources\n",
    "\n",
    "- [Replicate Documentation](https://replicate.com/docs)\n",
    "- [Fine-Tuning Guide](https://replicate.com/docs/guides/fine-tune-a-language-model)\n",
    "- [Model Library](https://replicate.com/collections/language-models)\n",
    "- [Pricing](https://replicate.com/pricing)\n",
    "\n",
    "## üí° Tips\n",
    "\n",
    "1. **Start small**: Test with ~50 examples before scaling up\n",
    "2. **Quality > Quantity**: Well-crafted examples beat more mediocre ones\n",
    "3. **Monitor costs**: Replicate charges per-second for training\n",
    "4. **Version control**: Keep your training data versioned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
