Paper: Offline_RL_Generative_Trajectory.pdf
Category: 10_offline_rl

Category Definition:
Learning from fixed datasets without environment interaction (Batch RL).

Abstract Snippet:
Preprint  O FFLINE R EINFORCEMENT L EARNING WITH G ENERA TIVE T RAJECTORY P OLICIES Xinsong Feng1 , Leshu Tang2 , Chenan Wang1 , Haipeng Chen1 1 William & Mary, 2 UCLA xfeng06@wm.edu, leshutang@ucla.edu, cwang33@wm.edu, hchen23@wm.edu  arXiv:2510.11499v1 [cs.LG] 13 Oct 2025  A BSTRACT Generative models have emerged as a powerful class of policies for offline reinforcement learning (RL) due to their ability to capture complex, multi-modal behaviors. However, existing methods face a stark trade-off: slow, iterative models like diffusion policies are computationally expensive, while fast, single-...

Specific Evidence for Classification:
- "Preprint  O FFLINE R EINFORCEMENT L EARNING WITH G ENERA TIVE T RAJECTORY P OLICIES Xinsong Feng1 , Leshu Tang2 , Chenan Wang1 , Haipeng Chen1 1 William & Mary, 2 UCLA xfeng06@wm.edu, leshutang@ucla.edu, cwang33@wm.edu, hchen23@wm.edu  arXiv:2510.11499v1 [cs.LG] 13 Oct 2025  A BSTRACT Generative models have emerged as a powerful class of policies for offline reinforcement learning (RL) due to their ability to capture complex, multi-modal behaviors."

Conclusion:
This paper is classified as 10_offline_rl because it explicitly discusses concepts such as offline, batch, dataset, matching the research direction's core themes.
