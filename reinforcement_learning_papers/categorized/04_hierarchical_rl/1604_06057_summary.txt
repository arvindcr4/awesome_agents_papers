PAPER: 1604_06057.pdf
TITLE: Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation
ARXIV_ID: 1604.06057v2
RESEARCH_METHOD: 04_hierarchical_rl
METHOD_DESCRIPTION: The paper introduces Hierarchical Deep Q-Networks (h-DQN), a framework that integrates hierarchical value functions with intrinsic motivation for deep reinforcement learning. h-DQN consists of a meta-controller that selects goals and a controller that learns to achieve these goals through intrinsic rewards. The framework allows for flexible goal specifications and efficient exploration in complex environments.
KEY_CONTRIBUTIONS:
- The paper proposes a novel hierarchical reinforcement learning framework that combines temporal abstraction and intrinsic motivation.
- h-DQN is demonstrated to be effective in environments with sparse and delayed rewards, such as the Atari game Montezuma's Revenge.
- The framework enables efficient exploration and learning in complex environments by parameterizing intrinsic motivation in the space of entities and relations.
- The authors highlight the potential for combining deep generative models with h-DQN to disentangle objects from raw pixels and improve performance in more challenging environments.
