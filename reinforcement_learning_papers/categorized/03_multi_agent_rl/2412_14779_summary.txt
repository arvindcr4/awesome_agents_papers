Here is the extracted information:

**PAPER:** Agent-Temporal Credit Assignment for Optimal Policy Preservation in Sparse Multi-Agent Reinforcement Learning
**TITLE:** Agent-Temporal Credit Assignment for Optimal Policy Preservation in Sparse Multi-Agent Reinforcement Learning
**ARXIV_ID:** 2412.14779v1 [cs.MA]
**RESEARCH_METHOD:** 03_multi_agent_rl
**METHOD_DESCRIPTION:** The paper proposes a novel approach called Temporal-Agent Reward Redistribution (TAR2) to address the agent-temporal credit assignment problem in multi-agent reinforcement learning. TAR2 decomposes sparse global rewards into timestep-specific rewards and calculates agent-specific contributions to these rewards. The method is designed to preserve the optimal policy of the original reward function and is theoretically proven to be equivalent to potential-based reward shaping.
**KEY_CONTRIBUTIONS:**
* Introduction of the TAR2 approach for agent-temporal credit assignment in multi-agent reinforcement learning
* Theoretical proof that TAR2 is equivalent to potential-based reward shaping, ensuring that the optimal policy remains unchanged
* Empirical results demonstrating that TAR2 stabilizes and accelerates the learning process
* Application of TAR2 to various environments, including SMACLite and Google Football
* Comparison of TAR2 with other state-of-the-art baselines, including IPPO and MAPPO
