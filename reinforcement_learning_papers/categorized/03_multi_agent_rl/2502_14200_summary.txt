Here are the extracted information from the research paper:

**PAPER**: Causal Mean Field Multi-Agent Reinforcement Learning
**TITLE**: Causal Mean Field Multi-Agent Reinforcement Learning
**ARXIV_ID**: 2502.14200v1
**RESEARCH_METHOD**: 03_multi_agent_rl
**METHOD_DESCRIPTION**: The paper proposes a new algorithm called Causal Mean Field Q-learning (CMFQ) to address the scalability problem in multi-agent reinforcement learning. CMFQ uses a structural causal model (SCM) to represent the invariant causal structure of decision-making in mean-field reinforcement learning (MFRL). The algorithm enables agents to identify more essential interactions by intervening on the SCM and quantifying the causal effects of pairwise interactions.
**KEY_CONTRIBUTIONS**:
* The paper analyzes the bottleneck of MFRL in solving the scalability problem and proposes CMFQ to alleviate the second problem of non-stationarity.
* CMFQ demonstrates a promising and flexible framework for incorporating causal inference into MFRL.
* The method to calculate causal effects is very flexible, and new algorithms could be obtained by reasonably modifying the causal module in the framework.
* CMFQ exhibits impressive scalability during both training and execution, outperforming other baselines in the mixed cooperative-competitive game and cooperative predator-prey game tasks.
