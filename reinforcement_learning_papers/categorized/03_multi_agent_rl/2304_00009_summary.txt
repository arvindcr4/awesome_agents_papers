Here is the extracted information:

**PAPER:** The challenge of redundancy on multi-agent value factorisation
**TITLE:** The challenge of redundancy on multi-agent value factorisation: Extended Abstract
**ARXIV_ID:** 2304.00009v1
**RESEARCH_METHOD:** 03_multi_agent_rl
**METHOD_DESCRIPTION:** The authors propose a new method called Relevance Decomposition Network (RDN) to address the challenge of redundancy in multi-agent reinforcement learning. RDN uses layer-wise relevance propagation (LRP) to separate the learning of the joint value function and the generation of local reward signals, allowing for more effective credit assignment in environments with high numbers of redundant agents.
**KEY_CONTRIBUTIONS:**
* The authors identify the problem of redundancy in multi-agent reinforcement learning, where the presence of redundant agents can lead to decreased performance and increased variance in credit assignment.
* They propose RDN as a solution to this problem, which uses LRP to perform more optimal credit assignments in environments with high numbers of redundant agents.
* The authors demonstrate the effectiveness of RDN in a series of experiments, showing that it outperforms existing methods such as QMIX and VDN in environments with varying numbers of redundant agents.
* They also show that RDN can reach near-optimal convergence on all environments used, without the need for ground truth state information.
