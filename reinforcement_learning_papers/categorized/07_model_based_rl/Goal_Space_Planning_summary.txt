PAPER: Goal_Space_Planning.pdf
TITLE: A New View on Planning in Online Reinforcement Learning
RESEARCH_METHOD: 07_model_based_rl
METHOD_DESCRIPTION: This paper introduces a new approach to model-based reinforcement learning called Goal-Space Planning (GSP), which uses background planning to improve value propagation with minimalist, local models and computationally efficient planning. The GSP algorithm focuses on planning over a given set of abstract subgoals to provide quickly updated, approximate values to speed up learning. The agent first learns a set of subgoal-conditioned models, which are then used to form a temporally abstract goal-space semi-MDP. The agent can update its policy based on these subgoal values to speed up learning.
KEY_CONTRIBUTIONS:
* Introduces a new approach to model-based reinforcement learning called Goal-Space Planning (GSP)
* Uses background planning to improve value propagation with minimalist, local models and computationally efficient planning
* Provides a new formalism for planning in online reinforcement learning, which can be used to speed up learning in various domains
* Shows that GSP can propagate value and learn an optimal policy faster than its base learner in several domains, including FourRooms, PinBall, and GridBall
* Demonstrates that GSP can be used with different types of value function approximation, including tabular and linear function approximation
* Investigates the use of GSP in the deep reinforcement learning setting, where the learner must also learn a representation of its environment.
