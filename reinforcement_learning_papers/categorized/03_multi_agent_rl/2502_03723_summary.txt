Here is the extracted information:

**PAPER**: LLM-Guided Credit Assignment in Multi-Agent Reinforcement Learning
**TITLE**: LLM-Guided Credit Assignment in Multi-Agent Reinforcement Learning
**ARXIV_ID**: 2502.03723v2
**RESEARCH_METHOD**: 03_multi_agent_rl
**METHOD_DESCRIPTION**: This paper proposes a novel framework called LLM-Guided Credit Assignment (LCA) that leverages large language models (LLMs) to generate dense, agent-specific rewards based on a natural language description of the task and the overall team goal. The LCA approach decomposes the joint preference ranking into individual preference rankings for each agent, allowing for the learning of individual reward functions. The method uses a potential-based reward-shaping mechanism to mitigate the impact of LLM hallucination, enhancing the robustness and reliability of the approach.
**KEY_CONTRIBUTIONS**:
* The paper proposes a novel framework for credit assignment in multi-agent reinforcement learning using LLMs.
* The LCA approach generates dense, agent-specific rewards based on a natural language description of the task and the overall team goal.
* The method decomposes the joint preference ranking into individual preference rankings for each agent, allowing for the learning of individual reward functions.
* The paper demonstrates the effectiveness of the LCA approach in various multi-agent collaboration scenarios, including the Two-Switch, Victim-Rubble, and Pistonball environments.
* The results show that the LCA approach achieves faster convergence and higher policy returns compared to state-of-the-art MARL baselines.
