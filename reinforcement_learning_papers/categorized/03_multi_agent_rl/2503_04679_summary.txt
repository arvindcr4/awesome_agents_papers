Here is the extracted information:

**PAPER:** Multi-Agent Inverse Q-Learning from Demonstrations
**TITLE:** Multi-Agent Inverse Q-Learning from Demonstrations
**ARXIV_ID:** 2503.04679v1 [cs.MA]
**RESEARCH_METHOD:** 03_multi_agent_rl
**METHOD_DESCRIPTION:** This paper proposes a novel multi-agent inverse reinforcement learning algorithm called Multi-Agent Marginal Q-Learning from Demonstrations (MAMQL). MAMQL learns a marginalization of the action-value function of each agent by taking the expectation of their value function over the action space of all other agents. This allows for a well-motivated use of Boltzmann policies in the multi-agent context.
**KEY_CONTRIBUTIONS:**
* Proposes a novel multi-agent inverse reinforcement learning algorithm called MAMQL
* Learns a marginalization of the action-value function of each agent
* Uses Boltzmann policies to model the behavior of agents in a multi-agent setting
* Demonstrates the effectiveness of MAMQL in several multi-agent environments, including a grid world, Overcooked, and a highway intersection scenario
* Compares MAMQL to several baselines, including behavioral cloning, IQ-Learn, and MA-AIRL, and shows that MAMQL outperforms them in terms of average reward and convergence time.
