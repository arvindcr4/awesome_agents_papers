Here is the extracted information:

**PAPER:** Structured Reinforcement Learning for Combinatorial Decision-Making
**TITLE:** Structured Reinforcement Learning
**RESEARCH_METHOD:** 07_model_based_rl
**METHOD_DESCRIPTION:** This paper proposes a novel reinforcement learning paradigm called Structured Reinforcement Learning (SRL) for solving combinatorial Markov Decision Processes (C-MDPs). SRL integrates combinatorial optimization layers into the actor neural network, enabling end-to-end learning of the actor via Fenchel-Young losses. The method provides a geometric interpretation of SRL as a primal-dual algorithm in the dual of the moment polytope.
**KEY_CONTRIBUTIONS:**
* SRL is a novel actor-critic RL paradigm that embeds combinatorial optimization-layers into the actor neural network.
* SRL enables end-to-end learning of the actor via Fenchel-Young losses and provides a geometric interpretation of SRL as a primal-dual algorithm.
* SRL is evaluated across six environments with exogenous and endogenous uncertainty, matching or surpassing the performance of unstructured RL and imitation learning on static tasks and improving over these baselines by up to 92% on dynamic problems.
* SRL exhibits improved stability and convergence speed compared to unstructured RL.
* SRL is compared to Structured Imitation Learning (SIL) and Proximal Policy Optimization (PPO) in three static and three dynamic environments, demonstrating its effectiveness in solving C-MDPs.
(NOTE: Processed using first-chunk strategy due to file size)
