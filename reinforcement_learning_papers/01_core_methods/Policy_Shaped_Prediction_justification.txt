Paper: Policy_Shaped_Prediction.pdf
Category: 01_core_methods

Category Definition:
Fundamental RL algorithms like PPO, DQN, SAC, and policy gradients.

Abstract Snippet:
Policy-shaped prediction: avoiding distractions in model-based reinforcement learning  arXiv:2412.05766v1 [cs.LG] 8 Dec 2024  Miles Hutson Stanford University hutson@stanford.edu  Isaac Kauvar Stanford University ikauvar@stanford.edu  Nick Haber Stanford University nhaber@stanford.edu  Abstract Model-based reinforcement learning (MBRL) is a promising route to sampleefficient policy optimization. However, a known vulnerability of reconstructionbased MBRL consists of scenarios in which detailed aspects of the world are highly predictable, but irrelevant to learning a good policy. Such scenarios ...

Specific Evidence for Classification:
- "Policy-shaped prediction: avoiding distractions in model-based reinforcement learning  arXiv:2412.05766v1 [cs.LG] 8 Dec 2024  Miles Hutson Stanford University hutson@stanford.edu  Isaac Kauvar Stanford University ikauvar@stanford.edu  Nick Haber Stanford University nhaber@stanford.edu  Abstract Model-based reinforcement learning (MBRL) is a promising route to sampleefficient policy optimization."

Conclusion:
This paper is classified as 01_core_methods because it explicitly discusses concepts such as algorithm, policy gradient, q-learning, matching the research direction's core themes.
