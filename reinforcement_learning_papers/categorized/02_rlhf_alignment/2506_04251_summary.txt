Here is the extracted information:

**PAPER:** Language-Driven Coordination and Learning in Multi-Agent Simulation Environments
**TITLE:** LLM-MARL: A Unified Framework for Multi-Agent Reinforcement Learning with Large Language Models
**ARXIV_ID:** Not provided
**RESEARCH_METHOD:** 02_rlhf_alignment (Reinforcement Learning with Hierarchical Feedback Alignment)
**METHOD_DESCRIPTION:** This paper introduces LLM-MARL, a framework that integrates large language models (LLMs) into multi-agent reinforcement learning (MARL) to enhance coordination, communication, and generalization in simulated environments. The framework features three modular components: LLM-Coordinator, LLM-Communicator, and LLM-Memory, which dynamically generate subgoals, facilitate symbolic inter-agent messaging, and support episodic recall.

**KEY_CONTRIBUTIONS:**

* Proposed a novel framework that integrates LLMs into MARL systems via coordinator, communicator, and memory modules.
* Designed training procedures that support dynamic prompting, LLM-guided supervision, and RL optimization in tandem.
* Empirically demonstrated significant gains in cooperation, generalization, and language-grounded policy learning across multiple complex environments.

Let me know if you need any further assistance!
