Here is the extracted information in the format you requested:

**PAPER:** M AESTRO : L EARNING TO C OLLABORATE VIA C ON DITIONAL L ISTWISE P OLICY O PTIMIZATION FOR M ULTI -AGENT LLM S
**TITLE:** M AESTRO : Learning to Collaborate via Conditional Listwise Policy Optimization for Multi-Agent LLMs
**ARXIV_ID:** 2511.06134v1
**RESEARCH_METHOD:** 03_multi_agent_rl
**METHOD_DESCRIPTION:** The paper introduces M AESTRO, a principled framework for multi-agent collaboration that enables both divergent exploration and convergent synthesis. The framework consists of a collective of parallel execution agents for diverse exploration and a centralized agent for convergent, evaluative synthesis. The authors also propose Conditional Listwise Policy Optimization (CLPO), a reinforcement learning objective that disentangles decision-making from rationale generation.
**KEY_CONTRIBUTIONS:**
* Introduction of M AESTRO, a framework for multi-agent collaboration that operationalizes the divergent-convergent duality through three coordinated phases.
* Proposal of Conditional Listwise Policy Optimization (CLPO), an RL objective that decouples signals for decisions and reasons.
* Experimental evaluation of M AESTRO with CLPO on various benchmarks, demonstrating significant improvements over state-of-the-art baselines.
