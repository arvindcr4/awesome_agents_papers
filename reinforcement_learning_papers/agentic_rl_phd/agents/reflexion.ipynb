{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reflexion.py\n",
    "\n",
    "Auto-generated implementation from the Agentic RL PhD codebase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Implementations & References\n",
    "The following links point to the official or high-quality reference implementations for the papers covered in this notebook:\n\n",
    "- https://github.com/noahshinn/reflexion\n",
    "\n",
    "*Note: The code below is a simplified pedagogical implementation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "# Paper: \"Reflexion: Language Agents with Verbal Reinforcement Learning\" (Shinn et al., 2023)\n",
    "# Category: Agentic / Verbal RL\n",
    "\n",
    "class ReflexionAgent:\n",
    "    def __init__(self, llm_client, system_prompt):\n",
    "        self.llm = llm_client\n",
    "        self.system_prompt = system_prompt\n",
    "        self.memory = [] # Short-term trajectory\n",
    "        self.reflections = [] # \"Verbal\" gradients/updates\n",
    "\n",
    "    def act(self, observation: str) -> str:\n",
    "        \"\"\"\n",
    "        Generates an action based on context + past reflections.\n",
    "        \"\"\"\n",
    "        context = self._build_context(observation)\n",
    "        action = self.llm.generate(context)\n",
    "        self.memory.append(f\"Obs: {observation} -> Action: {action}\")\n",
    "        return action\n",
    "\n",
    "    def reflect(self, success: bool, feedback: str):\n",
    "        \"\"\"\n",
    "        The \"Learning\" Step.\n",
    "        Instead of backpropagation, we ask the LLM to criticize itself.\n",
    "        \"\"\"\n",
    "        if success:\n",
    "            return # No need to fix what isn't broken\n",
    "        \n",
    "        trajectory = \"\\n\".join(self.memory[-5:]) # Look at last 5 steps\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You failed the task. \n",
    "        Trajectory:\n",
    "        {trajectory}\n",
    "        \n",
    "        Feedback: {feedback}\n",
    "        \n",
    "        Reflect on why you failed and devise a new plan. \n",
    "        Be concise.\n",
    "        \"\"\"\n",
    "        \n",
    "        critique = self.llm.generate(prompt)\n",
    "        self.reflections.append(critique)\n",
    "        # Clear specific memory to try again with new wisdom\n",
    "        self.memory = [] \n",
    "\n",
    "    def _build_context(self, observation):\n",
    "        \"\"\"\n",
    "        Injects 'Reflections' into the context window.\n",
    "        This is analogous to 'updating the policy weights'.\n",
    "        \"\"\"\n",
    "        context = f\"System: {self.system_prompt}\\n\"\n",
    "        \n",
    "        if self.reflections:\n",
    "            context += \"Past Mistakes & Lessons:\\n\"\n",
    "            for i, r in enumerate(self.reflections):\n",
    "                context += f\"{i+1}. {r}\\n\"\n",
    "        \n",
    "        context += f\"\\nCurrent Observation: {observation}\"\n",
    "        return context\n",
    "\n",
    "# Mock LLM for demonstration\n",
    "class MockLLM:\n",
    "    def generate(self, prompt):\n",
    "        return \"Thinking... [Placeholder Action]\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}