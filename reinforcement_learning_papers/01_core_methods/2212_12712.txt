When Do Curricula Work in Federated Learning?

arXiv:2212.12712v1 [cs.LG] 24 Dec 2022

Saeed Vahidian1 , Sreevatsank Kadaveru1 , Woonjoon Baek1 , Weijia Wang1 , Vyacheslav Kungurtsev2,
Chen Chen3 , Mubarak Shah3 , Bill Lin1
1

University of California San Diego

Abstract
An oft-cited open problem of federated learning is the existence of data heterogeneity at the clients. One pathway to
understanding the drastic accuracy drop in federated learning is by scrutinizing the behavior of the clients’ deep models on data with different levels of ”difficulty”, which has
been left unaddressed. In this paper, we investigate a different and rarely studied dimension of FL: ordered learning.
Specifically, we aim to investigate how ordered learning
principles can contribute to alleviating the heterogeneity effects in FL. We present theoretical analysis and conduct extensive empirical studies on the efficacy of orderings spanning three kinds of learning: curriculum, anti-curriculum,
and random curriculum. We find that curriculum learning
largely alleviates non-IIDness. Interestingly, the more disparate the data distributions across clients the more they
benefit from ordered learning. We provide analysis explaining this phenomenon, specifically indicating how curriculum training appears to make the objective landscape progressively less convex, suggesting fast converging iterations
at the beginning of the training procedure. We derive quantitative results of convergence for both convex and nonconvex objectives by modeling the curriculum training on federated devices as local SGD with locally biased stochastic
gradients. Also, inspired by ordered learning, we propose a
novel client selection technique that benefits from the realworld disparity in the clients. Our proposed approach to
client selection has a synergic effect when applied together
with ordered learning in FL.

1. Introduction
Inspired by the learning principle underlying the cognitive process of humans, curriculum learning (CL) generally
proposes a training paradigm for machine learning models in which the difficulty of the training task is progressively scaled, going from ”easy” to ”hard”. Prior empirical
studies have demonstrated that CL is effective in avoiding
bad local minima and in improving the generalization results [1,2]. Also interestingly, another line of work proposes
the exact opposite strategy of prioritizing the harder exam-

2

Czech Technical University

3

UCF

ples first, such as [3–5]–these techniques are referred to as
“anti-curriculum”. It is shown that certain tasks can benefit
from anti-curriculum techniques. However, in tasks such as
object detection [6,7], and large-scale text models [8] CL is
standard practice.
Although the empirical observations on CL appear to be
in conflict, this has not impeded the study of CL in machine learning tasks. Certain scenarios [9] have witnessed
the potential benefits of CL. The efficacy of CL has been explored in a considerable breadth of applications, including,
but not limited to, supervised learning tasks within computer vision [10], healthcare [11], reinforcement learning
tasks [12], natural language processing (NLP) [13] as well
as other applications such as graph learning [14], and neural
architecture search [15].
Curriculum learning has been studied in considerable
depth for the standard centralized training settings. However, to the best of our knowledge, our paper is the first
attempt at studying the methodologies, applications, and efficacy of CL in a decentralized training setting and in particular for federated learning (FL). In FL, the training time
budget and the communication bandwidth are the key limiting constraints, and as demonstrated in [9] CL is particularly effective in settings with a limited training budget. It
is an interesting proposition to apply the CL idea to an FL
setting, and that is exactly what we explore in our paper (in
Section 2).
The idea of CL is agnostic to the underlying algorithms
used for federation and hence can be very easily applied to
any of the state-of-the-art solutions in FL. Our technique
does not require a pre-trained expert model and does not
impose any additional synchronization overhead on the system. Also, as the CL is applied to the client, it does not add
any additional computational overhead to the server.
Further, we propose a novel framework for efficient
client selection in an FL setting that builds upon our idea
of CL in FL. We show in Section 4, CL on clients is able
to leverage the real-world discrepancy in the clients to its
advantage. Furthermore, when combined with the primary
idea of CL in FL, we find that it provides compounding ben-

efits.
Contributions: In this paper, we comprehensively assess the efficacy of CL in FL and provide novel insights into
the efficacy of CL under the various conditions and methodologies in the FL environment.
We provide a rigorous convergence theory and analysis
of FL in non-IID settings, under strongly convex and nonconvex assumptions, by considering local training steps as
biased SGD, where CL naturally grows the bias over the
iterations, in Section 5 of the main paper and Section 2 of
the Supplementary Material (SM).
We hope to provide comprehensible answers to the
following six important questions:
Q1: Which of the curriculum learning paradigm is effective
in FL? And under what conditions?
Q2: Can CL alleviate the statistical data heterogeneity in
FL?
Q3: Does the efficacy of CL in FL depend on the underlying
client data distributions?
Q4: Whether the effectiveness of CL is correlated with the
size of datasets owned by each client?
Q5: Are there any benefits of smart client selection? And
can CL be applied to the problem of client selection?
Q6: Can we apply the ideas of CL to both the client data
and client selection?
We test our ideas on two widely adopted network
architectures on popular datasets in the FL community
(CIFAR-10, CIFAR-100, and FMNIST) under a wide range
of choices of curricula and compare them with several
global state-of-the-art baselines. We have the following
findings:
• CL in FL boosts the classification accuracy under
both IID and Non-IID data distributions (Sections 3.1,
and 3.2).
• The efficacy of CL is more pronounced when the client
data is heterogeneous (Section 3.3).
• CL on client selection has a synergic effect that compounds the benefits of CL in FL (Section 4).
• CL can alleviate data heterogeneity across clients and CL
is particularly effective in the initial stages of training as
the larger initial steps of the optimization are done on the
“easier” examples which are closer together in distribution (Section 5 of main paper, and Section 2 of the SM).
• The efficacy of our technique is observed in both lower
and higher data regimes (Section 3 of the SM).

2. Curriculum Components
Federated Learning (FL) techniques provide a mechanism to address the growing privacy and security concerns
associated with data collection, all-the-while satiating the

need for large datasets for training powerful machine learning models. A major appeal of FL is its ability to train a
model over a distributed dataset without needing the data
to be collated into a central location for training. In the
FL framework, we have a server and multiple clients with
a distributed dataset. The process of federation is an iterative process that involves multiple rounds of back-and-forth
communication between the server and the clients that participate in the process [?]. This back-and-forth communication incurs a significant communication overhead, thereby
limiting the number of rounds that are pragmatically possible in real-world applications. Curriculum learning is an
idea that particularly shines in these scenarios where the
training time is limited [9]. Motivated by this idea, we define a curriculum for training in the federated learning setting. A curriculum consists of three key components:
The scoring function: It is a mapping from an input sample, xi ∈ D = {(x1 , y1 ), (x2 , y2 ), ..., (xn , yn )}, to a numerical value, si (xi ) ∈ R+ . We define a range of scoring
functions when defining a CL for the FL setting in the subsequent sections. When defining the scoring function of a
curriculum in FL, we look for loss-based dynamic measures
for the score that update every iteration, unlike the methods proposed in [16] which produce a fixed score for each
sample. This is because the instantaneous score of samples changes significantly between iterations, and using a
fixed score leads to an inconsistency in the optimization objectives, making training less stable [17]. Also, we avoid
techniques like [18] which requires human annotators, as it
is not practical in a privacy-preserving framework.
The pacing function: The pacing function gλ (t) determines scaling of the difficulty of the training data introduced to the model at each of the training steps t and it
selects the highest scoring samples for training at each step.
The pacing function is parameterized by λ = (a, b) where
a is the fraction of the training budget needed for the pacing
function to begin sampling from the full training set and b
represents the fraction of the training set the pacing function exposes to the model at the start of training. In this paper, the full training set size and the total number of training steps (budget) are denoted by N and T , respectively.
Further, we consider five pacing function families, including exponential, step, linear, quadratic, and root (sqrt). The
expressions we used for the pacing functions are shown in
Table 5 of the SM. we follow [19] in defining the notion
of pacing function and use it to schedule how examples are
introduced to the training procedure.
The order: Curriculum learning orders sample from the
highest score (easy ones) to lowest score, anti-curriculum
learning orders from lowest score to highest, and finally,
random curriculum randomly samples data in each step regardless of their scores.

Algorithm 1: The Curriculum FL Framework

Server executes:
initialize f with θ
for each round t = 0, 1, 2, ... do
St ← (random set of K clients)
for each client m ∈ St in parallel do
broadcast θgt to clients
(t)
(t)
θm ← ClientUpdate(m, θg )
PK
(t+1)
(t)
|Dm |
= m=1 PK
θg
θm {}Dm is the set of
i=1 |Di |
the local data on the client with index m.
return θgt+1

Figure 1. Scoring client samples based on the global model (sG ) provides the most accurate scores for all levels of Non-IIDness. Scoring
) provides the least accurate scores,
based on the local model (spred
L
especially when data are Non-IID, as it provides the worst accuracy.
Evaluating the effect of using different scoring methods on accuracy when
the clients employ curriculum, anti-curriculum, or random ordering during their local training on CIFAR-10 with IID data (left) and Non-IID
(2) (right). All curricula use the linear pacing function with a = 0.8
and b = 0.2. We run each experiment three times for 100 communication rounds with 10 local epochs and report the mean and standard deviation (std) for global test accuracy. Note that the results for vanilla FedAvg
for the left figure, and the right one are 52.30 ± 0.86, and 41.96 ± 1.77,
respectively.

ClientUpdate (m, θgt ):
t
Obtain the score of each data sample using θgt and/or θm
as described in section 3.1
(x1 , x2 , ..., xn ) ← sort({x2 , ..., xn }, s, o)
for t = 1, 2, ..., T do
t
θm
← train(θgt , {x1 , x2 , ..., xg(t) })

3. Experiment
Experimental setting. To ensure that our observations are
robust to the choice of architectures, and datasets, we report
empirical results for LeNet-5 [20] architecture on CIFAR10 [21] and Fashion MNIST (FMNIST) [22], and ResNet9 [23] architecture for CIFAR-100 [21] datasets. All models
were trained using SGD with momentum. Details of the
implementations, architectures, and hyperparameters can be
found in Section 7 of the SM.
Baselines and Implementation. To provide a comprehensive study on the efficacy of CL on FL setups, we consider
the predominant approaches to FL that train a global model,
including FedAvg [24], FedProx [25], SCAFFOLD [26],
and FedNova [27]. In all experiments, we assume 100
clients are available, and 10% of them are sampled randomly at each round. Unless stated otherwise, throughout
the experiments, the number of communication rounds is
100, each client performs 10 local epochs with a batch size
of 10, and the local optimizer is SGD. To better understand
the mutual impact of different data partitioning methods
in FL and CL, we consider both federated heterogeneous
(Non-IID) and homogeneous (IID) settings. In each dataset
other than IID data partitioning settings, we consider two
different federated heterogeneity settings as in [?,28]: NonIID label skew (20%), and Non-IID Dir(β).

50
curr
anti
rand

45
40
sG

sGPred

Pred
sLG

sL

Scoring Functions

sLPred

Accuracy

45

Input: M clients indexed by m, sampling rate R ∈ (0, 1],
participating-client number K, communication rounds RC ,
server model f with θg , pacing function gλ : [T ] →
[N ], scoring function s : [N ] → R, order o ∈
{”curriculum”, ”anti”, ”random”},

Accuracy

55

40
curr
anti
rand

35
30
sG

sGPred

Pred
sLG

sL

Scoring Functions

sLPred

3.1. Effect of scoring function in IID and Non-IID
FL
In this section, we investigate five scoring functions. As
discussed earlier, in standard centralized training, samples
are scored using the loss value of an expert pre-trained
model. Given a pre-trained model fθ : X → Y, the score is
defined as si (xi ) = Priri , where ri = L(yi ,f1θ (xi )) , with L
i
being the inference loss. In this setup, a higher score corresponds to an easier sample.
In FL [?, 24], a trusted server broadcasts a single initial
global model, θg , to a random subset of selected clients in
each round. The model is optimized in a decentralized fashion by multiple clients who perform some steps of SGD updates (θk = θg − η∇Lk ). The resulting model is then sent
back to the server, ultimately converging to a joint representative model. With that in mind, in our setting, the scores
can be obtained by clients either via the global model that
they receive from the server, which we name as sG or by
their own updated local model, named as sL or the score
can be determined based on the average of the local and
global model loss, named as sLG 1 .
We further consider another family of scoring that is
based on ground truth class prediction. In particular, in each
round, clients receive the global model from the server and
get the prediction using the received global model and the
current local model as ŷG and ŷL , respectively. For those
samples whose ŷL and ŷG do not match, the client tags them
as hard samples and otherwise as easy ones. This scoring
method is called spred
LG . Further, ground truth class prediction and scoring can be solely done by the global model or
the client’s local model, which end up with two other differpred
ent scoring methods, namely spred
respectively.
G , and sL
This procedure is described in Algorithm 1.
Fig. 1 demonstrates what the impact of using these var1 Since it produces very similar results to s

G , we skipped it.

3.2. Effect of pacing function and its parameters in
IID and Non-IID FL
In order to study the effect of different families of pacing functions along with the hyperparameters λ = (a, b),
we test the exponential, step, linear, quadratic, and root
function families. We further first fix b to 0.2 and let
a ∈ {0.1, 0.5, 0.8}2. The accuracy results are presented
in Fig. 2. It is noteworthy that the complement of this
figure for Non-IID is presented in Fig. 12 in the SM. As
is evident, for all pacing function families, the trends between the curriculum and the other orderings, i.e., (anti,
random)-curriculum are markedly opposite in how they improve/degrade by sweeping a from small values to large
ones. The pattern for Non-IID which presented in the SM
is almost similar to that of IID. Values of a ∈ [0.5, 0.8] produce the best results. As can be seen from Fig. 2, the best
accuracy achieved by curriculum learning outperforms the
best accuracy obtained by other orderings by a large margin. For example, in the “linear” pacing function, the best
accuracy achieved for curriculum learning when a = 0.8
is 56.60 ± 0.91 which improved the vanilla results by 4%
while that of random when a = 0.1 is 52.73 ± 0.81 and improved vanilla by 0.5%. Henceforth, we set a = 0.8 and the
pacing function to linear. After selecting the pacing function and a the final step is to fix these two and see the impact
of b. Now we let all curricula use the linear pacing functions
with a = 0.8 and only sweep b ∈ {0.0025, 0.1, 0.2, 0.5, 0.8}
2 Note that b ∈ [0, 1]. Also, a = 0 or b = 1 is equivalent to no ordered
training, i.e., standard training.

Figure 2. Bigger a values provide better accuracy performance for all
pacing function families on IID settings for curriculum learning. But
a notable contrast can be seen with random-/anti ordering. The effect
of using different pacing function families and their hyperparameter a on
accuracy when the clients employ curriculum, anti-curriculum or random
ordering during their local training on CIFAR-10 with IID data. We run
each experiment three times for 100 communication rounds with 10 local
epochs and report the mean and std for global test accuracy. The figures
from left to right are for curriculum, random, and anti ones.
0.0025

0.2

0.1

0.5

0.8

55

Accuracy

Accuracy

ious scoring methods is on the global accuracy when curriculum, anti-curriculum, or random ordering is exploited
by the clients in the order in which their CIFAR-10 examples are learned with FedAvg under IID and Non-IID (2)
data partitions. The results are obtained by averaging over
three randomly initialized trials and calculating the standard
deviation (std).
The results reveal that first, the scoring functions are
producing broadly consistent results except for spred
for
L
both IID and Non-IID and sL for Non-IID settings. sG provides the most accurate scores, thereby improving the accuracy by a noticeable margin compared to its peers. This
is quite expected, as the global model is more mature compared to the client model, second, the curriculum learning
improves the accuracy results consistently across different
scoring functions, third, curriculum learning is more effective when the clients underlying data distributions are NonIID. To ensure that the latter does not occur by chance, we
will delve into this point in detail in subsection 3.3. Due to
the superiority of sG relative to others, we set the scoring
function to be sG henceforth. We will further elaborate on
the precision of sG compared to an expert model in Section 4.4.

50
45
40

curr

anti

rand

0.0025

0.2

0.1

0.5

0.8

45
40
35
30
25

curr

anti

rand

Ordering
Ordering
Figure 3. Smaller b values provide better accuracy performance for
both IID and Non-IID settings as further corroborate the benefit of
employing curriculum learning. Evaluating the effect of hyperparameter b on accuracy when the clients employ curriculum, anti-curriculum,
or random ordering during their local training on CIFAR-10 with IID for
FedAVg (left), and with Dir(0.05) for FedAvg (right). All curricula use the
linear pacing functions with a = 0.8. We run each experiment three times
for 100 communication rounds with 10 local epochs and report the mean
and std for global test accuracy.

and report the results in Fig. 3. Perhaps most striking is
that curriculum learning tends to have smaller values of b to
improve accuracy, which is in contrast with (random-/anti)
orderings. The performance of anti-curriculum shows a significant dependence on the value of b. Further, curriculum
learning provides a robust benefit for different values of b
and it beats the vanilla FedAvg by 4 − 7% depending upon
the distribution of the data. Henceforth, we fix b to 0.2.

3.3. Effect of level of data heterogeneity
Equipped with the ingredients explained in the preceding section, we are now in a position to investigate the significant benefits of employing curriculum learning in FL
when the data distribution environment is more heterogeneous. To ensure a reliable finding, we investigate the impact of heterogeneity in four baselines through extensive experiments on benchmark datasets, i.e., CIFAR-10, CIFAR100, and FMNIST. In particular, we distribute the data between clients according to Non-IID Dir(β) defined in [29].
In Dir(β), heterogeneity can be controlled by the parameter
β of the Dirichlet distribution. Specifically, when β → ∞
the clients’ data partitions become IID, and when β → 0
they become extremely Non-IID.
To understand the relationship between the ordering-

Table 1. Curriculum-learning helps more when training with more

Table 4. Curriculum-learning helps more when training with more

severe data heterogeneity across clients. Understanding the benefit of
ordered learning with increasing data heterogeneity (β = 0.9 → 0.05)
when clients are trained on CIFAR-10 with FedAvg method.

severe data heterogeneity across clients. Understanding the benefit of
ordered learning with increasing data heterogeneity (β = 0.9 → 0.05)
when clients are trained on CIFAR-10 with SCAFFOLD method.

Non-IIDness

Curriculum

Anti

Random

Vanilla

Non-IIDness

Curriculum

Anti

Random

Vanilla

Dir(β = 0.05)

46.34 ± 1.55

31.16 ± 3.16

41.91 ± 2.23

39.56 ± 4.91

Dir(β = 0.05)

45.91 ± 1.17

21.29 ± 1.82

38.27 ± 2.19

41.33 ± 1.30

Dir(β = 0.2)

51.09 ± 0.39

42.34 ± 1.48

46.35 ± 1.44

46.75 ± 0.72

Dir(β = 0.2)

49.69 ± 1.81

28.69 ± 0.60

45.29 ± 1.93

46.62 ± 0.58

Dir(β = 0.9)

55.36 ± 0.69

46.86 ± 0.35

52.42 ± 0.90

52.19 ± 0.73

Dir(β = 0.9)

52.05 ± 1.14

30.75 ± 0.79

49.25 ± 0.76

50.24 ± 0.57

Table 2. Curriculum-learning helps more when training with more

4. Curriculum on Clients

severe data heterogeneity across clients. Understanding the benefit of
ordered learning with increasing data heterogeneity (β = 0.9 → 0.05)
when clients are trained on CIFAR-10 with Fedprox method.

The technique of ordered learning presented in previous sections is designed to exploit the heterogeneity of data
at the clients but is not geared to effectively leverage the
heterogeneity between the clients that, as we discuss further, naturally emerges in the real world.
In the literature, some recent works have dabbled with
the idea of smarter client selection, and many selection criteria have been suggested, such as importance sampling,
where the probabilities for clients to be selected are proportional to their importance measured by the norm of update [31], test accuracy [32]. The [33] paper proposes client
selection based on local loss where clients with higher loss
are preferentially selected to participate in more rounds of
federation, which is in stark contrast to [34] in which the
clients with a lower loss are preferentially selected. It’s
clear from the literature that the heterogeneous environment in FL can hamper the overall training and convergence
speed [35, 36], but the empirical observations on client selection criteria are either in conflict or their efficacy is minimal. In this section, inspired by curriculum learning, we try
to propose a more sophisticated mechanism of client selection that generalizes the above strategies to the FL setting.

Non-IIDness

Curriculum

Anti

Random

Vanilla

Dir(β = 0.05)

47.94 ± 0.96

36.08 ± 1.52

42.62 ± 0.35

41.48 ± 0.29

Dir(β = 0.2)

50.02 ± 0.15

40.92 ± 0.90

46.41 ± 1.12

46.18 ± 0.90

Dir(β = 0.9)

56.48 ± 0.18

48.37 ± 0.91

51.69 ± 0.40

53.07 ± 1.25

Table 3. Curriculum learning helps more when training with more
severe data heterogeneity across clients. Understanding the benefit of
ordered learning with increasing data heterogeneity (β = 0.9 → 0.05)
when clients are trained on CIFAR-10 with FedNova method.
Non-IIDness

Curriculum

Anti

Random

Vanilla

Dir(β = 0.05)

43.73 ± 0.09

28.31 ± 1.93

37.81 ± 3.06

31.97 ± 0.90

Dir(β = 0.2)

47.01 ± 1.89

36.55 ± 1.42

44.21 ± 1.00

41.28 ± 0.30

Dir(β = 0.9)

50.74 ± 0.19

41.76 ± 0.90

48.87 ± 0.88

47.230 ± 1.80

based learning and the level of statistical data heterogeneity,
we ran all baselines for different Dirichlet distribution β values β ∈ {0.05, 0.2, 0.9}. The accuracy results of different
baselines on CIFAR-10 while employing (anti-) curriculum,
or random learning with linear pacing functions (0.8, 0.2)
and using sG are presented in Tables 1, 2, 3, and 4. For the
comprehensiveness of the study, we will present results for
CIFAR-100 respectively in Section 5 of the SM.
The results are surprising: The benefits of ordered
learning are more prominent with increased data heterogeneity. The greater the distribution discrepancy between clients, the greater the benefit to curriculum learning.
If we consider client heterogeneity as distributional skew
[30], then this is logical: easier data samples are those with
overall lower variance, both unbiased and skew from the
mean, and thus the total collection of CL-easier data samples in a dataset is more IID than the alternative. Thus,
in the crucial early phases of training, the training behaves
closer to FedAvg/FedProx/SCAFFOLD/FedNova under IID
distributions. Therefore, CL can alleviate the drastic accuracy drop when clients’ decentralized data are statistically
heterogeneous, which comes from stable training from IID
samples to Non-IID ones, fundamentally improving the accuracy. This is formalized with quantitative convergence
rates in the Section 5 of the main paper and in Section 2 of
the SM.

4.1. Motivation
In the real world, the distributed dataset used in FL is
often generated in-situ by clients, and the data is measured/generated using a particular sensor belonging to the
client. For example, consider the case of a distributed image
dataset generated by smartphone users using the onboard
camera or a distributed medical imaging dataset generated
by hospitals with their in-house imaging systems. In such
scenarios, as there is a huge variety in the make and quality of the imaging sensors, the data generated by the clients
is uniquely biased by the idiosyncrasies of the sensor, such
as the noise, distortions, quality, etc. This introduces variability in the quality of the data at clients, in addition to the
Non-IID nature of the data. However, it is interesting to
note that these effects apply consistently across all the data
at the specific client.
From a curriculum point of view, as the data points are
scored and ordered by difficulty, which is just a function of
the loss value of that data point, these idiosyncratic distortions uniformly affect the loss/difficulty value of all the data
at that particular client. Also, it is possible that the difficulty

(a) IID

(b) Dir(0.2)

(c) Dir(0.05)

(a) IID

(b) Dir(0.2)

(c) Dir(0.05)

Figure 4. Consistency in data difficulty at the client hurts the effi-

Figure 5. Client curriculum does not suffer from low heterogeneity

cacy of curricula. The effect of consistency in the difficulty distribution
at the client nullifies the effect of curricula. The values plotted are for FedAvg on CIFAR-10. The standard deviation values of (Low, High) consistency for the IID are (0.52, 0.01), Dir(0.2) are (0.51, 0.14), and Dir(0.05)
are (0.50, 0.13). Note that we use Algorithm 2 to construct partitions
with varying difficulty, and as detailed in Section 4.3 it is not possible
to control the partition difficulty value with arbitrary precision, hence the
above minor variations. The Low consistency scenario is generated using
ford = 0.0 and the high consistency scenario uses ford = 1.0.

in the data difficulty and is effective when data curriculum is not. The
scenario shown here is the same as the scenario with high local consistency
from Fig 4. As we observe the client curriculum is able to overcome the
limitations of the data curriculum.

among the data points at the particular client is fairly consistent as the level of noise, quality of the sensor, etc. are
the same across the data points. This bias in difficulty varies
between clients but is often constant within the same client.
Naturally, this introduces a heterogeneity in the clients participating in the federation. In general, this can be thought
of as some clients being ”easy” and some being ”difficult”.
We can quantify this notion of consistency in difficulty by
the standard deviation in the score of the data points at the
client.
When the standard deviation of the intra-client data is
low, i.e., when the difficulty of the data within a client
is consistent, we find that the curriculum on FL behaves
very differently in these kinds of scenarios. We observe
the advantage of curriculum diminishes significantly and
has similar efficacy as that of random curricula as shown
in Fig 4. The advantage of curriculum can be defined
as Ao = accuracy(o) − accuracy(vanilla), where o ∈
{curr, anti, rand}.

4.2. Client Curriculum
We propose to extend the ideas of curriculum onto the
set of clients, in an attempt to leverage the heterogeneity
in the clients. To the best of our knowledge, our paper is
the first attempt to introduce the idea of curriculum on
clients in an FL setting. Many curricula ideas can be
neatly extended to apply to the set of clients. In order to
define a curriculum over the clients, we need to define a
scoring function, a pacing function, and an ordering over
the scores. We define the client loss as the mean loss of the
local data points at the client (Eq. 1), and the client score
can be thought of as inversely proportional to the loss. The
ordering is defined over the client scores.
Lk =

kDm k

X
1
lj
kDm k j

(1)

where m is the index for client, Dm represents the dataset

at client m, lj is the loss of jth data point in Dm .
The pacing function, as in the case of data curricula, is
used to pace the number of clients participating in the federation. Starting from a small value, the pacing function
gradually increases the number of clients participating in
the federation. The action of the pacing function amounts
to scaling the participation rate of the clients.
The clients are scored and rank-ordered based on the
choice of ordering, then a subset of size K (t) of the K
clients is chosen in a rank-ordered fashion. The value K (t)
is prescribed by the pacing function. The K (t) clients are
randomly batched into mini-batches of clients. These minibatches of clients subsequently participate in the federation
process. Thereby, we have two sets of curricula, one that
acts locally on the client data and the other that acts on the
set of clients. Henceforth we will refer to these as the data
curriculum and the client curriculum, respectively. We study the interplay of these curricula in Section 4.5.
Fig. 5 confirms that the benefits of the algorithm severely
depend on the data of the client having a diverse set of difficulties. As is evident from Fig. 5, we are able to realize
an Acurr of 5.67 − 7.19% for the different values of NonIIDness using our proposed client curriculum algorithm in
the scenario with high consistency in the client data where
the data curriculum has reduced/no benefits. This illustrates
that the client curriculum is able to effectively overcome the
limiting constraint of local variability in data and is able to
leverage the heterogeneity in the set of clients to its benefit.

4.3. Difficulty based partitioning
For the experiments in this section, we require client
datasets (Dm ) of varying difficulty at the desired level of
Non-IIDness. In order to construct partitions of varying
difficulty, we need to address two key challenges: one, we
need a way to accurately assess the difficulty of each of the
data points, and two, we need to be able to work with different levels of Non-IIDness. To address the first challenge,
we rank the data points in order of difficulty using an a priori trained expert model θE that was trained on the entire
baseline dataset and has the same network topology as the

global model. As the expert model has the same topology
as the model that we intend to train and as it is trained on
the entire dataset, it is an accurate judge of the difficulty of
the data points. Interestingly, this idea can be extended to
be used as a scoring method for curriculum as well. We call
this scoring method the expert scoring sE . We look at this
in greater detail in Section 4.4.
To address the second challenge, a possible solution is to
first partition the standard dataset into the desired Non-IID
partitions using well-known techniques such as the Dirichlet distribution, followed by adding different levels of noise
to the samples of the different data partitions. This would
partition with varying difficulty; however, doing so would
alter the standard baseline dataset, and we would lose the
ability to compare the results to known baseline values and
between different settings. We would like to be able to compare our performance results with standard baselines, so we
require a method that does not alter the data or resort to
data augmentation techniques, and we devise a technique
that does just that.
Starting with the baseline dataset, we first divide it into
the desired Non-IID partitions the same as before, but then
instead of adding noise to the dataset, we attempt to reshuffle the data among partitions in such a way that we create ”easy” partitions and ”hard” partitions. This can be
achieved by ordering the data in increasing order of difficulty and distributing the data among the partitions starting
from the ”easy” data points, all the while honoring the NonIID class counts of each of the partitions as determined by
the Non-IID distribution. The outline is detailed in Algorithm 2. It is noteworthy that, although we are able to generate partitions of varying difficulty, we do not have direct
control over the ”difficulty” of each of the partitions and
hence cannot generate partitions with an arbitrary distribution of difficulty as can be done by adding noise.

Algorithm 2: Partition Difficulty Distribution
Input: partitions {P0 , P1 , ..., PN } of the input dataset D of
C classes indexed by c, fraction of each partition to replace
ford ∈ (0, 1], expert model θE
Class prior of partitions and dataset:
for each partition i = 0, 1, 2, ..., N do
Pi ← count(data points of class c in partition i)
Compute loss (L) for each data point in D using θE
Dc ← argsort(Lc )
Reconstitute partition:
idc = cumsumi (Ni,c )
Distribute ford
for each partition i = 0, 1, 2, ..., N do
Pi ← Pi ∪ partition(ford ∗ Ni,c elements of Dc beginning at idi,c )
D′ c ← remaining elements of Dc
Distribute remaining (1 − ford )
for each partition i = 0, 1, 2, ..., N do
Pi ← Pi ∪ random((1 − ford ) ∗ Ni,c elements of D′ c )

(a) Client curriculum

(b) Data curriculum

Figure 6. Effect of expert scoring sE and sG on ”curr” curriculum.
Plotted here is the evolution of the global model’s accuracy over the course
of federation for β ∈ {0.05, 0.2} and IID with an ordering of ’curr’, using
FedAvg. sG and sE scoring functions have similar behavior on the Client
Curricula (Left) and Data Curricula (Right).

4.4. Expert guided and self-guided curricula
The scoring method sE , as discussed above, can also be
used to guide the learning process in a curriculum learning
setting. As the expert model used for scoring shares the
same network topology as the global model that we intend
to train, and as the expert was trained on the entire dataset,
the expert-guided curricula can be thought of as a pedagogical mode of learning.
The global model accuracy at different rounds of federation is depicted in Fig. 6. We see a clear trend in Fig 6
that sE outperforms sG in the initial rounds, but sG converges to sE over the rounds. Also, sG accuracy in the initial rounds very closely approximates the random scoring
accuracy. The sG scoring method is a self-guided curriculum, that uses the global model. The global model is just
random (noisy) in the initial rounds of federation, and hence
the curricula it produces are also random, thereby closely

Figure 7. Synergic Effect of Client and Data curricula. CC here refers
to Client Curriculum and DC refers to Data Curriculum. The figure shows
the synergic effects of the curricula.

approximating the performance of the random curriculum.
As the global model is refined over time, it becomes better at determining the ”true” curricula, eventually converging on the sE curve. The model trained with sE benefits
from curriculum effects from the first round and thus starts
strong.

4.5. Ablation study
In this section, we show the interplay between the
data curriculum and the client curriculum
and measure their contributions towards the global model’s
accuracy.
As reported in Fig 7, we observe that
the client curriculum and the data curriculum independently outperform the baseline by about 2 − 3%, and
we observe a synergic effect of the combination that outperforms both the curricula and the baseline by about 5%.

5. Theoretical Analysis and Convergence
Guarantees
Now we attempt to analytically motivate the improved
performance of CL in general, and for heterogeneous data
in particular.
Convergence Rate Advantages of Curriculum Learning
Consider a standard loss function of the least squares form,
N
1 X
L(θ, {xi , yi }) =
(f (θ, xi ) − yi )2
2N i=1
Compute the generic form of the Hessian,
N
1 X
∇2θθ L(θ, {xi , yi }) =
∇θ f (θ, xi )∇θ f (θ, xi )T
N i=1

+∇2θθ f (θ, xi )(f (θ, xi ) − yi )

Note that the Fisher information matrix, or GaussNewton term ∇θ f (θ, xi )∇θ f (θ, xi )T is expected to be positive definite and independent of each samples loss value,
however, the greater the magnitude of the overall loss
(f (θ, xi )−yi ) the greater the potential influence of the Hessian of the neural network model ∇2θθ f (θ, xi ) on the overall
Hessian of the objective function. Thus, inherently, curriculum training makes the initial objective function more
convex than otherwise. This has the clear consequence of
enabling faster optimization trajectories at the beginning of
the training process.
Distribution Skew and Heterogeneous Data. Formally, in
terms of the optimization landscape and criteria, the presence of Non-IID data is often modeled in terms of the quantitative features of the appropriate model in a purely deterministic sense, a different minimizer, etc. Distributionally,
however, one can observe, see e.g. [30], that data discrepancy across clients is often manifested as skew. Skew is the
third moment of a random variable that indicates that there
is a preferential direction in the uncertainty. As an example,
image data is distributed across clients by giving the left division of an image—e.g., the left face of a cat—to one client
and the right to another. See Fig. 8 for an illustration.
A simple and transparent way to model this is to use the
biased SGD framework. Specifically, there is an underlying objective function of interest f (x), however, each client
only has access to a biased stochastic gradient of this function. Uniquely in the case we consider and model, the bias

Figure 8. Illustration of skew-based heterogeneous data distribution across clients and curriculum learning mitigation thereof.

adds up to zero across clients. We shall use the notation
of [37] although for completeness we acknowledge the predecessor [38]. To the best of our knowledge, we present
the first analysis of federated averaging with heterogeneous
data using the biased SGD framework, despite how naturally it models the training procedure given standard distributional patterns in splitting training data across clients. In
the SM, we develop this model formally and provide quantitative convergence results. Informally, the overall findings
can be summarized as follows:
1. For strongly convex objectives, the bias introduces error to the asymptotic distance to the optimal solution,
the amount of which can be decreased by appropriate annealing stepsizes according to the client or databased CL.
2. For nonconvex objectives with a bounded gradient assumption, it appears that with a sufficiently annealed
stepsize, standard centralized sublinear ergodic rates
of convergence to zero approximate stationarity in expectation can be recovered.

6. Conclusion
In this work, we provided a comprehensive study on the
benefit of employing CL in FL under both homogeneous
and heterogeneous setting. We further ran extensive
experiments on a broad range of curricula and pacing
functions over three datasets, CIFAR10, CIFAR100, and
FMNIST and demonstrated that ordered learning can have
noticeable benefits in federated training. Surprisingly, we
found empirically that CL can be more beneficial when
the clients underlying data distributions are significantly
Non-IID. By studying the convergence behavior of FL
using a novel biased SGD model based on the observation
of data heterogeneity as distributional skew, we were able
to theoretically explain this phenomenon. Moreover, we
proposed curriculum on clients for the first time. Our
results show that the order in which clients are participated

in the federation plays an important role in the accuracy
performance of the global model. In particular, training the
global model in a meaningful order, from the easy clients
to the hard ones, using curriculum learning can provide
performance improvements over the random sampling
approach.

Supplementary Document
The supplementary material is organized as follows:
Section 1 presents preliminaries; Section 2 provides the
convergence of theory; Section 3 studies the effect of the
amount of data that each client owns on its benefit from CL;
in Section 4 additional experiments are provided to evaluate the effect of pacing function and its parameters in IID
and non-IID FL; Section 5 studies the correlation between
the ordering based learning and the level of statistical data
heterogeneity on CIFAR-100; Section 6 presents the related
work to this paper; Section 7 contains implementation details; and finally, Section 6 concludes the paper.

1. Preliminary
The five function families used throughout, including exponential, step, linear, quadratic, and root, and their expressions can be seen in Table 5 and Fig. 9.
Table 5. The five families of pacing functions we employed in this paper.
The parameter a determines the fraction of training time until all data is
used. Parameter b sets the initial fraction of the data used.
Pacing Function

Expression

Exponential
Step
Root (Sqrt)
Linear
Quadratic

(1−b)
aT − 1)
N b + Ne10
−1 (e
t
⌋
N b + N ⌊ aT
√
√ −b t
Nb + N
aT
N −b
N b + aT t
N −b 2
t
N b + (aT
)2

size of data

Curricula, Data Dissimilarity and Convergence The
score of the data samples is based on the server’s parameter vector θg . Naturally, this approach creates a significant
association between the degree of statistical dissimilarity of
the data at each client with the training difficulty score used
to rank data samples for curriculum learning. So we can
safely purport that CL, for non-iid data, results in a level of
dissimilarity that increases with the iteration t.
To understand how this affects the convergence, we review a few standard works and study how increasing heterogeneity with the iteration number affects the convergence
guarantees.
To begin with, the state of the art in convergence theory
of Federated Averaging (or Local SGD) for convex objectives is given, to the best of our knowledge, in [39].
Here the main result of interest is [39, Theorem 5], for
which the objective optimality gap is bounded by,
E[f (θT ) − f (θ∗ )] ≤

bN

step

αT

T

Figure 9. Pacing function curves of different families are used throughout the paper. As shown, the hyperparameter α specifies the fraction of
the training step until all data is used in training. The hyperparameter b
determines the initial fraction of the data used in training.

C1
+ C2 γσ 2 + C3 γ 2 σ 2
γT

where the variance σ is proportional to the heterogeneity.
It can be seen from the convergence theory that the bound
changes to, with σt iteration dependent,
E[f (θT ) − f (x∗ )] ≤

exp
linear
quad
root
step

0

In this section, we give a review of the literature on Federated Averaging and the associated convergence guarantees, presenting an analysis of how we expect these to be
modified by the introduction of curriculum learning.

10t

N

0

2. Convergence Theory

T
T
X
X
C1
+ C2 γ
σt2 + C3 γ 2
σt2
γT
t=0
t=0

suggesting an overall better convergence quality for any
given iteration, since we expect σt < σ up until t = T , i.e.,
early iterations generate better accuracy than otherwise.
In regards to nonconvex objectives, which are of course
more faithful to the practice of training neural networks, to
the best of our knowledge the state of the art in theoretical convergence guarantees for local SGD is given in [35].
There, a notion of gradient similarity is presented,

Λ(θ, q) =

M
P

m=1
M
P

qm k∇fm (θ)k2

m=1

2

qm ∇fm (θ)

and assuming a bound λ on this term, λ does not appear directly in the convergence bounds in [35, Theorem 4.2 and
Theorem 4.4] (respectively for the objective satisfying the
PL condition and the general case). However, the number
of local steps, which they denote as E, (i.e. the number

of SGD steps in ClientUpdate in Algorithm 1) depends
on E ∝ 1/λ, meaning the greater the dissimilarity and the
fewer local iterations are permitted to ensure convergence,
a net increase in the total number of communications necessary.
The use of the FedProx objective can also be analyzed
through the lens of iterate-varying dissimilarity. Considering [40, Theorem 4] we have that with,
1
− ρ̄(Bt , γ, µ), ρ̄(Bt , γ, µ) = O(Bt )O(γ)O(1/µ)
µ

ρt =

and, with St devices chosen at iteration t
E[f (xt+1 |St ] − f (xt ) ≤ −ρt k∇f (xt )k2
and thus with Curriculum training, we see increasing Bt and
thus decreasing ρt , and thus, again, we shall expect to see
initial faster and then gradually slower convergence.
Local SGD Model and Convergence Analysis Consider
the Local SGD framework as presented in Algorithm 3.
Algorithm 3: Local SGD Model of Algorithm 1

Server executes:
initialize f with θg
for each round t = 0, 1, 2, ..., T do
St ← (random set of Q clients)
for each client q ∈ St in parallel do
(t,0)
broadcast θgt to clients as θk
for j = 0, 1, 2, ..., J
(t,j)
(t,j)
Sample gk
∼ ∇f (θk , Dk )
(t,j+1)
(t,j)
(t,j) (t,j)
θk
←θ
−α
gk
P k |Dk |
(t+1)
(t,J )
PK
= K
θg
θ
k=1
|D | k

(t,j)

(t,j)

gk

(t,j)

= ∇f (θk
(t,j)

where kbk

(t,j)

(θk

(t,j)

) + bk

(t,j)

) + nk

(t,j)

α(t,j) ≤

(t,j)

(θk

(t,j)

, ξk

)
(2)

is a random variable satisfying,
(t,j)

(t,j)

(θk

(t,j)

, ξk

)] = 0

(t,j)

(θk

)

2

+ σ2

1
4(3 + 2M )L

Then it holds that the distance to the solution satisfies, after
each averaging step,

)k2 ≤ B (t,j) for all k, and, for all θ,
X (t,j)
bk (θ) = 0
(3)

Eξ [nk

(t,j)

) + bk

• For all t, j we have ,

k∈St

and ξk

for data based curriculum training.
Now we present two results as depending on the conditions applying to the functions characterizing the optimization. In the first case, we shall consider strongly convex objectives, as characterizing least squares empirical risk minimization of, e.g., linear models. In this scenario, we permit
the variance to grow with the parameter size, i.e., we do not
assume bounded gradients.

E θ̂(T,0) − θ∗
+

satisfies,

(t,j)

(θk

B (0,0) < B (0,1) < ... = B (0,J) = B (1,0) < B (1,1) < ...
< B (1,J) = B (2,0) < ...B (t,0) < B (t,1) < ...
< B (t,J) = B (t+1,0) < B (t+1,1) < ...
< B (t+1,J) ...B (T,K−1) < B (T,J)

(t,j)

We formalize the notion of distributional skew by making the following assumption on the bias structure associated with each stochastic gradient computation:
Assumption 1 It holds that gk

for client based curriculum training, and

≤ M ∇f (θk

i

i=1

B (0,0) = B (0,1) = ... = B (0,J) < B (1,0) = B (1,1) = ...
= B (1,J) < ... < B (t,0) = B (t,1) = ... = B (t,J) < B (t+1,0)
= B (t+1,1) = ... = B (t+1,J) < ... < B (T,0) = B (T,1)
= ... = B (T,J)

Theorem 1 Assume that
• f is strongly convex with convexity parameter µ > 0
• ∇f is Lipschitz continuous with Lipschitz constant L
• the noise variance satisfies,


2
(t,j) (t,j) (t,j)
Eξ nk (θk , ξk )

Input: M clients indexed by m, participating-client number Q, communication rounds T , local optimization steps
J, server model f with parameters θg

return θgt+1

We note that,

(4)

+

2

≤

T Q
J
Q

t=1 j=0

(1 − α(t,j) µ/2)kθ̂(0,0) − θ∗ k2

T P
J
P
2(α(t,j) )2 [L((3+2M)B (t,j) +3σ3 ]

t=1 j=0
T P
J
P

t=1 j=0

Q

2α(t,j) L(B (t,j) )2 /µ)
Q

In studying the form of this result, we note that the overall
convergence rate and error resembles the original with an
important caveat in regards to the error on account of the
bias term. First, the bias term adds an error proportional
to the stepsize, thus yielding an asymptotic error bounded
from below with the bias. Second, the stepsize can be
used to mitigate the error from the bias terms. Indeed,
with, e.g., data-based curriculum, if B (t,j) = O(j 1/4 ) then

α(t,j) = O(t−1 j −1/4 ) would mitigate the growing error. It
is clear that the standard practice of diminishing stepsizes
will result in a lower total error at each iteration for curriculum compared to anti-curriculum. Standard Local SGD
guarantees are not preserved regardless, however, with the
asymptotic bias depending on the total degree of data heterogeneity, summed in this weighted manner throughout the
optimization procedure.
Nonconvex Objectives Now we consider the general
case of nonconvex objectives without any additional conditions regarding the growth properties of the objective function to permit generality encompassing the functional properties of neural networks. Using the biased SGD framework and inspired by the structure of the convergence theory of [41], we study the effect of the associated gradient
estimate errors.
Theorem 2 Assume that
• k∇f k is uniformly bounded by G
• ∇f is Lipschitz continuous with Lipschitz constant L
• the noise variance satisfies,


2
(t,j) (t,j) (t,j)
Eξ nk (θk , ξk )
≤ σ2
• f is lower bounded by f∗
Then we obtain the ergodic rate,
T P
J
P

t=0 j=0

+2

α(t,j)

α(t,j) +

t=0 j=0

J
P

α(t,l)

l=j

!

LG2

Compared to standard results, we can see that curricula
contributes an error that corresponds to the cross terms of
the stepsizes, indicating a benefit to annealing the stepsize
along local iterations as well as along averaging steps.
Now we present the proofs that build up the argument for
the main new convergence results we present in Section 2,
specifically Theorem 1 and 2.

2.1. Strongly Convex Problems
Lemma 1 The stochastic gradient second moment satisfies:
(t,j) 2

E[kgk

(t,j)

k ] ≤ 2(3 + 2M )L(f (θk ) − f ∗ )
+(3 + 2M )B (t,j) + 3σ 2

Proof. Follows from,
(t,j) 2

1 X (t,j) (t,j)
1 X
(t,j)
gk , ḡ
=
∇f (xk )
|St |
|St |
k∈St

k∈St

Note that Assumption 1, in particular (4) and (4) imply that
(t,j)
E[gk ] = ḡ (t,j) .
The next Lemma is similar to [39, Lemma 5] with a simpler proof of simple adding the terms across agents up using
the previous result.
Lemma 2
2
E[kg (t,k) − ḡ (t,j)
i
h k ]≤
P
2
(t,j)
(3+2M)
∗
(t,j)
+ 3σ
2L(f
(θ
)
−
f
)
+
B
2
k
Q
Q
k∈S (t)

The next Lemma is similar to [39, Lemma 6] which in turn
follows [42, Lemma 2.1]. Consider the sequence,
θ̂(t,j+1) = θ̂(t,j) − α(t,j) g (t,j)

Lemma 3
kθ̂(t,j) − α(t,j) ḡh(t,j) − θ∗ k2 ≤ kθ̂(t,j) − θ∗ k2
P
(t,j)
(t,j)
+ 2αQ
(α(t,j) L − 1/2)(f (θk ) − f (θ∗ ))
k∈S (t)
i
(t,j)
− µ2 kθk − θ∗ k2
P
(t,j)
(t,j)
kθ̂(t,j) − θk k2
+ 2α Q L
k∈S (t)

Finally we obtain our first derivation of expected convergence below.
Lemma 4 Let L̄ := (L + (3 + 2M )2L/Q) and assume
that α(t,j) ≤ 41L̄ . It holds that the expected distance of the
average parameter to the solution satisfies the recursion,
(t,j+1)

(t,j)

(t,j)

(t,j)

k ] ≤ 3k∇f (θk )k2 + 3kbk (θk )k2
(t,j) (t,j) (t,j)
+3E[knk (θk , ξk )k2 ]
(t,j)
≤ (3 + 2M )k∇f (θk )k2 + (3 + 2M )B (t,j) + 3σ 2
(t,j)
≤ 2(3 + 2M )L(f (θk ) − f ∗ ) + (3 + 2M )B (t,j) + 3σ 2
E[kgk

g (t,j) =

and note that by this construction x̂(t,J) = x̂(t+1,0) . The
proof is a straightforward application of strong convexity.
It holds that,

k∇f (θ(t,0) k2 ≤ Q(f (θ0 ) − f ∗ )
T P
J
P

where in the last line we used ∇f (θ∗ ) = 0 and LDefine,
smoothness.


−θ∗ k2 ] ≤ 1 − α(t,j)
µ kθ̂(t,j) − θ∗ k2

(t,j)
−α 2
f (θ̂(t,j) − f (θ∗ )
P
(t,j)
(t,j)
kθ̂(t,j) − θk k2
+ 2α Q L

E[kθ̂k

k∈S (t)
(t,j) 2 (t,j)
) B

+ (3+2M)(αQ

2

(t,j) 2

+ 3σ (αQ

)

Proof. Indeed, compute directly,

Proof. Using the previous set of results,
(t,j+1)

− θ∗ k2 ] ≤ kθ̂(t,j) − α(t,j) ḡ (t,j) − θ∗ k2
+(α(t,j) )2 E[kg (t,j) − ḡ (t,j) k2 ]
(t,j)
≤ kθ̂
− θ ∗ k2 h
P
(t,j)
(t,j)
+ 2αQ
(α(t,j) L − 1/2)(f (θk ) − f (θ∗ ))
(t)
k∈S
i
(t,j)
− µ2 kθk − θ∗ k2
P
(t,j)
(t,j)
kθ̂(t,j) − θk k2
+ 2α Q L
(t)
k∈S
i
(t,j) 2
P h
(t,j)
)
∗
(t,j)
+ (3+2M)(α
2L(f
(θ
−
f
(θ
))
+
B
2
k
Q
E[kθ̂k

2

(t,j) 2


2
− g (t,j)

P  (t,j)
f (θk ) − f (θ∗ )



k∈S (t)
≤ 2(3+2M)L
Q

(t,j)

gk

(5)

k∈S (t)

+(3 + 2M )B (t,j) + 3σ 2

Next we derive a recursion on the average parameter deviation.
Lemma 5 Let µ > 0. The average iterate deviation satisfies the bound,

E

1
Q

P

k∈S (t)

kθ̂

1
Q

P

k∈S (t)
(α(t,j) )2
+ Q

(t,j+1)

≤ (1 − α(t,j) µ/2)E

"

(t,j+1) 2
− θk
k
1
Q

P

#
(t,j) 2

kθ̂(t,j) − θk

#

k


(t,j) 2
P
(t,j)
)
f (θk ) − f (θ∗ )
+ 2(3+2M)L(α
Q
k∈S (t)

+α(t,j) α(t,j) (3+2M )+B (t,j)/µ B (t,j) +3(α(t,j) )2 σ 2
k∈S (t)

kθ̂

(t,j)

P

E

k∈S (t)

(t,j)

(t,j)
− θk k 2

#

#

i
h
(t,j)
E kg (t,j) − gk k2
k∈S (t) hD
Ei
P
(t,j)
(t,j)
E θk − θ̂(t,j) , gk − g (t,j)
P

k∈S (t)

hD

(t,j)

θk

(t,j)

− θ̂(t,j) , gk

− g (t,j)

Ei

E
P D (t,j)
(t,j)
(t,j) (t,j)
θk − θ̂(t,j) , ∇f (θk ) + bk (θk )
k∈S
*(t)
+
h
i
P
P
(t,j)
(t,j)
(t,j)
(t,j)
1
θk −θ̂(t,j) , Q
+
∇f (θk )+bk (θk )
k∈S (t) D
k∈S (t)
E
P
(t,j)
(t,j)
(t,j) (t,j)
θ̂(t,j) − θk , ∇f (θk ) + bk (θk )
=
k∈S (t) h
i
P
(t,j)
(t,j)
≤
f (θ̂(t,j) ) − f (θk ) − µ2 kθk − θ(t,j) k2
k∈S (t)
P
(t,j)
+
B (t,j) kθk − θ(t,j) k
=−

Next, from Lemma 1 we can conclude that

"

(t)

− 2αQ

−

By assumption α(t,j) L̄ − 1/2
≤
− 41 and
then
applying
Jensen’s
inequality
we i have
P h 1
(t,j)
(t,j)
µ
1
∗
∗ 2
−
≤
(f
(θ
)
−
f
(θ
))
−
kθ
−
θ
k
k
k
Q
4
2
(t)
k∈S


Plugging
− 14 (f (θ̂(t,j) ) − f (θ∗ )) + µ2 kθ̂(t,j) − θ∗ k2 .
this expression into the last displayed equation, the
conclusion follows.

E

≤E

"k∈S

(t,j+1) 2
kθ̂(t,j+1) − θk
k

For the second term in the above expression we can apply (5). For the third, we note that,

k∈S (t)
2
(t,j) 2
(3+2M)(α(t,j) )2 B (t,j)
+
+ 3σ (αQ )
Q

P

1
Q

P

k∈S (t)

+ 3σ (αQ )
≤ kθ̂(t,j) − θ∗ k2 h
P
(t,j)
(t,j)
+ 2αQ
(α(t,j) L̄ − 1/2)(f (θk ) − f (θ∗ ))
k∈S (t)
i
(t,j)
− µ2 kθk − θ∗ k2
P
(t,j)
(t,j)
kθ̂(t,j) − θk k2
+ 2α Q L

1
Q

E

"

k∈S (t)

where we used strong convexity in the inequality. Apply(t,j)
ing Young’s inequality to obtain B (t,j) kθk − θ(t,j) k ≤
(t,j)
µ
− θ(t,j) k2 + µ1 (B (t,j) )2 yields the final result.
4 kθk
Now we want to use the previous Lemma in order to bound
the contribution of the average iterate discrepancy to the
overall descent appearing in Lemma 4. Taking a sum for
a given t, for j = 1, ..., J, we can see that

J
P

j=0

E

"

1
Q

P

kθ̂

(t,j)

(t,j)
− θk k 2

k∈S (t)
J
J
Q
P
(t,j)
2α
L
(1 − α(t,l) µ/2)
≤
Q
j=0
l=j
"

2α(t,j) (3 + 2M )L

P 
(t)

#

(t,j)

f (θk


) − f (θ∗ )

k∈S

+ α(t,j) (3 + 2M )+ B (t,j) /µ B (t,j)
+ 3α(t,j) σ 2

With that, we proceed with the main result:

(6)

3. Effect of amount of data on clients end

Proof. of Theorem 1 From Lemma 4 and (6)
J
Q

E[kθ̂(t+1,0) − θ∗ k2 ] ≤

j=0

(1 − α(t,j) µ/2)kθ̂(t,0) − θ∗ k2

J
J
P
Q
2α(t,j) L
(1 − α(t,l) µ/2)
+
Q
j=0
l=j
"

 P  (t,j)
2α(t,j) (3 + 2M )L − 12
f (θk ) − f (θ∗ )
k∈S (t) 
(t,j)
+ 2α
(3 + 2M) + B (t,j) /µ B (t,j)
+ 6α(t,j) σ 2

Noting that the assumption on the Theorem implies that the
term involving the objective value difference is negative, we
obtain the statement of the main result.

In this section, we are interested in understanding
whether the previous conclusions we made for CIFAR10
generalize to both high and low data regimes on the client’s
end. In particular, we divide the larger dataset into multiples of the number of clients and randomly assign M of
those data partitions to the M clients. The larger the number of partitions, the smaller the amount of data on each of
the clients. As can be seen from Fig. 10 the amount of data
that each client owns has no relationship with the benefit
it gains from curriculum learning. In fact, CL ameliorates
the classification accuracy performance equally under both
lower and higher data regimes on the clients’ end.

2.2. Nonconvex Objectives
Proof. of Theorem 2 As standard, we begin by applying
the Descent Lemma across subsequent averaging steps.

k∈S (t) j=0

1
Q

+ L2

J
P P

k∈S (t) j=0

2

(t,j)
α(t,j) gk

(t,j)

1
= Q

k∈S (t) j=0

(t,0)

(t,0)

= Q

k∈S (t)
h j=0

(t,j)

(θ(t,0) ) + ∇f (θ(t,0) , iξk

(t,j)

α

f (θ(t+1,0) ) − f (θ(t,0) ) ≤ −

+

α(t,j)

j=0
J
P

j=0

Accuracy

35

30

30
100

200

400

Partitions

800

25

100

200

400

Partitions

800

client’s end and the benefit they gain from ordered learning. The accuracy decreases when the amount of data each client owns is reduced,
but it gains the same amount of benefit from curriculum learning with
more data. Evaluating the impact of the amount of data each client owns
on the accuracy when the clients employ curriculum, anti-curriculum or
random ordering during their local training on CIFAR-10 with Non-IID
(2) for FedAVg (left), and with Dir(0.05) for Fedprox (right). All curricula
use the linear pacing functions with a = 0.8 and b = 0.2. Each experiment
is repeated three times for a total of 100 communication rounds with ten
local epochs, and the mean and standard deviation for global test accuracy
are reported.

)


α(t,j) ∇f (θ(t,0) )

and so, combining the previous two
J sets of equations,
P
+

40

35

(t,j)
(t,j)
, ξk ) + ∇f (θ(t,j) , ξk )

ii
(t,j)
(t,j)
−E ∇f (θ(t,0) , ξk ) + ∇f (θ(t,j) , ξk )

J
P

45

40

25

rand
vanilla

h
(t,0)
α(t,j) E ∇f (θ(t,0) ) + bk (θ(t,0) )

−f (θ(t,0) ) − bk

− ∇f (θ
J
P P
1

45

curr
anti

Figure 10. There is no correlation between the amount of data on the

Now, we consider the discrepancy of gk to ∇f (θ(t,0) ) to
obtain a perturbation from the decrease we expect to get,
that we wish to eventually bound relative to said decrease.
Specifically, taking total expectations (and implicitly using
" property):
#
the tower
J
P
P
(t,j)
1
E Q
gk
k∈S (t) j=0
J
P P

rand
vanilla

Accuracy

f (θ(t+1,0) ) − f (θ(t,0) ) ≤ ∇f (θ(t,0) ), θ(t+1,0) − θ(t,0)
L
(t+1,0)
− θ(t,0) k2
* + 2 kθ
+
J
P P
1
(t,0)
(t,j) (t,j)
≤ − ∇f (θ
), Q
α
gk

curr
anti

J
P

α(t,l)

l=j

Q

!

j=0

Q

LG2

2

(α(t,j) ) LG2
2Q

from which we obtain the final result.

k∇f (θ(t,0) )k2

4. Effect of pacing function and its parameters
in IID and Non-IID FL
This subsection complements subsection 3.2 of the main
paper, where we evaluated the effect of pacing function and
its hyperparameter a when clients train on CIFAR-10 with
FedAvg under IID data. Here, we report the results for FedAvg under Non-IID Dir(0.05). The conclusion is similar–
Fig. 12 shows that bigger values of a provide better accuracy performance for most of the pacing function families
on both extreme IID and Non-IID setting. It is noteworthy
that, the observations generalize to other baselines, as discussed in different sections of the paper.

45
Dir(0.2)

Non-IIDness

Dir(0.9)

curr
anti
rand
vanilla

45

40
Dir(0.05)

45

50

50

curr
anti
rand
vanilla

50

Dir(0.2)

Non-IIDness

Dir(0.9)

curr
anti
rand
vanilla

45

40
Dir(0.05)

Dir(0.2)

Non-IIDness

Dir(0.9)

Accuracy

Accuracy

Accuracy

50

40
Dir(0.05)

55

55

Accuracy

55

40

curr
anti
rand
vanilla

35

30
Dir(0.05)

Dir(0.2)

Non-IIDness

Dir(0.9)

Figure 11. Curriculum-learning helps more when training with more severe data heterogeneity across clients on CIFAR-100. Test accuracy of
different baselines when sweeping from extremely Non-IID setting, Dir (0.05) to highly IID setting, Dir(0.9). For each baseline, the average of final global
test accuracy is reported. We run each baseline 3 times for 100 communication rounds with 10 local epochs. The figures from left to right, are for FedAvg,
Fedprox, Scaffold, and FedNova baselines.

Figure 12. Bigger a values provide better accuracy performance for
most of pacing function families and on both IID and Non-IID setting for curriculum learning. But a notable contrast can be seen with
random-/anti ordering. The effect of using different pacing function families and their hyperparameter a on the accuracy when the clients employ
curriculum, anti-curriculum or random ordering during their local training
on CIFAR-10 with Non-IID Dir(0.05) data. The figures from left to right
are for curriculum, random, and anti ones.

5. Effect of level of heterogeneity
This subsection complements subsection 3.3 of the main
paper. In this section, we present further experimental
results showing the relationship between ordering-based
learning and the level of statistical data heterogeneity.
Herein, we are interested in investigating whether the previous conclusions we made for CIFAR-10 generalize to other
datasets such as CIFAR-100. Fig. 11 shows the same trend
as in CIFAR-10, i.e., again, we see that as the data from the
clients becomes more heterogeneous, the global model benefits more from curriculum learning, resulting in higher performance accuracy when compared to ”vanilla” and ”anti/random” learning. We provided rigorous analysis to explain this phenomenon.

6. Related Work
Early CL formulated the easy-to-hard training paradigm
in the context of deep learning [1]. CL determines a sequence of training instances, which in essence corresponds
to a list of samples ranked in ascending order of learning
difficulty [2]. Samples are ranked according to per-sample
loss [17]. In the early steps of training, samples with smaller
loss (higher score) are selected, and gradually the subset
size over time is increased to cover all the training data.
[18] proposed to manually sort the samples using human annotators. Self-paced learning (SPL) [2] chooses the curriculum based on hardness (e.g., per-sample loss) during train-

ing. [16] proposes using a consistency score (c-score) calculated based on the consistency of a model in correctly predicting a particular example’s label trained on i.i.d. draws of
the training set. [43] determines the difficulty of learning an
example by the metric of the earliest training iteration, after which the model predicts the ground truth class for that
example in all subsequent iterations.

7. Implementation Details
We begin by splitting the dataset into K partitions, and
these partitions are distributed among the N clients in the
federation. For most experiments M = 100 and the partitions are constructed with an input Non-IID Dirichlet distribution with parameter β and using Algorithm 2 with
ford = 0, unless otherwise specified. The merits of the
Algorithm 2 are detailed in Section 4.3.
At the client, we use an SGD optimizer for training with
an exponentially decaying learning η = η0 (1 + α ∗ i)−b ,
with parameters η0 = 0.001, α = 0.001, b = 0.75 and i is
the step index, and a momentum ρ = 0.9 and weight decay
of ω = 5 ∗ 10−4 . The step count i is a parameter local to the
clients and is reset at the beginning of each federation round
thereby resetting the learning rate back to η0 for each round
of federation. For the ResNet models however, we do not
use the exponential decay learning rate and set b = 0 with
η0 = 0.01, and weight decay ω = 0, due to our observation
that these values empirically work well.
A small batch size of bsdata = 10 is used on the server.
At each client, we use the local epochs nepoch = 10, which,
together with the client data partition size, determines the
number of local steps at the clients between two global
model averaging steps of the federation algorithm. The
number of communication rounds of federation is R = 100
and the client participation rate is f = 0.1, unless otherwise
specified. Similarly, when performing client curriculum, we
use a client batch size of bsclient = 10.
Certain federated learning algorithms require additional
algorithm specific parameters; these are chosen to match
the best values reported by the authors in their respective
papers. For reproducibility of the experiments, we seed our
random number generator with a seed of 202207 at the be-

ginning of each experiment. Each experiment consists of 3
trials, and we report the mean and variance of the results.

References
[1] Yoshua Bengio, Jérôme Louradour, Ronan Collobert, and Jason Weston. Curriculum learning. volume 382, pages 41–48.
ACM, 2009.
[2] Lu Jiang, Deyu Meng, Qian Zhao, Shiguang Shan, and
Alexander G. Hauptmann. Self-paced curriculum learning.
In Blai Bonet and Sven Koenig, editors, Proceedings of
the Twenty-Ninth AAAI Conference on Artificial Intelligence,
January 25-30, 2015, Austin, Texas, USA, pages 2694–2700.
AAAI Press, 2015.
[3] Te Pi, Xi Li, Zhongfei Zhang, Deyu Meng, Fei Wu, Jun Xiao,
and Yueting Zhuang. Self-paced boost learning for classification. In Subbarao Kambhampati, editor, Proceedings of the
Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016, New York, NY, USA, 9-15 July 2016,
pages 1932–1938. IJCAI/AAAI Press, 2016.

[11] Amelia Jiménez-Sánchez, Mickael Tardy, Miguel
Ángel González Ballester, Diana Mateus, and Gemma
Piella. Memory-aware curriculum federated learning for
breast cancer classification. CoRR, abs/2107.02504, 2021.
[12] Zhipeng Ren, Daoyi Dong, Huaxiong Li, and Chunlin Chen.
Self-paced prioritized curriculum learning with coverage
penalty in deep reinforcement learning. IEEE Transactions
on Neural Networks and Learning Systems, 29(6):2216–
2226, 2018.
[13] Yi Tay, Shuohang Wang, Anh Tuan Luu, Jie Fu, Minh C.
Phan, Xingdi Yuan, Jinfeng Rao, Siu Cheung Hui, and Aston
Zhang. Simple and effective curriculum pointer-generator
networks for reading comprehension over long narratives. In
Proceedings of the 57th Conference of the Association for
Computational Linguistics, ACL 2019, Florence, Italy, July
28- August 2, 2019, Volume 1: Long Papers, pages 4922–
4931, 2019.
[14] Chen Gong, Jian Yang, and Dacheng Tao. Multi-modal curriculum learning over graphs. 10(4), 2019.

[4] Xuan Zhang, Gaurav Kumar, Huda Khayrallah, Kenton Murray, Jeremy Gwinnup, Marianna J. Martindale, Paul McNamee, Kevin Duh, and Marine Carpuat. An empirical exploration of curriculum learning for neural machine translation. CoRR, abs/1811.00739, 2018.

[15] Yong Guo, Yaofo Chen, Yin Zheng, Peilin Zhao, Jian Chen,
Junzhou Huang, and Mingkui Tan. Breaking the curse of
space explosion: Towards efficient NAS with curriculum
search. In Proceedings of the 37th International Conference
on Machine Learning, ICML 2020, 13-18 July 2020, Virtual
Event, volume 119, pages 3822–3831. PMLR, 2020.

[5] Xuan Zhang, Pamela Shapiro, Gaurav Kumar, Paul McNamee, Marine Carpuat, and Kevin Duh. Curriculum learning for domain adaptation in neural machine translation.
CoRR, abs/1905.05816, 2019.

[16] Ziheng Jiang, Chiyuan Zhang, Kunal Talwar, and Michael C.
Mozer. Exploring the memorization-generalization continuum in deep learning. CoRR, abs/2002.03206, 2020.

[6] Jihan Yang, Shaoshuai Shi, Zhe Wang, Hongsheng Li, and
Xiaojuan Qi. ST3D: self-training for unsupervised domain
adaptation on 3d object detection. In IEEE Conference on
Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021, pages 10368–10378, 2021.
[7] Enver Sangineto, Moin Nabi, Dubravko Culibrk, and Nicu
Sebe. Self paced deep learning for weakly supervised object detection. IEEE Trans. Pattern Anal. Mach. Intell.,
41(3):712–725, 2019.
[8] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and
Peter J. Liu. Exploring the limits of transfer learning with
a unified text-to-text transformer. J. Mach. Learn. Res.,
21:140:1–140:67, 2020.
[9] Xiaoxia Wu, Ethan Dyer, and Behnam Neyshabur. When do
curricula work? In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May
3-7, 2021, 2021.
[10] Sheng Guo, Weilin Huang, Haozhi Zhang, Chenfan Zhuang,
Dengke Dong, Matthew R. Scott, and Dinglong Huang. Curriculumnet: Weakly supervised learning from large-scale
web images. In Computer Vision - ECCV 2018 - 15th
European Conference, Munich, Germany, September 8-14,
2018, Proceedings, Part X, volume 11214, pages 139–154.
Springer, 2018.

[17] Tianyi Zhou, Shengjie Wang, and Jeff A. Bilmes. Curriculum learning by dynamic instance hardness. In Hugo
Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, MariaFlorina Balcan, and Hsuan-Tien Lin, editors, Advances in
Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020,
NeurIPS 2020, December 6-12, 2020, virtual, 2020.
[18] Anastasia Pentina, Viktoriia Sharmanska, and Christoph H.
Lampert. Curriculum learning of multiple tasks. In IEEE
Conference on Computer Vision and Pattern Recognition,
CVPR 2015, Boston, MA, USA, June 7-12, 2015, pages
5492–5500. IEEE Computer Society, 2015.
[19] Guy Hacohen and Daphna Weinshall. On the power of curriculum learning in training deep networks. In Kamalika
Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings
of the 36th International Conference on Machine Learning,
ICML 2019, 9-15 June 2019, Long Beach, California, USA,
volume 97 of Proceedings of Machine Learning Research,
pages 2535–2544. PMLR, 2019.
[20] Yann LeCun, Bernhard Boser, John S Denker, Donnie
Henderson, Richard E Howard, Wayne Hubbard, and
Lawrence D Jackel. Backpropagation applied to handwritten zip code recognition. Neural computation, 1(4):541–551,
1989.
[21] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple
layers of features from tiny images. 2009.

[22] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashionmnist: a novel image dataset for benchmarking machine
learning algorithms. arXiv preprint arXiv:1708.07747,
2017.

Innovative Applications of Artificial Intelligence, IAAI 2022,
The Twelveth Symposium on Educational Advances in Artificial Intelligence, EAAI 2022 Virtual Event, February 22 March 1, 2022, pages 9091–9099. AAAI Press, 2022.

[23] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pages 770–778, 2016.

[35] Farzin Haddadpour and Mehrdad Mahdavi. On the convergence of local descent methods in federated learning. arXiv
preprint arXiv:1910.14425, 2019.

[24] Brendan McMahan, Eider Moore, Daniel Ramage, Seth
Hampson, and Blaise Aguera y Arcas. Communicationefficient learning of deep networks from decentralized data.
In Artificial Intelligence and Statistics, pages 1273–1282.
PMLR, 2017.
[25] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi,
Ameet Talwalkar, and Virginia Smith. Federated optimization in heterogeneous networks. In Proceedings of Machine
Learning and Systems 2020, MLSys 2020, Austin, March 24, 2020. mlsys.org, 2020.
[26] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri,
Sashank J. Reddi, Sebastian U. Stich, and Ananda Theertha
Suresh. SCAFFOLD: stochastic controlled averaging for
federated learning. In Proceedings of the 37th International
Conference on Machine Learning, ICML, volume 119, pages
5132–5143. PMLR, 2020.
[27] Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and
H. Vincent Poor. Tackling the objective inconsistency problem in heterogeneous federated optimization. In Advances
in Neural Information Processing Systems, volume 33, pages
7611–7623. Curran Associates, Inc., 2020.
[28] Saeed Vahidian, Mahdi Morafah, Weijia Wang, Vyacheslav
Kungurtsev, Chen Chen, Mubarak Shah, and Bill Lin. Efficient distribution similarity identification in clustered federated learning via principal angles between client data subspaces. https://arxiv.org/abs/2209.10526, 2022.
[29] Qinbin Li, Yiqun Diao, Quan Chen, and Bingsheng He. Federated learning on non-iid data silos: An experimental study.
arXiv preprint arXiv:2102.02079, 2021.
[30] Hangyu Zhu, Jinjin Xu, Shiqing Liu, and Yaochu Jin. Federated learning on non-iid data: A survey. Neurocomputing,
465:371–390, 2021.
[31] Wenlin Chen, Samuel Horváth, and Peter Richtárik. Optimal client sampling for federated learning.
CoRR,
abs/2010.13723, 2020.
[32] Ihab Mohammed, Shadha Tabatabai, Ala I. Al-Fuqaha,
Faissal El Bouanani, Junaid Qadir, Basheer Qolomany, and
Mohsen Guizani. Budgeted online selection of candidate iot
clients to participate in federated learning. IEEE Internet
Things J., 8(7):5938–5952, 2021.
[33] Yae Jee Cho, Jianyu Wang, and Gauri Joshi. Client selection
in federated learning: Convergence analysis and power-ofchoice selection strategies. CoRR, abs/2010.01243, 2020.
[34] Sai Qian Zhang, Jieyu Lin, and Qi Zhang. A multi-agent reinforcement learning approach for efficient client selection in
federated learning. In Thirty-Sixth AAAI Conference on Artificial Intelligence, AAAI 2022, Thirty-Fourth Conference on

[36] Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad
Mahdavi. Adaptive personalized federated learning. CoRR,
abs/2003.13461, 2020.
[37] Ahmad Ajalloeian and Sebastian U Stich. On the convergence of sgd with biased gradients. arXiv preprint
arXiv:2008.00051, 2020.
[38] Belhal Karimi, Blazej Miasojedow, Eric Moulines, and HoiTo Wai. Non-asymptotic analysis of biased stochastic approximation scheme. In Conference on Learning Theory,
pages 1944–1974. PMLR, 2019.
[39] Ahmed Khaled, Konstantin Mishchenko, and Peter
Richtárik. Tighter theory for local sgd on identical and heterogeneous data. In International Conference on Artificial
Intelligence and Statistics, pages 4519–4529. PMLR, 2020.
[40] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi,
Ameet Talwalkar, and Virginia Smith. Federated optimization in heterogeneous networks. Proceedings of Machine
Learning and Systems, 2:429–450, 2020.
[41] Fan Zhou and Guojing Cong. On the convergence properties
of a k-step averaging stochastic gradient descent algorithm
for nonconvex optimization. In Proceedings of the 27th International Joint Conference on Artificial Intelligence, pages
3219–3227, 2018.
[42] Sebastian Urban Stich. Local sgd converges fast and communicates little. In ICLR 2019-International Conference on
Learning Representations, number CONF, 2019.
[43] Mariya Toneva, Alessandro Sordoni, Remi Tachet des
Combes, Adam Trischler, Yoshua Bengio, and Geoffrey J.
Gordon. An empirical study of example forgetting during
deep neural network learning. CoRR, abs/1812.05159, 2018.

