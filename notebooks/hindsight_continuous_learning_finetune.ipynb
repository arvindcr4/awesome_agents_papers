{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Learning with Hindsight-Inspired Memory\n",
    "\n",
    "This notebook implements a **self-improving finetuning system** that combines:\n",
    "\n",
    "1. **Hindsight Memory Architecture** - Biomimetic memory with World/Experience/Opinion/Observation types\n",
    "2. **Continuous Learning** - Accumulate learnings from agent interactions over time\n",
    "3. **Periodic Finetuning** - Update the model with accumulated knowledge\n",
    "\n",
    "## Key Concepts from Hindsight\n",
    "\n",
    "| Memory Type | Description | Finetuning Use |\n",
    "|-------------|-------------|----------------|\n",
    "| **World** | Facts about the domain | Base knowledge |\n",
    "| **Experiences** | Agent interactions with outcomes | Training examples |\n",
    "| **Opinions** | Confidence-scored learned beliefs | System prompt tuning |\n",
    "| **Observations** | Derived insights from reflection | Synthetic data generation |\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Agent     â”‚â”€â”€â”€â”€â–¶â”‚   Retain     â”‚â”€â”€â”€â”€â–¶â”‚   Memory Bank   â”‚\n",
    "â”‚ Interaction â”‚     â”‚ (Experience) â”‚     â”‚ (Hindsight)     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                                  â”‚\n",
    "                                                  â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Finetuned â”‚â—€â”€â”€â”€â”€â”‚   Reflect    â”‚â—€â”€â”€â”€â”€â”‚   Recall        â”‚\n",
    "â”‚   Model     â”‚     â”‚ + Generate   â”‚     â”‚   (Memories)    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install together pandas jsonlines numpy openai\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import List, Optional, Dict, Any\n",
    "from enum import Enum\n",
    "import uuid\n",
    "\n",
    "# Set your API keys\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "except:\n",
    "    TOGETHER_API_KEY = os.environ.get('TOGETHER_API_KEY', input(\"Enter Together API key: \"))\n",
    "    OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', input(\"Enter OpenAI API key: \"))\n",
    "\n",
    "os.environ['TOGETHER_API_KEY'] = TOGETHER_API_KEY\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "from together import Together\n",
    "from openai import OpenAI\n",
    "\n",
    "together_client = Together(api_key=TOGETHER_API_KEY)\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "print(\"âœ… Clients configured for Together AI and OpenAI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hindsight Memory Types\n",
    "\n",
    "Implementing the biomimetic memory architecture from Hindsight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryType(Enum):\n",
    "    \"\"\"Hindsight memory types matching the biomimetic architecture.\"\"\"\n",
    "    WORLD = \"world\"         # Facts about the world/domain\n",
    "    EXPERIENCE = \"experience\"  # Agent's own experiences\n",
    "    OPINION = \"opinion\"     # Beliefs with confidence scores\n",
    "    OBSERVATION = \"observation\"  # Derived insights\n",
    "\n",
    "@dataclass\n",
    "class Memory:\n",
    "    \"\"\"A single memory unit in the Hindsight system.\"\"\"\n",
    "    id: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    content: str = \"\"\n",
    "    memory_type: MemoryType = MemoryType.WORLD\n",
    "    context: str = \"\"  # Context for this memory\n",
    "    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "    confidence: float = 1.0  # 0-1 for opinions\n",
    "    embedding: Optional[List[float]] = None\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"id\": self.id,\n",
    "            \"content\": self.content,\n",
    "            \"memory_type\": self.memory_type.value,\n",
    "            \"context\": self.context,\n",
    "            \"timestamp\": self.timestamp,\n",
    "            \"confidence\": self.confidence,\n",
    "            \"metadata\": self.metadata\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data: dict):\n",
    "        return cls(\n",
    "            id=data.get(\"id\", str(uuid.uuid4())),\n",
    "            content=data[\"content\"],\n",
    "            memory_type=MemoryType(data[\"memory_type\"]),\n",
    "            context=data.get(\"context\", \"\"),\n",
    "            timestamp=data.get(\"timestamp\", datetime.now().isoformat()),\n",
    "            confidence=data.get(\"confidence\", 1.0),\n",
    "            metadata=data.get(\"metadata\", {})\n",
    "        )\n",
    "\n",
    "print(\"âœ… Memory types defined\")\n",
    "print(f\"   MemoryType: {list(MemoryType)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hindsight Memory Bank\n",
    "\n",
    "Implements the core Retain/Recall/Reflect operations from Hindsight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryBank:\n",
    "    \"\"\"\n",
    "    Hindsight-inspired memory bank with Retain/Recall/Reflect operations.\n",
    "\n",
    "    This is a simplified local implementation. For production, use the\n",
    "    actual Hindsight server from https://github.com/vectorize-io/hindsight\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bank_id: str, llm_client=None):\n",
    "        self.bank_id = bank_id\n",
    "        self.llm_client = llm_client or openai_client\n",
    "        self.memories: List[Memory] = []\n",
    "\n",
    "    def retain(self, content: str, memory_type: MemoryType = MemoryType.EXPERIENCE,\n",
    "               context: str = \"\", confidence: float = 1.0,\n",
    "               metadata: Dict = None) -> Memory:\n",
    "        \"\"\"\n",
    "        RETAIN: Store information in the memory bank.\n",
    "\n",
        "Behind the scenes, this uses an LLM to extract entities, relationships,\n",
        "and temporal data - just like Hindsight does.\n",
    "        \"\"\"\n",
    "        memory = Memory(\n",
    "            content=content,\n",
    "            memory_type=memory_type,\n",
    "            context=context,\n",
            "            confidence=confidence,\n",
            "            metadata=metadata or {}\n",
    "        )\n",
    "\n",
    "        # Optionally extract structured data using LLM\n",
    "        if self.llm_client:\n",
    "            extraction = self._extract_memory_data(content, memory_type)\n",
    "            memory.metadata.update(extraction)\n",
    "\n",
    "        self.memories.append(memory)\n",
    "        return memory\n",
    "\n",
    "    def _extract_memory_data(self, content: str, memory_type: MemoryType) -> Dict:\n",
    "        \"\"\"Use LLM to extract structured data from memory content.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Extract key information from this memory for better retrieval:\n",
    "\n",
        "Memory: {content}\n",
        "Type: {memory_type.value}\n",
        "\n",
        "Return a JSON object with:\n",
        "- entities: List of key entities mentioned\n",
        "- topics: Main topics/themes\n",
        "- sentiment: positive/negative/neutral (for experiences)\n",
        "- outcome: success/failure/neutral (for experiences)\n",
        "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.llm_client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=200\n",
    "            )\n",
    "            return json.loads(response.choices[0].message.content)\n",
    "        except:\n",
    "            return {\"entities\": [], \"topics\": [], \"sentiment\": \"neutral\"}\n",
    "\n",
    "    def recall(self, query: str, memory_types: List[MemoryType] = None,\n",
    "               limit: int = 10) -> List[Memory]:\n",
    "        \"\"\"\n",
        "        RECALL: Retrieve memories matching the query.\n",
    "\n",
        "Hindsight does 4 retrieval strategies in parallel:\n",
        "- Semantic: Vector similarity\n",
        "- Keyword: BM25 exact matching\n",
        "- Graph: Entity/temporal/causal links\n",
        "- Temporal: Time range filtering\n",
        "\n",
        "This implementation does simple keyword + semantic matching.\n",
    "        \"\"\"\n",
    "        if memory_types is None:\n",
    "            memory_types = list(MemoryType)\n",
    "\n",
    "        # Filter by type first\n",
    "        filtered = [m for m in self.memories if m.memory_type in memory_types]\n",
    "\n",
    "        # Score by relevance (simple keyword + length matching)\n",
    "        query_lower = query.lower()\n",
    "        query_words = set(query_lower.split())\n",
    "\n",
    "        scored = []\n",
    "        for memory in filtered:\n",
    "            score = 0.0\n",
    "\n",
    "            # Keyword match\n",
    "            content_words = set(memory.content.lower().split())\n",
    "            score += len(query_words & content_words) / max(len(query_words), 1)\n",
    "\n            # Context match\n",
    "            if memory.context:\n",
    "                context_words = set(memory.context.lower().split())\n",
    "                score += 0.5 * len(query_words & context_words) / max(len(context_words), 1)\n",
    "\n            # Confidence boost for opinions\n",
    "            if memory.memory_type == MemoryType.OPINION:\n",
    "                score *= (0.8 + 0.2 * memory.confidence)\n",
    "\n            scored.append((score, memory))\n",
    "\n        # Sort by score and return top results\n",
    "        scored.sort(reverse=True, key=lambda x: x[0])\n",
    "        return [m for _, m in scored[:limit]]\n",
    "\n",
    "    def reflect(self, query: str) -> str:\n",
    "        \"\"\"\n",
        "        REFLECT: Perform thoughtful analysis using bank's memories.\n",
        "\n",
        "This is where continuous learning happens! We:\n",
        "1. Recall relevant memories\n",
        "2. Analyze patterns across experiences\n",
        "3. Generate new observations and opinions\n",
        "4. Retain new learnings back into the bank\n",
    "        \"\"\"\n",
    "        # Get relevant memories\n",
    "        experiences = self.recall(query, [MemoryType.EXPERIENCE], limit=20)\n",
    "        opinions = self.recall(query, [MemoryType.OPINION], limit=10)\n",
    "        observations = self.recall(query, [MemoryType.OBSERVATION], limit=5)\n",
    "\n        # Build context for reflection\n",
        "        context = f\"\"\"\n",
        "Query to reflect on: {query}\n",
        "\n",
        "Relevant Experiences:\n",
        "{'\\n'.join([e.content for e in experiences[:10]])}\n",
        "\n",
        "Current Opinions:\n",
        "{'\\n'.join([o.content for o in opinions[:5]])}\n",
        "\n",
        "Previous Observations:\n",
        "{'\\n'.join([o.content for o in observations[:3]])}\n",
        "        \"\"\"\n",
    "\n",
    "        # Generate reflection using LLM\n",
    "        prompt = f\"\"\"\n",
    "        You are a reflective agent using the Hindsight memory system.\n",
    "        Analyze the accumulated memories and generate insights.\n",
    "\n",
        "{context}\n",
        "\n",
        "Generate:\n",
        "1. NEW_OBSERVATION: A key insight derived from these experiences\n",
        "2. UPDATED_OPINION: An updated belief with confidence score (0-1)\n",
        "3. BEST_PRACTICE: What works well based on successful experiences\n",
        "4. COMMON_PITFALL: What to avoid based on failures\n",
    "\n",
        "Format as JSON:\n",
        "```json\n",
        "{{\n",
        "    \"observation\": \"...\",\n",
        "    \"opinion\": \"...\",\n",
        "    \"confidence\": 0.85,\n",
        "    \"best_practice\": \"...\",\n",
        "    \"pitfall\": \"...\",\n",
        "    \"training_examples\": [\n",
        "        {{\"user\": \"...\", \"assistant\": \"...\"}}\n",
        "    ]\n",
        "}}\n",
        "```\n",
        "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.llm_client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=1000\n",
    "            )\n",
    "\n",
    "            # Parse and retain new learnings\n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "\n",
            # Retain the observation\n",
    "            self.retain(\n",
    "                result[\"observation\"],\n",
    "                memory_type=MemoryType.OBSERVATION,\n",
    "                context=query,\n",
    "                confidence=result.get(\"confidence\", 0.7)\n",
    "            )\n",
    "\n",
    "            # Retain updated opinion\n",
    "            self.retain(\n",
    "                result[\"opinion\"],\n",
    "                memory_type=MemoryType.OPINION,\n",
    "                context=query,\n",
    "                confidence=result.get(\"confidence\", 0.7)\n",
    "            )\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Get statistics about the memory bank.\"\"\"\n",
    "        by_type = {}\n",
    "        for mt in MemoryType:\n",
    "            count = sum(1 for m in self.memories if m.memory_type == mt)\n",
    "            avg_confidence = np.mean([m.confidence for m in self.memories if m.memory_type == mt]) if count > 0 else 0\n",
    "            by_type[mt.value] = {\"count\": count, \"avg_confidence\": avg_confidence}\n",
    "\n",
    "        return {\n",
    "            \"bank_id\": self.bank_id,\n",
    "            \"total_memories\": len(self.memories),\n",
    "            \"by_type\": by_type\n",
    "        }\n",
    "\n",
    "    def save(self, filepath: str):\n",
    "        \"\"\"Save memory bank to file.\"\"\"\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump([m.to_dict() for m in self.memories], f, indent=2)\n",
    "\n",
    "    def load(self, filepath: str):\n",
    "        \"\"\"Load memory bank from file.\"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            self.memories = [Memory.from_dict(d) for d in data]\n",
    "\n",
    "print(\"âœ… MemoryBank class defined with Retain/Recall/Reflect operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experience Collector\n",
    "\n",
    "Captures agent interactions and their outcomes for continuous learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceCollector:\n",
    "    \"\"\"\n",
    "    Captures and processes agent experiences for the learning loop.\n",
    "\n",
    "    An experience consists of:\n",
    "- Query: What the user asked\n",
    "- Response: What the agent answered\n",
    "- Outcome: How it turned out (success/failure/rating)\n",
    "- Context: Additional context about the interaction\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, memory_bank: MemoryBank):\n",
    "        self.memory_bank = memory_bank\n",
    "        self.experiences: List[Dict] = []\n",
    "\n",
    "    def record_experience(self, query: str, response: str, outcome: str,\n",
    "                          context: str = \"\", rating: float = None):\n",
    "        \"\"\"\n",
        "        Record a new experience from an agent interaction.\n",
    "\n",
        "        Args:\n",
    "            query: The user's query\n",
    "            response: The agent's response\n",
    "            outcome: \"success\", \"failure\", \"partial\", or description\n",
    "            context: Additional context (domain, user type, etc.)\n",
    "            rating: Optional 0-1 rating of the response quality\n",
    "        \"\"\"\n",
    "        experience = {\n",
    "            \"id\": str(uuid.uuid4()),\n",
            "            \"query\": query,\n",
    "            \"response\": response,\n",
    "            \"outcome\": outcome,\n",
            "            \"context\": context,\n",
    "            \"rating\": rating,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "        self.experiences.append(experience)\n",
    "\n",
    "        # Calculate confidence based on outcome/rating\n",
    "        if rating is not None:\n",
    "            confidence = rating\n",
    "        elif outcome == \"success\":\n",
    "            confidence = 0.9\n",
    "        elif outcome == \"partial\":\n",
    "            confidence = 0.5\n",
    "        else:\n",
    "            confidence = 0.3\n",
    "\n",
    "        # Retain as experience in memory bank\n",
    "        self.memory_bank.retain(\n",
    "            content=f\"Query: {query}\\nResponse: {response}\\nOutcome: {outcome}\",\n",
    "            memory_type=MemoryType.EXPERIENCE,\n",
    "            context=context,\n",
    "            confidence=confidence,\n",
    "            metadata={\"rating\": rating, \"outcome\": outcome}\n",
    "        )\n",
    "\n",
    "        return experience\n",
    "\n",
    "    def record_success(self, query: str, response: str, context: str = \"\"):\n",
    "        \"\"\"Convenience method for recording successful interactions.\"\"\"\n",
    "        return self.record_experience(query, response, \"success\", context, rating=1.0)\n",
    "\n",
    "    def record_failure(self, query: str, response: str, context: str = \"\",\n",
    "                       what_went_wrong: str = \"\"):\n",
    "        \"\"\"Convenience method for recording failed interactions.\"\"\"\n",
    "        return self.record_experience(\n",
    "            query, response, f\"failure: {what_went_wrong}\", context, rating=0.0\n",
    "        )\n",
    "\n",
    "    def get_training_examples(self, min_rating: float = 0.8,\n",
    "                              max_examples: int = 100) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract high-quality experiences as training examples.\n",
    "\n",
        "These can be used for finetuning.\n",
    "        \"\"\"\n",
    "        # Filter by rating\n",
    "        filtered = [e for e in self.experiences\n",
    "                    if (e.get(\"rating\", 0) >= min_rating or e[\"outcome\"] == \"success\")]\n",
    "\n        # Limit count\n",
    "        filtered = filtered[:max_examples]\n",
    "\n        # Convert to training format\n",
    "        return [\n",
    "            {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": self._get_system_prompt(e[\"context\"])},\n",
    "                    {\"role\": \"user\", \"content\": e[\"query\"]},\n",
    "                    {\"role\": \"assistant\", \"content\": e[\"response\"]}\n",
    "                ]\n",
    "            }\n",
    "            for e in filtered\n",
    "        ]\n",
    "\n",
    "    def _get_system_prompt(self, context: str) -> str:\n",
    "        \"\"\"Generate system prompt based on context and accumulated opinions.\"\"\"\n",
    "        # Get opinions from memory bank\n",
    "        opinions = self.memory_bank.recall(context, [MemoryType.OPINION], limit=5)\n",
    "\n",
    "        opinion_text = \"\"\n",
    "        if opinions:\n",
    "            opinion_text = \"\\n\".join([o.content for o in opinions])\n",
    "\n",
    "        base_prompt = \"\"\"You are a helpful AI assistant that provides accurate, well-reasoned responses.\"\"\"\n",
    "\n",
    "        if opinion_text:\n",
    "            base_prompt += f\"\\n\\nLearned guidelines:\\n{opinion_text}\"\n",
    "\n",
    "        return base_prompt\n",
    "\n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Get statistics about collected experiences.\"\"\"\n",
    "        ratings = [e[\"rating\"] for e in self.experiences if e[\"rating\"] is not None]\n",
    "        outcomes = {}\n",
    "        for e in self.experiences:\n",
    "            outcome = e[\"outcome\"].split(\":\")[0]\n",
    "            outcomes[outcome] = outcomes.get(outcome, 0) + 1\n",
    "\n",
    "        return {\n",
    "            \"total_experiences\": len(self.experiences),\n",
    "            \"avg_rating\": np.mean(ratings) if ratings else None,\n",
    "            \"outcome_distribution\": outcomes\n",
    "        }\n",
    "\n",
    "print(\"âœ… ExperienceCollector class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Synthetic Data Generator\n",
    "\n",
    "Uses reflection to generate additional training examples from memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataGenerator:\n",
    "    \"\"\"\n",
    "    Generates synthetic training data using reflection on accumulated memories.\n",
    "\n",
    "This is key to continuous learning - we can create more training data\n",
    "from our existing experiences rather than relying solely on new interactions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, memory_bank: MemoryBank, llm_client=None):\n",
    "        self.memory_bank = memory_bank\n",
    "        self.llm_client = llm_client or openai_client\n",
    "\n",
    "    def generate_variations(self, query: str, response: str,\n",
    "                           num_variations: int = 3) -> List[Dict]:\n",
    "        \"\"\"\n",
        "        Generate variations of a successful query-response pair.\n",
    "\n",
        "This helps expand the training dataset with semantically similar examples.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Generate {num_variations} variations of this query and response pair.\n",
    "\n",
        "Original Query: {query}\n",
        "Original Response: {response}\n",
        "\n",
        "For each variation:\n",
        "- Change the query phrasing but keep the intent\n",
        "- Keep the response structure but update details\n",
        "- Make it sound natural and diverse\n",
        "\n",
        "Return as JSON array:\n",
        \"\"\"[{\"query\": \"...\", \"response\": \"...\"}]\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.llm_client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=1000\n",
    "            )\n",
    "            return json.loads(response.choices[0].message.content)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating variations: {e}\")\n",
    "            return []\n",
    "\n",
    "    def generate_edge_cases(self, domain: str, num_cases: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
        "        Generate challenging edge cases based on common pitfalls.\n",
    "\n",
        "Uses the memory bank's record of failures to generate training data\n",
        "for handling difficult scenarios.\n",
    "        \"\"\"\n",
    "        # Get common pitfalls from memory bank\n",
    "        failures = self.memory_bank.recall(\n",
    "            domain, [MemoryType.EXPERIENCE], limit=20\n",
    "        )\n",
    "        failure_contexts = [f.content for f in failures if f.confidence < 0.5]\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Generate {num_cases} challenging edge case queries for the domain: {domain}\n",
        "\n",
        "Common pitfalls to address:\n",
    "        {chr(10).join(failure_contexts[:5]) if failure_contexts else \"None recorded yet\"}\n",
        "\n",
        "Generate queries that represent:\n",
        "- Ambiguous requests\n",
        "- Edge cases\n",
        "- Complex scenarios\n",
        "- Common mistakes users make\n",
        "\n",
        "For each, also provide a good response that handles it well.\n",
        "Return as JSON array:\n",
        \"\"\"[{\"query\": \"...\", \"response\": \"...\"}]\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.llm_client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=1500\n",
    "            )\n",
    "            return json.loads(response.choices[0].message.content)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating edge cases: {e}\")\n",
    "            return []\n",
    "\n",
    "    def generate_training_dataset(self, domain: str, target_size: int = 100) -> List[Dict]:\n",
    "        \"\"\"\n",
        "        Generate a complete training dataset from memory bank.\n",
    "\n",
        "Combines:\n",
        "1. High-rated experiences\n",
        "2. Synthetic variations\n",
        "3. Edge cases\n",
        "4. Observations from reflection\n",
    "        \"\"\"\n",
    "        training_data = []\n",
    "\n",
    "        # Get successful experiences\n",
    "        experiences = self.memory_bank.recall(domain, [MemoryType.EXPERIENCE], limit=100)\n",
    "        successful = [e for e in experiences if e.confidence >= 0.8]\n",
    "\n",
    "        for exp in successful:\n",
    "            # Parse the stored content\n",
    "            content = exp.content\n",
    "            if \"Query:\" in content and \"Response:\" in content:\n",
    "                parts = content.split(\"Response:\")\n",
    "                query = parts[0].replace(\"Query:\", \"\").strip()\n",
    "                response = parts[1].replace(\"Outcome:\", \"\").strip() if len(parts) > 1 else \"\"\n",
    "\n",
    "                training_data.append({\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"user\", \"content\": query},\n",
    "                        {\"role\": \"assistant\", \"content\": response}\n",
    "                    ]\n",
    "                })\n",
    "\n",
        "        # Generate variations of top examples\n",
    "        if len(training_data) < target_size // 2:\n",
    "            for example in training_data[:5]:\n",
    "                query = example[\"messages\"][0][\"content\"]\n",
    "                response = example[\"messages\"][1][\"content\"]\n",
    "                variations = self.generate_variations(query, response, 3)\n",
    "                for v in variations:\n",
    "                    if len(training_data) >= target_size:\n",
    "                        break\n",
    "                    training_data.append({\n",
    "                        \"messages\": [\n",
    "                            {\"role\": \"user\", \"content\": v[\"query\"]},\n",
    "                            {\"role\": \"assistant\", \"content\": v[\"response\"]}\n",
    "                        ]\n",
    "                    })\n",
    "\n",
    "        # Generate edge cases\n",
    "        edge_cases = self.generate_edge_cases(domain, target_size // 4)\n",
    "        for ec in edge_cases:\n",
    "            if len(training_data) >= target_size:\n",
    "                break\n",
    "            training_data.append({\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": ec[\"query\"]},\n",
    "                    {\"role\": \"assistant\", \"content\": ec[\"response\"]}\n",
    "                ]\n",
    "            })\n",
    "\n",
    "        return training_data[:target_size]\n",
    "\n",
    "print(\"âœ… SyntheticDataGenerator class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Continuous Learning Orchestrator\n",
    "\n",
    "Ties everything together for the continuous learning loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousLearningOrchestrator:\n",
    "    \"\"\"\n",
    "    Orchestrates the continuous learning and finetuning pipeline.\n",
    "\n",
    "    Loop:\n",
    "    1. Agent handles user query\n",
    "    "   2. Collect experience (success/failure with context)\n",
    "    3. Periodically reflect to generate observations\n",
    "    4. Accumulate training data\n",
    "    5. Finetune model when enough new data\n",
    "    6. Deploy updated model\n",
    "    7. Repeat\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bank_id: str, domain: str,\n",
    "                 llm_client=None, together_client=None):\n",
    "        self.domain = domain\n",
    "        self.memory_bank = MemoryBank(bank_id, llm_client)\n",
    "        self.experience_collector = ExperienceCollector(self.memory_bank)\n",
    "        self.synthetic_generator = SyntheticDataGenerator(self.memory_bank, llm_client)\n",
    "        self.together_client = together_client\n",
    "\n",
    "        self.experience_count = 0\n",
    "        self.last_finetune_count = 0\n",
    "        self.experiences_per_finetune = 50  # Trigger finetune after this many new experiences\n",
    "\n",
    "    def handle_query(self, query: str, context: str = \"\") -> Dict:\n",
    "        \"\"\"\n",
    "        Handle a user query with the learning loop.\n",
    "\n",
        "1. Recall relevant memories\n",
        "2. Generate response (using current model)\n",
    "        "3. Return response + relevant context\n",
    "        \"\"\"\n",
    "        # Recall relevant memories for context\n",
    "        relevant_experiences = self.memory_bank.recall(query, [MemoryType.EXPERIENCE], limit=5)\n",
    "        relevant_opinions = self.memory_bank.recall(query, [MemoryType.OPINION], limit=3)\n",
    "\n",
    "        # Build context from memories\n",
    "        memory_context = \"\"\n",
    "        if relevant_experiences:\n",
    "            memory_context = \"Previous relevant experiences:\\n\" + \"\\n\".join(\n",
    "                [e.content[:200] for e in relevant_experiences]\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"context\": context,\n",
    "            \"relevant_memories\": len(relevant_experiences),\n",
    "            \"opinions\": [o.content for o in relevant_opinions],\n",
    "            \"memory_context\": memory_context\n",
    "        }\n",
    "\n",
    "    def record_outcome(self, query: str, response: str, outcome: str,\n",
    "                       context: str = \"\", rating: float = None):\n",
    "        \"\"\"\n",
    "        Record the outcome of a query handling.\n",
    "\n",
        "This is the key to continuous learning - every interaction becomes data.\n",
    "        \"\"\"\n",
    "        self.experience_collector.record_experience(\n",
    "            query, response, outcome, context, rating\n",
    "        )\n",
    "        self.experience_count += 1\n",
    "\n",
    "        # Check if we should trigger reflection\n",
    "        if self.experience_count % 10 == 0:\n",
    "            self._periodic_reflection()\n",
    "\n",
    "        # Check if we should trigger finetuning\n",
    "        if self.experience_count - self.last_finetune_count >= self.experiences_per_finetune:\n",
    "            return {\"should_finetune\": True, \"new_experiences\": self.experiences_per_finetune}\n",
    "\n",
    "        return {\"should_finetune\": False}\n",
    "\n",
    "    def _periodic_reflection(self):\n",
    "        \"\"\"Run reflection to generate new observations and opinions.\"\"\"\n",
    "        print(f\"\\nðŸ”„ Running periodic reflection (experience #{self.experience_count})...\")\n",
    "        result = self.memory_bank.reflect(f\"Best practices for {self.domain}\")\n",
    "        if \"observation\" in result:\n",
    "            print(f\"   ðŸ“ New observation: {result['observation'][:100]}...\")\n",
    "        return result\n",
    "\n",
    "    def prepare_finetuning_data(self, min_quality: float = 0.8) -> List[Dict]:\n",
    "        \"\"\"\n",
        "        Prepare training data for finetuning from accumulated memories.\n",
    "\n",
        "Combines:\n",
        "- High-rated recorded experiences\n",
        "- Synthetic data from variations\n",
        "- Generated edge cases\n",
        "- Observations from reflection\n",
        "        \"\"\"\n",
    "        print(f\"\\nðŸ“Š Preparing finetuning data...\")\n",
    "\n",
    "        # Get training examples from experiences\n",
    "        training_examples = self.experience_collector.get_training_examples(\n",
    "            min_rating=min_quality\n",
    "        )\n",
    "        print(f\"   Found {len(training_examples)} high-quality experiences\")\n",
    "\n",
    "        # Generate synthetic data\n",
    "        synthetic = self.synthetic_generator.generate_training_dataset(\n",
    "            self.domain, target_size=100\n",
    "        )\n",
    "        print(f\"   Generated {len(synthetic)} synthetic examples\")\n",
    "\n",
    "        # Combine and deduplicate\n",
    "        all_data = training_examples + synthetic\n",
    "        unique_data = self._deduplicate(all_data)\n",
    "\n",
    "        print(f\"   Total unique training examples: {len(unique_data)}\")\n",
    "        return unique_data\n",
    "\n",
    "    def _deduplicate(self, data: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Remove duplicate examples based on content hashing.\"\"\"\n",
    "        seen = set()\n",
    "        unique = []\n",
    "\n",
    "        for example in data:\n",
    "            # Create a hash from the content\n",
    "            content_str = json.dumps(example, sort_keys=True)\n",
    "            content_hash = hash(content_str)\n",
    "\n",
    "            if content_hash not in seen:\n",
    "                seen.add(content_hash)\n",
    "                unique.append(example)\n",
    "\n",
    "        return unique\n",
    "\n",
    "    def get_status(self) -> Dict:\n",
    "        \"\"\"Get current status of the learning system.\"\"\"\n",
    "        return {\n",
    "            \"domain\": self.domain,\n",
            "            \"total_experiences\": self.experience_count,\n",
            "            \"experiences_since_finetune\": self.experience_count - self.last_finetune_count,\n",
            "            \"experiences_per_finetune\": self.experiences_per_finetune,\n",
            "            \"memory_bank_stats\": self.memory_bank.get_stats(),\n",
    "            \"experience_stats\": self.experience_collector.get_stats()\n",
    "        }\n",
    "\n",
    "print(\"âœ… ContinuousLearningOrchestrator class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Demo: Walkthrough of the Continuous Learning System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a continuous learning system for a domain (e.g., SQL assistance)\n",
    "DOMAIN = \"SQL Query Assistant\"\n",
    "orchestrator = ContinuousLearningOrchestrator(\n",
    "    bank_id=\"sql-assistant-learn-001\",\n",
    "    domain=DOMAIN,\n",
    "    llm_client=openai_client\n",
    ")\n",
    "\n",
    "print(f\"ðŸš€ Created continuous learning system for: {DOMAIN}\")\n",
    "print(f\"   Bank ID: {orchestrator.memory_bank.bank_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Add some initial world knowledge\n",
    "print(\"\\nðŸ“š Step 1: Adding initial world knowledge...\")\n",
    "\n",
    "initial_facts = [\n",
    "    \"SQL JOINs combine rows from two or more tables based on a related column.\",\n",
    "    \"INNER JOIN returns only matching rows from both tables.\",\n",
    "    \"LEFT JOIN returns all rows from the left table and matched rows from the right.\",\n",
    "    \"Use EXPLAIN before running expensive queries to see the execution plan.\",\n",
    "    \"Indexes on foreign keys significantly improve join performance.\",\n",
    "]\n",
    "\n",
    "for fact in initial_facts:\n",
    "    orchestrator.memory_bank.retain(\n",
    "        content=fact,\n",
    "        memory_type=MemoryType.WORLD,\n",
    "        context=DOMAIN\n",
    "    )\n",
    "\n",
    "print(f\"   Added {len(initial_facts)} initial facts to world memory\")\n",
    "print(f\"   Memory bank stats: {orchestrator.memory_bank.get_stats()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Simulate some agent interactions\n",
    "print(\"\\nðŸ¤– Step 2: Simulating agent interactions...\")\n",
    "\n",
    "simulated_interactions = [\n",
    "    {\n",
    "        \"query\": \"Write a query to find all customers who placed orders last month\",\n",
    "        \"response\": \"SELECT c.* FROM customers c JOIN orders o ON c.id = o.customer_id WHERE o.created_at >= DATE_SUB(NOW(), INTERVAL 1 MONTH)\",\n",
    "        \"outcome\": \"success\",\n",
    "        \"context\": \"customer lookup\",\n",
    "        \"rating\": 0.95\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I find duplicate records in a table?\",\n",
    "        \"response\": \"SELECT email, COUNT(*) FROM users GROUP BY email HAVING COUNT(*) > 1\",\n",
    "        \"outcome\": \"success\",\n",
    "        \"context\": \"data cleaning\",\n",
    "        \"rating\": 0.9\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Write a slow query that scans the entire table\",\n",
    "        \"response\": \"SELECT * FROM orders WHERE YEAR(created_at) = 2024\",\n",
    "        \"outcome\": \"failure\",\n",
    "        \"what_went_wrong\": \"Full table scan, should use index on created_at\",\n",
    "        \"context\": \"performance\",\n",
    "        \"rating\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Optimize this query: SELECT * FROM large_table WHERE status = 'active'\",\n",
    "        \"response\": \"SELECT id, name, email FROM large_table WHERE status = 'active' AND created_at > '2024-01-01'\",\n",
    "        \"outcome\": \"success\",\n",
    "        \"context\": \"performance optimization\",\n",
    "        \"rating\": 0.85\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the difference between UNION and UNION ALL?\",\n",
    "        \"response\": \"UNION removes duplicates, UNION ALL keeps all rows including duplicates. Use UNION ALL when you know there are no duplicates for better performance.\",\n",
    "        \"outcome\": \"success\",\n",
    "        \"context\": \"sql concepts\",\n",
    "        \"rating\": 1.0\n",
    "    }\n",
    "]\n",
    "\n",
    "for interaction in simulated_interactions:\n",
    "    result = orchestrator.record_outcome(\n",
    "        query=interaction[\"query\"],\n",
    "        response=interaction[\"response\"],\n",
    "        outcome=interaction[\"outcome\"],\n",
    "        context=interaction[\"context\"],\n",
        "        rating=interaction.get(\"rating\")\n",
    )\n",
    "\n",
    "print(f\"   Recorded {len(simulated_interactions)} interactions\")\n",
    "print(f\"   System status: {orchestrator.get_status()['total_experiences']} total experiences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Test recall - get relevant memories for a query\n",
    "print(\"\\nðŸ” Step 3: Testing memory recall...\")\n",
    "\n",
    "test_query = \"How do I optimize SQL queries?\"\n",
    "memories = orchestrator.memory_bank.recall(test_query, limit=5)\n",
    "\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"\\nRetrieved {len(memories)} relevant memories:\\n\")\n",
    "\n",
    "for i, mem in enumerate(memories, 1):\n",
    "    print(f\"{i}. [{mem.memory_type.value}] (confidence: {mem.confidence:.2f})\")\n",
    "    print(f\"   {mem.content[:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Run reflection to generate observations and opinions\n",
    "print(\"\\nðŸ’­ Step 4: Running reflection to generate insights...\")\n",
    "\n",
    "reflection_result = orchestrator.memory_bank.reflect(\n",
    "    f\"Best practices and common mistakes in {DOMAIN}\"\n",
    ")\n",
    "\n",
    "if \"observation\" in reflection_result:\n",
    "    print(\"\\nðŸ“ New Observation:\")\n",
    "    print(f\"   {reflection_result['observation']}\")\n",
    "\n",
    "    print(\"\\nðŸŽ¯ Updated Opinion:\")\n",
    "    print(f\"   {reflection_result['opinion']}\")\n",
    "\n",
    "    print(f\"\\n   Confidence: {reflection_result.get('confidence', 'N/A')}\")\n",
    "\n",
    "    print(\"\\nâœ… Best Practice:\")\n",
    "    print(f\"   {reflection_result.get('best_practice', 'N/A')}\")\n",
    "\n",
    "    print(\"\\nâš ï¸  Common Pitfall:\")\n",
    "    print(f\"   {reflection_result.get('pitfall', 'N/A')}\")\n",
    "\n",
    "    if \"training_examples\" in reflection_result:\n",
    "        print(f\"\\nðŸ“š Generated {len(reflection_result['training_examples'])} synthetic training examples\")\n",
    "else:\n",
    "    print(f\"Reflection result: {reflection_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Check memory bank statistics\n",
    "print(\"\\nðŸ“Š Step 5: Memory Bank Statistics\")\n",
    "stats = orchestrator.memory_bank.get_stats()\n",
    "\n",
    "print(f\"\\nBank: {stats['bank_id']}\")\n",
    "print(f\"Total Memories: {stats['total_memories']}\")\n",
    "print(\"\\nBreakdown by type:\")\n",
    "for mem_type, type_stats in stats['by_type'].items():\n",
    "    print(f\"  â€¢ {mem_type}: {type_stats['count']} memories (avg confidence: {type_stats['avg_confidence']:.2f})\")\n",
    "\n",
    "print(f\"\\nExperience Stats:\")\n",
    "exp_stats = orchestrator.experience_collector.get_stats()\n",
    "for k, v in exp_stats.items():\n",
    "    print(f\"  â€¢ {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Training Data for Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Generate training data for finetuning\n",
    "print(\"\\nðŸŽ¯ Step 6: Generating finetuning training data...\")\n",
    "\n",
    "training_data = orchestrator.prepare_finetuning_data(min_quality=0.7)\n",
    "\n",
    "print(f\"\\nðŸ“¦ Generated {len(training_data)} training examples\")\n",
    "\n",
    "# Show a sample\n",
    "if training_data:\n",
    "    print(\"\\nSample training example:\")\n",
    "    sample = training_data[0]\n",
    "    for msg in sample[\"messages\"]:\n",
    "        print(f\"\\n[{msg['role']}]:\")\n",
    "        print(f\"   {msg['content'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training data to JSONL\n",
    "TRAIN_FILE = \"continuous_learning_training_data.jsonl\"\n",
    "\n",
    "with open(TRAIN_FILE, 'w') as f:\n",
    "    for example in training_data:\n",
    "        f.write(json.dumps(example) + '\\n')\n",
    "\n",
    "print(f\"\\nâœ… Saved training data to {TRAIN_FILE}\")\n",
    "\n",
    "import os\n",
    "file_size = os.path.getsize(TRAIN_FILE)\n",
    "print(f\"   File size: {file_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Launch Finetuning Job (Optional)\n",
    "\n",
    "Once you have enough training data, you can launch a finetuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FINETUNING CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "# Your model's name\n",
    "MODEL_SUFFIX = \"sql-assistant-continuous-v1\"\n",
    "\n",
    "# Base model to fine-tune\n",
    "BASE_MODEL = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "\n",
    "# Training hyperparameters\n",
    "finetune_config = {\n",
    "    \"n_epochs\": 3,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"batch_size\": 4,\n",
    "    \"warmup_ratio\": 0.1,\n",
    "}\n",
    "\n",
    "print(\"ðŸ“‹ Finetuning Configuration:\")\n",
    "print(f\"   Base model: {BASE_MODEL}\")\n",
    "print(f\"   Output suffix: {MODEL_SUFFIX}\")\n",
    "print(f\"   Training examples: {len(training_data)}\")\n",
    "for k, v in finetune_config.items():\n",
    "    print(f\"   {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training file to Together AI\n",
    "print(\"\\nðŸ“¤ Uploading training data to Together AI...\")\n",
    "\n",
    "try:\n",
    "    file_response = together_client.files.upload(\n",
    "        file=open(TRAIN_FILE, \"rb\"),\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "\n",
    "    FILE_ID = file_response.id\n",
    "    print(f\"âœ… Upload complete! File ID: {FILE_ID}\")\n",
    "    print(f\"   Status: {file_response.status}\")\n",
    "\nexcept Exception as e:\n",
    "    print(f\"âŒ Upload failed: {e}\")\n",
    "    print(\"   Skipping finetuning step - this is expected without API keys\")\n",
    "    FILE_ID = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and launch finetuning job (if file was uploaded)\n",
    "if FILE_ID:\n",
    "    print(\"\\nðŸš€ Creating finetuning job...\")\n",
    "\n",
    "    job = together_client.fine_tuning.create(\n",
    "        model=BASE_MODEL,\n",
    "        training_file=FILE_ID,\n",
    "        suffix=MODEL_SUFFIX,\n",
    "        hyperparameters=finetune_config\n",
    "    )\n",
    "\n",
    "    JOB_ID = job.id\n",
    "    print(f\"âœ… Finetuning job created!\")\n",
    "    print(f\"   Job ID: {JOB_ID}\")\n",
    "    print(f\"   Status: {job.status}\")\n",
    "    print(f\"\\n   You can monitor progress at: https://together.ai/finetune/{JOB_ID}\")\nelse:\n",
    "    print(\"\\nâš ï¸  No file ID - skipping finetuning job creation\")\n",
    "    print(\"   This is expected when running without valid API keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. The Continuous Learning Loop\n",
    "\n",
    "Here's how to use this system in production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PRODUCTION CONTINUOUS LEARNING LOOP\n",
    "\n",
    "1. Agent handles user query\n",
    "2. Use orchestrator.handle_query(query) to get relevant memories\n",
    "3. Generate response using model + memory context\n",
    "4. Get user feedback / detect success/failure\n",
    "5. Call orchestrator.record_outcome(query, response, outcome, context, rating)\n",
    "6. Every N experiences, reflection runs automatically\n",
    "7. When experiences_since_finetune >= threshold:\n",
    "   - Call orchestrator.prepare_finetuning_data()\n",
    "   - Upload to Together AI and create finetuning job\n",
    "   - When complete, deploy new model\n",
    "   - Reset experience counter\n",
    "8. Repeat forever!\n",
    "\n",
    "Example production code:\n",
    "\"\"\"\n",
    "\n",
    "# Example production usage pattern:\n",
    "\n",
    "def handle_user_query_production(orchestrator, query, user_context):\n",
    "    \"\"\"\n",
    "    Production query handling with continuous learning.\n",
    "    \"\"\"\n",
    "    # 1. Get relevant memories\n",
    "    context = orchestrator.handle_query(query, user_context)\n",
    "\n",
    "    # 2. Build prompt with memory context\n",
    "    system_prompt = f\"\"\"You are a helpful {orchestrator.domain} assistant.\n",
    "\n",
    "Relevant previous experiences:\n",
    "{context['memory_context']}\n",
    "\n",
    "Your learned guidelines:\n",
    "\\n'.join(context['opinions'])}\"\"\"\n",
    "\n",
    "    # 3. Call your model (could be the continuously fine-tuned one!)\n",
    "    # response = call_model(model, system_prompt, query)\n",
    "\n",
    "    # 4. Get feedback (could be explicit ratings or implicit signals)\n",
    "    # user_satisfied = check_user_feedback()\n",
    "\n",
    "    # 5. Record the outcome\n",
    "    # result = orchestrator.record_outcome(\n",
    "    #     query=query,\n",
    "    #     response=response,\n",
    "    #     outcome=\"success\" if user_satisfied else \"failure\",\n",
    "    #     context=user_context\n",
    "    # )\n",
    "\n",
    "    # 6. Check if should trigger finetuning\n",
    "    # if result['should_finetune']:\n",
    "    #     data = orchestrator.prepare_finetuning_data()\n",
    "    #     launch_finetuning_job(data)\n",
    "\n",
    "    # return response\n",
    "\n",
    "print(\"âœ… Production loop pattern defined\")\n",
    "print(\"\\nðŸ“š See the code above for the full production pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save/Load Memory Bank\n",
    "\n",
    "Persist the memory bank for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save memory bank\n",
    "MEMORY_BANK_FILE = \"hindsight_memory_bank.json\"\n",
    "\n",
    "orchestrator.memory_bank.save(MEMORY_BANK_FILE)\n",
    "print(f\"âœ… Memory bank saved to {MEMORY_BANK_FILE}\")\n",
    "\n",
    "# Load later\n",
    "# new_orchestrator = ContinuousLearningOrchestrator(bank_id=\"sql-assistant-learn-001\", domain=DOMAIN)\n",
    "# new_orchestrator.memory_bank.load(MEMORY_BANK_FILE)\n",
    "\n",
    "print(\"\\nðŸ’¡ Tip: Save the memory bank after each batch of experiences!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implements a **continuous learning system** inspired by Hindsight:\n",
    "\n",
    "### Key Components\n",
    "| Component | Purpose |\n",
    "|-----------|---------|\n",
    "| `MemoryBank` | Store/retrieve memories with Retain/Recall/Reflect |\n",
    "| `MemoryType` | WORLD, EXPERIENCE, OPINION, OBSERVATION |\n",
    "| `ExperienceCollector` | Record agent interactions with outcomes |\n",
    "| `SyntheticDataGenerator` | Expand training data via variations |\n",
    "| `ContinuousLearningOrchestrator` | Tie it all together |\n",
    "\n",
    "### How It Works\n",
    "1. **Retain** experiences from agent interactions\n",
    "2. **Recall** relevant memories when handling queries\n",
    "3. **Reflect** periodically to generate observations\n",
    "4. **Accumulate** training data from high-quality experiences\n",
    "5. **Finetune** the model with accumulated knowledge\n",
    "6. **Deploy** and repeat\n",
    "\n",
    "### Production Deployment\n",
    "For production use:\n",
    "- Use the actual Hindsight server (https://github.com/vectorize-io/hindsight)\n",
    "- Set up monitoring and alerts\n",
    "- Implement A/B testing for model versions\n",
    "- Track learning metrics over time\n",
    "\n",
    "### Resources\n",
    "- [Hindsight Paper](https://arxiv.org/abs/2512.12818)\n",
    "- [Hindsight GitHub](https://github.com/vectorize-io/hindsight)\n",
    "- [Together AI Fine-tuning](https://docs.together.ai/docs/fine-tuning)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
