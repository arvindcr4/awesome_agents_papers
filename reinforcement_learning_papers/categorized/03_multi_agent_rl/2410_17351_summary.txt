Here is the extracted information:

**PAPER:** Hierarchical Multi-agent Reinforcement Learning for Cyber Network Defense
**TITLE:** Hierarchical Multi-agent Reinforcement Learning for Cyber Network Defense
**ARXIV_ID:** 2410.17351v3 [cs.LG]
**RESEARCH_METHOD:** 03_multi_agent_rl
**METHOD_DESCRIPTION:** This paper proposes a hierarchical multi-agent reinforcement learning (MARL) approach for cyber network defense. The approach decomposes the complex cyber defense task into smaller sub-tasks, trains sub-policies for each sub-task using Proximal Policy Optimization (PPO) enhanced with domain expertise, and then trains a master policy to coordinate the selection of sub-policies. The master policy learns to reason about the decisions it can make by using state abstractions, such as the presence of indicators of compromise (IOCs) in the network.
**KEY_CONTRIBUTIONS:**
* Scalable hierarchical MARL approach for cyber network defense
* Decomposition of complex cyber defense task into smaller sub-tasks
* Training of sub-policies using PPO enhanced with domain expertise
* Evaluation of the approach in the CybORG CAGE 4 environment, a realistic cyber security environment
* Demonstration of the approach's effectiveness in defending against various types of adversaries
* Introduction of interpretable metrics for evaluating defense performance, including clean hosts ratio, non-escalated hosts ratio, mean time to recover, useful recoveries, wasted recoveries, recovery precision, and red impact count.
