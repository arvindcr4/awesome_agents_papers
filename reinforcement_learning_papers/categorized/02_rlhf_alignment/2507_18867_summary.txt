Here is the extracted information:

**PAPER:** Learning Individual Intrinsic Reward in Multi-Agent Reinforcement Learning via Incorporating Generalized Human Expertise
**TITLE:** Learning Individual Intrinsic Reward in Multi-Agent Reinforcement Learning via Incorporating Generalized Human Expertise
**ARXIV_ID:** 2507.18867v1 [cs.LG]
**RESEARCH_METHOD:** 02_rlhf_alignment
**METHOD_DESCRIPTION:** This paper proposes a novel framework called LIGHT, which integrates human knowledge into multi-agent reinforcement learning (MARL) algorithms to improve learning efficiency, especially in sparse-reward tasks. LIGHT guides each agent to avoid unnecessary exploration by considering both individual action distribution and human expertise preference distribution. The method designs individual intrinsic rewards for each agent based on actionable representational transformation relevant to Q-learning, allowing agents to align their action preferences with human expertise while maximizing joint action value.
**KEY_CONTRIBUTIONS:**
* Proposes a novel framework called LIGHT that incorporates human knowledge into MARL algorithms.
* Introduces a method to design individual intrinsic rewards for each agent based on human expertise.
* Evaluates the performance of LIGHT on challenging benchmarks, including Level-Based Foraging (LBF) and StarCraft Multi-Agent Challenge (SMAC).
* Conducts ablation studies to demonstrate the effectiveness of individual intrinsic reward and human knowledge in improving learning efficiency.
* Shows that LIGHT outperforms representative baselines in terms of performance and aligns better with human knowledge preferences.
