Here is the extracted information:

**PAPER:** Graph Convolutional Value Decomposition in Multi-Agent Reinforcement Learning

**TITLE:** Graph Convolutional Value Decomposition in Multi-Agent Reinforcement Learning

**ARXIV_ID:** 2010.04740v2 [cs.LG]

**RESEARCH_METHOD:** 03_multi_agent_rl

**METHOD_DESCRIPTION:** The paper proposes a novel framework for value function factorization in multi-agent deep reinforcement learning (MARL) using graph neural networks (GNNs). The method, called GraphMIX, models the team of agents as a directed graph, where each node represents an agent, and the edge weights are governed by an attention mechanism. The mixing GNN module is responsible for factorizing the team state-action value function into individual per-agent observation-action value functions and explicit credit assignment to each agent.

**KEY_CONTRIBUTIONS:**

* The paper proposes a novel framework for value function factorization in MARL using GNNs.
* The method, GraphMIX, models the team of agents as a directed graph and uses an attention mechanism to govern the edge weights.
* The mixing GNN module is responsible for factorizing the team state-action value function and explicit credit assignment to each agent.
* The paper demonstrates the superiority of GraphMIX compared to state-of-the-art methods on several scenarios in the StarCraft II multi-agent challenge (SMAC) benchmark.
* The paper also shows that GraphMIX can be used in conjunction with a hierarchical MARL architecture to improve the agents' performance and enable fine-tuning on mismatched test scenarios.
