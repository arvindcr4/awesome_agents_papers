Here are the extracted information and answers to your questions:

**PAPER:** DAPO: An Open-Source LLM Reinforcement Learning System at Scale
**TITLE:** DAPO: An Open-Source LLM Reinforcement Learning System at Scale
**RESEARCH_METHOD:** 02_rlhf_alignment
**METHOD_DESCRIPTION:** The paper proposes a Decoupled Clip and Dynamic sAmpling Policy Optimization (DAPO) algorithm for large-scale LLM Reinforcement Learning (RL). The algorithm aims to address the challenges of RL training, such as entropy collapse, reward noise, and training instability. The authors introduce four key techniques: Clip-Higher, Dynamic Sampling, Token-Level Policy Gradient Loss, and Overlong Reward Shaping.
**KEY_CONTRIBUTIONS:**
* The authors propose a new algorithm, DAPO, for large-scale LLM RL.
* They introduce four key techniques to improve the performance of DAPO: Clip-Higher, Dynamic Sampling, Token-Level Policy Gradient Loss, and Overlong Reward Shaping.
* The authors open-source their training code, dataset, and algorithm, making it accessible to the broader research community.
* They demonstrate the effectiveness of DAPO on the AIME 2024 benchmark, achieving state-of-the-art performance with 50% accuracy.
