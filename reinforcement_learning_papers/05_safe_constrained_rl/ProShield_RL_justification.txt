Paper: ProShield_RL.pdf
Category: 05_safe_constrained_rl

Category Definition:
Optimizing rewards under safety constraints or risk minimization.

Abstract Snippet:
ProSh: Probabilistic Shielding for Model-free Reinforcement Learning Edwin Hamel-De le Court∗  Imperial College London, United Kingdom e.hamel-de-le-court@imperial.ac.uk  Gaspard Ohlmann∗  Mulhouse, France gaspard.ohlmann@outlook.com  arXiv:2510.15720v2 [cs.LG] 21 Oct 2025  ABSTRACT Safety is a major concern in reinforcement learning (RL): we aim at developing RL systems that not only perform optimally, but are also safe to deploy by providing formal guarantees about their safety. To this end, we introduce Probabilistic Shielding via Risk Augmentation (ProSh), a model-free algorithm for safe r...

Specific Evidence for Classification:
- "ProSh: Probabilistic Shielding for Model-free Reinforcement Learning Edwin Hamel-De le Court∗  Imperial College London, United Kingdom e.hamel-de-le-court@imperial.ac.uk  Gaspard Ohlmann∗  Mulhouse, France gaspard.ohlmann@outlook.com  arXiv:2510.15720v2 [cs.LG] 21 Oct 2025  ABSTRACT Safety is a major concern in reinforcement learning (RL): we aim at developing RL systems that not only perform optimally, but are also safe to deploy by providing formal guarantees about their safety."
- "To this end, we introduce Probabilistic Shielding via Risk Augmentation (ProSh), a model-free algorithm for safe reinforcement learning under cost constraints."

Conclusion:
This paper is classified as 05_safe_constrained_rl because it explicitly discusses concepts such as safety, constrained, cpo, matching the research direction's core themes.
