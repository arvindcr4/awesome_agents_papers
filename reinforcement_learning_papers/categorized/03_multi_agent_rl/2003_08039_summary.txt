PAPER: 2003_08039.pdf
TITLE: ROMA: Multi-Agent Reinforcement Learning with Emergent Roles
ARXIV_ID: 2003.08039v3 [cs.MA]
RESEARCH_METHOD: 03_multi_agent_rl
METHOD_DESCRIPTION: This paper proposes a novel multi-agent reinforcement learning framework called ROMA, which introduces the concept of emergent roles to improve the efficiency of multi-agent learning. ROMA conditions individual policies on stochastic latent variables, called roles, which are learned to be identifiable and specialized through two novel regularizers. The framework is trained end-to-end and can be applied to various multi-agent tasks.

KEY_CONTRIBUTIONS:
* Introduces the concept of emergent roles in multi-agent reinforcement learning to improve learning efficiency
* Proposes two novel regularizers to learn identifiable and specialized roles
* Develops a role-oriented multi-agent reinforcement learning framework (ROMA) that conditions individual policies on stochastic latent variables (roles)
* Demonstrates the effectiveness of ROMA on the StarCraft II micromanagement benchmark, outperforming state-of-the-art baselines
* Visualizes the emergence and evolution of roles during training, providing insights into the learning process
* Provides a new perspective on understanding and promoting cooperation within agent teams, drawing connections to the division of labor in natural systems.
