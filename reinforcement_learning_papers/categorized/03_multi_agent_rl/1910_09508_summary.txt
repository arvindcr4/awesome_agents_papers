Here is the extracted information:

PAPER: 1910_09508.pdf
TITLE: Multi-agent Hierarchical Reinforcement Learning with Dynamic Termination
ARXIV_ID: 1910.09508v1
RESEARCH_METHOD: 03_multi_agent_rl
METHOD_DESCRIPTION: This paper proposes a novel dynamic termination scheme for multi-agent hierarchical reinforcement learning, which allows agents to flexibly terminate their current options based on the state and others' options. The approach balances flexibility and predictability, combining the advantages of both. The authors evaluate their model empirically on a set of multi-agent pursuit and taxi tasks, demonstrating that their agents learn to adapt flexibly across scenarios that require different termination behaviors.

KEY_CONTRIBUTIONS:
* Proposed a novel dynamic termination scheme for multi-agent hierarchical reinforcement learning
* Introduced a delayed communication method for agents to approximate the joint Q-value
* Incorporated dynamic termination as an option to the high-level controller network, introducing little additional model complexity
* Evaluated the model empirically on multi-agent pursuit and taxi tasks, demonstrating improved performance and flexibility
* Compared the approach with existing state-of-the-art algorithms, showing that it outperforms them in various tasks and settings.
