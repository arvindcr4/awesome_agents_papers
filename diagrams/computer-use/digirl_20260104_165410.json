{
  "paper_id": "digirl",
  "paper_title": "DigiRL: Device Control",
  "timestamp": "20260104_165410",
  "result": {
    "requestId": "Z9Bb9EUiZQfNXIObx4fR",
    "imageUrl": "https://storage.googleapis.com/second-petal-295822.appspot.com/elements/autoDiagram%3Ae9fc2c1ec81f654b6016859c04eae972be618f07a8aea4b88a52965498d58d9c.png",
    "createEraserFileUrl": "https://app.eraser.io/new?requestId=Z9Bb9EUiZQfNXIObx4fR",
    "diagrams": [
      {
        "diagramType": "sequence-diagram",
        "code": "title Autonomous RL Training Workflow\nautoNumber nested\n\n// Actors and ordering\n\"RL Agent\"           [icon: user,      color: cyan]\nEnvironment          [icon: globe,     color: green]\n\"Reward Function\"    [icon: star,      color: magenta]\n\"Policy Network\"     [icon: cpu,       color: yellow]\n\"Experience Replay\"  [icon: database,  color: orange]\nOptimizer            [icon: settings]\nEvaluator            [icon: monitor,   color: purple]\n\n// Initialization\nRL Agent > Environment: Start new episode\nactivate RL Agent\nactivate Environment\n\nloop [label: each time-step] {\n  // Agent perceives environment\n  RL Agent > Environment: Observe state s_t\n  Environment --> RL Agent: Return s_t\n  \n  // Agent decides action\n  RL Agent > \"Policy Network\": Infer action a_t\n  \"Policy Network\" --> RL Agent: a_t\n  \n  // Agent acts and environment responds\n  RL Agent > Environment: Execute a_t\n  Environment --> RL Agent: s_{t+1}, r_t\n  \n  // Store experience\n  RL Agent > \"\"Experience Replay\": Append (s_t,a_t,r_t,s_\"{t+1})\n  \n  opt [label: buffer full, icon: archive] {\n    // Sample and learn\n    \"Experience Replay\" > Optimizer: Sample minibatch\n    Optimizer > \"Policy Network\": Backpropagate gradients\n    \"Policy Network\" --> Optimizer: Updated weights\n  }\n  \n  alt [label: performance check, icon: gauge] {\n    Evaluator --> RL Agent: perf \u2265 threshold?\n    break [label: goal reached] {\n      RL Agent > Evaluator: Log success\n    }\n  }\n}\n\n// Episode cleanup\ndeactivate Environment\ndeactivate RL Agent\n\npar [label: Concurrent Reporting & Persistence] {\n  // Reporting metrics\n  RL Agent > Evaluator: Send training metrics\n} and {\n  // Persist replay buffer\n  RL Agent > \"Experience Replay\": Save to disk\n}\n\n// Final evaluation\nEvaluator > \"Reward Function\": Validate reward signals\n\"Reward Function\" --> Evaluator: Consistency report\n\nEvaluator > RL Agent: Final performance summary"
      }
    ]
  }
}