{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• Fine-Tune LLMs with Fireworks AI\n",
    "\n",
    "This notebook guides you through fine-tuning a Large Language Model using Fireworks AI.\n",
    "\n",
    "**What you'll learn:**\n",
    "1. How to prepare a dataset for fine-tuning\n",
    "2. How to upload data to Fireworks\n",
    "3. How to start and monitor a fine-tuning job\n",
    "4. How to test your fine-tuned model\n",
    "\n",
    "**Prerequisites:**\n",
    "- A Fireworks AI account (free tier available at https://fireworks.ai)\n",
    "- An API key from Fireworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install fireworks-ai openai datasets pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from google.colab import userdata\n",
    "\n",
    "# Set your Fireworks API key\n",
    "# Option 1: Use Colab secrets (recommended)\n",
    "try:\n",
    "    FIREWORKS_API_KEY = userdata.get('FIREWORKS_API_KEY')\n",
    "except:\n",
    "    # Option 2: Enter manually\n",
    "    FIREWORKS_API_KEY = input(\"Enter your Fireworks API key: \")\n",
    "\n",
    "os.environ['FIREWORKS_API_KEY'] = FIREWORKS_API_KEY\n",
    "print(\"‚úÖ API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Preparation\n",
    "\n",
    "Fireworks expects data in **JSONL format** with conversation-style messages.\n",
    "\n",
    "### Format Options:\n",
    "\n",
    "**Chat format (recommended):**\n",
    "```json\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "```\n",
    "\n",
    "**Completion format:**\n",
    "```json\n",
    "{\"prompt\": \"...\", \"completion\": \"...\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a sample dataset for a customer support assistant\n",
    "# Replace this with your own data!\n",
    "\n",
    "sample_data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful customer support assistant for a software company.\"},\n",
    "            {\"role\": \"user\", \"content\": \"How do I reset my password?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"To reset your password:\\n1. Go to the login page\\n2. Click 'Forgot Password'\\n3. Enter your email address\\n4. Check your inbox for a reset link\\n5. Follow the link to create a new password\\n\\nThe link expires in 24 hours. Need any other help?\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful customer support assistant for a software company.\"},\n",
    "            {\"role\": \"user\", \"content\": \"My subscription expired, how do I renew?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I'd be happy to help you renew your subscription!\\n\\n1. Log into your account dashboard\\n2. Navigate to 'Billing & Subscription'\\n3. Click 'Renew' or 'Upgrade'\\n4. Select your preferred plan\\n5. Complete the payment\\n\\nYour access will be restored immediately after payment. Would you like me to walk you through any specific step?\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful customer support assistant for a software company.\"},\n",
    "            {\"role\": \"user\", \"content\": \"I'm getting an error when trying to upload files\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"I'm sorry to hear you're experiencing upload issues. Let me help troubleshoot:\\n\\n**Common causes:**\\n- File exceeds size limit (max 100MB)\\n- Unsupported file format\\n- Browser cache issues\\n\\n**Try these steps:**\\n1. Check if your file is under 100MB\\n2. Ensure it's a supported format (.pdf, .doc, .xlsx, .png, .jpg)\\n3. Clear browser cache and cookies\\n4. Try a different browser\\n\\nIf the issue persists, could you share the exact error message? That will help me identify the specific problem.\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìä Sample dataset with {len(sample_data)} examples\")\n",
    "print(\"\\nExample entry:\")\n",
    "print(json.dumps(sample_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create Your Own Dataset\n",
    "\n",
    "Here's where you define your training examples. The quality and diversity of your data directly impacts model performance.\n",
    "\n",
    "**Tips for good training data:**\n",
    "- Include 50-1000+ examples for best results\n",
    "- Cover diverse scenarios your model will encounter\n",
    "- Maintain consistent formatting in responses\n",
    "- Include edge cases and challenging examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TODO: Replace this with YOUR training data\n",
    "# ============================================================\n",
    "\n",
    "def create_training_example(system_prompt: str, user_input: str, assistant_response: str) -> dict:\n",
    "    \"\"\"\n",
    "    Helper function to create a single training example.\n",
    "    \n",
    "    Args:\n",
    "        system_prompt: The system instruction that sets the assistant's behavior\n",
    "        user_input: What the user says/asks\n",
    "        assistant_response: The ideal response you want the model to learn\n",
    "    \n",
    "    Returns:\n",
    "        A properly formatted training example dict\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_response}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Your system prompt - describes the assistant's persona/behavior\n",
    "SYSTEM_PROMPT = \"You are a helpful customer support assistant for a software company.\"\n",
    "\n",
    "# Add your training examples here\n",
    "training_data = [\n",
    "    create_training_example(\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        user_input=\"How do I cancel my account?\",\n",
    "        assistant_response=\"I understand you'd like to cancel your account. Before proceeding, may I ask what's prompting this decision? I'd like to see if there's anything we can do to address your concerns.\\n\\nIf you'd still like to proceed:\\n1. Go to Account Settings\\n2. Select 'Subscription'\\n3. Click 'Cancel Subscription'\\n4. Complete the confirmation\\n\\nNote: You'll retain access until the end of your billing period.\"\n",
    "    ),\n",
    "    # Add more examples...\n",
    "]\n",
    "\n",
    "# Combine with sample data for this demo\n",
    "all_training_data = sample_data + training_data\n",
    "print(f\"üìä Total training examples: {len(all_training_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Load from CSV or existing data source\n",
    "\n",
    "def load_from_csv(csv_path: str, system_prompt: str) -> list:\n",
    "    \"\"\"\n",
    "    Load training data from a CSV file.\n",
    "    \n",
    "    Expected CSV columns: 'user_input', 'assistant_response'\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    data = []\n",
    "    for _, row in df.iterrows():\n",
    "        data.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": row['user_input']},\n",
    "                {\"role\": \"assistant\", \"content\": row['assistant_response']}\n",
    "            ]\n",
    "        })\n",
    "    return data\n",
    "\n",
    "# Uncomment to use:\n",
    "# training_data = load_from_csv('your_data.csv', SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training data to JSONL file\n",
    "\n",
    "TRAIN_FILE = 'training_data.jsonl'\n",
    "\n",
    "with open(TRAIN_FILE, 'w') as f:\n",
    "    for example in all_training_data:\n",
    "        f.write(json.dumps(example) + '\\n')\n",
    "\n",
    "print(f\"‚úÖ Saved {len(all_training_data)} examples to {TRAIN_FILE}\")\n",
    "\n",
    "# Verify the file\n",
    "!head -n 1 {TRAIN_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload Dataset to Fireworks\n",
    "\n",
    "Now we'll upload our training data to Fireworks AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def upload_dataset(file_path: str, dataset_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Upload a JSONL file to Fireworks as a dataset.\n",
    "    \n",
    "    Returns the dataset ID for use in fine-tuning.\n",
    "    \"\"\"\n",
    "    url = \"https://api.fireworks.ai/v1/datasets\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {FIREWORKS_API_KEY}\"\n",
    "    }\n",
    "    \n",
    "    with open(file_path, 'rb') as f:\n",
    "        files = {\n",
    "            'file': (file_path, f, 'application/jsonl')\n",
    "        }\n",
    "        data = {\n",
    "            'name': dataset_name\n",
    "        }\n",
    "        response = requests.post(url, headers=headers, files=files, data=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(f\"‚úÖ Dataset uploaded successfully!\")\n",
    "        print(f\"   Dataset ID: {result.get('id')}\")\n",
    "        return result.get('id')\n",
    "    else:\n",
    "        print(f\"‚ùå Upload failed: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "# Upload the dataset\n",
    "DATASET_NAME = \"customer-support-v1\"  # Change this to your preferred name\n",
    "dataset_id = upload_dataset(TRAIN_FILE, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start Fine-Tuning Job\n",
    "\n",
    "Now let's start the fine-tuning job. Fireworks supports several base models:\n",
    "\n",
    "| Model | Description | Best For |\n",
    "|-------|-------------|----------|\n",
    "| `llama-v3p1-8b-instruct` | Meta Llama 3.1 8B | General purpose, fast |\n",
    "| `llama-v3p1-70b-instruct` | Meta Llama 3.1 70B | Higher quality, slower |\n",
    "| `mistral-7b-instruct-v0p2` | Mistral 7B | Good balance |\n",
    "| `mixtral-8x7b-instruct` | Mixtral 8x7B MoE | Complex tasks |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fine_tuning_job(\n",
    "    dataset_id: str,\n",
    "    model_name: str,\n",
    "    base_model: str = \"accounts/fireworks/models/llama-v3p1-8b-instruct\",\n",
    "    epochs: int = 3,\n",
    "    learning_rate: float = 1e-5\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Create a fine-tuning job on Fireworks.\n",
    "    \n",
    "    Args:\n",
    "        dataset_id: ID of the uploaded dataset\n",
    "        model_name: Name for your fine-tuned model\n",
    "        base_model: The base model to fine-tune\n",
    "        epochs: Number of training epochs\n",
    "        learning_rate: Learning rate for training\n",
    "    \"\"\"\n",
    "    url = \"https://api.fireworks.ai/v1/fine-tuning/jobs\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {FIREWORKS_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": base_model,\n",
    "        \"dataset\": dataset_id,\n",
    "        \"output_model_name\": model_name,\n",
    "        \"hyperparameters\": {\n",
    "            \"n_epochs\": epochs,\n",
    "            \"learning_rate\": learning_rate\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(f\"‚úÖ Fine-tuning job created!\")\n",
    "        print(f\"   Job ID: {result.get('id')}\")\n",
    "        print(f\"   Status: {result.get('status')}\")\n",
    "        return result\n",
    "    else:\n",
    "        print(f\"‚ùå Job creation failed: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Configure your fine-tuning job\n",
    "# ============================================================\n",
    "\n",
    "# Your fine-tuned model's name\n",
    "MODEL_NAME = \"customer-support-llama\"  # Change this!\n",
    "\n",
    "# Base model selection\n",
    "BASE_MODEL = \"accounts/fireworks/models/llama-v3p1-8b-instruct\"\n",
    "\n",
    "# Training hyperparameters\n",
    "EPOCHS = 3  # More epochs = more training, but risk of overfitting\n",
    "LEARNING_RATE = 1e-5  # Lower = more stable, higher = faster learning\n",
    "\n",
    "# Start the job (only run when ready!)\n",
    "if dataset_id:\n",
    "    job = create_fine_tuning_job(\n",
    "        dataset_id=dataset_id,\n",
    "        model_name=MODEL_NAME,\n",
    "        base_model=BASE_MODEL,\n",
    "        epochs=EPOCHS,\n",
    "        learning_rate=LEARNING_RATE\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No dataset ID - please upload your dataset first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Monitor Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def check_job_status(job_id: str) -> dict:\n",
    "    \"\"\"Check the status of a fine-tuning job.\"\"\"\n",
    "    url = f\"https://api.fireworks.ai/v1/fine-tuning/jobs/{job_id}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {FIREWORKS_API_KEY}\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "def monitor_job(job_id: str, poll_interval: int = 60):\n",
    "    \"\"\"Monitor a fine-tuning job until completion.\"\"\"\n",
    "    print(f\"üìä Monitoring job {job_id}...\")\n",
    "    print(\"   (This may take several minutes to hours depending on dataset size)\\n\")\n",
    "    \n",
    "    while True:\n",
    "        status = check_job_status(job_id)\n",
    "        state = status.get('status', 'unknown')\n",
    "        \n",
    "        print(f\"   Status: {state}\")\n",
    "        \n",
    "        if state in ['succeeded', 'completed']:\n",
    "            print(\"\\n‚úÖ Fine-tuning completed successfully!\")\n",
    "            print(f\"   Model: {status.get('fine_tuned_model')}\")\n",
    "            return status\n",
    "        elif state in ['failed', 'cancelled']:\n",
    "            print(f\"\\n‚ùå Job {state}\")\n",
    "            print(f\"   Error: {status.get('error', 'Unknown error')}\")\n",
    "            return status\n",
    "        \n",
    "        time.sleep(poll_interval)\n",
    "\n",
    "# Monitor the job (uncomment when you have a job running)\n",
    "# job_status = monitor_job(job['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick status check (use this to check status without waiting)\n",
    "if 'job' in dir() and job:\n",
    "    status = check_job_status(job['id'])\n",
    "    print(f\"Job ID: {job['id']}\")\n",
    "    print(f\"Status: {status.get('status')}\")\n",
    "    print(f\"Model: {status.get('fine_tuned_model', 'Not ready yet')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Your Fine-Tuned Model\n",
    "\n",
    "Once training completes, test your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize Fireworks client (uses OpenAI-compatible API)\n",
    "client = OpenAI(\n",
    "    api_key=FIREWORKS_API_KEY,\n",
    "    base_url=\"https://api.fireworks.ai/inference/v1\"\n",
    ")\n",
    "\n",
    "def chat_with_model(model_id: str, user_message: str, system_prompt: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Send a message to your fine-tuned model.\n",
    "    \n",
    "    Args:\n",
    "        model_id: Your fine-tuned model ID\n",
    "        user_message: The user's input\n",
    "        system_prompt: Optional system prompt\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    \n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model_id,\n",
    "        messages=messages,\n",
    "        max_tokens=512,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Test your fine-tuned model\n",
    "# ============================================================\n",
    "\n",
    "# Replace with your actual fine-tuned model ID\n",
    "FINE_TUNED_MODEL = f\"accounts/your-account/models/{MODEL_NAME}\"\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"How do I export my data?\",\n",
    "    \"Why is the app running slowly?\",\n",
    "    \"Can I get a refund?\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing fine-tuned model\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nüë§ User: {query}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        response = chat_with_model(\n",
    "            model_id=FINE_TUNED_MODEL,\n",
    "            user_message=query,\n",
    "            system_prompt=SYSTEM_PROMPT\n",
    "        )\n",
    "        print(f\"ü§ñ Assistant: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare Base vs Fine-Tuned Model\n",
    "\n",
    "See the difference your fine-tuning made!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(query: str, system_prompt: str = None):\n",
    "    \"\"\"Compare responses from base and fine-tuned models.\"\"\"\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Base model response\n",
    "    print(\"\\nüìå BASE MODEL (Llama 3.1 8B):\")\n",
    "    print(\"-\" * 40)\n",
    "    try:\n",
    "        base_response = chat_with_model(\n",
    "            model_id=\"accounts/fireworks/models/llama-v3p1-8b-instruct\",\n",
    "            user_message=query,\n",
    "            system_prompt=system_prompt\n",
    "        )\n",
    "        print(base_response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Fine-tuned model response\n",
    "    print(f\"\\nüéØ FINE-TUNED MODEL ({MODEL_NAME}):\")\n",
    "    print(\"-\" * 40)\n",
    "    try:\n",
    "        ft_response = chat_with_model(\n",
    "            model_id=FINE_TUNED_MODEL,\n",
    "            user_message=query,\n",
    "            system_prompt=system_prompt\n",
    "        )\n",
    "        print(ft_response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Compare on a test query\n",
    "compare_models(\n",
    "    query=\"I can't log in to my account\",\n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Additional Resources\n",
    "\n",
    "- [Fireworks AI Documentation](https://docs.fireworks.ai/)\n",
    "- [Fine-Tuning Guide](https://docs.fireworks.ai/fine-tuning/fine-tuning-guide)\n",
    "- [Model Catalog](https://fireworks.ai/models)\n",
    "- [Pricing](https://fireworks.ai/pricing)\n",
    "\n",
    "## üí° Tips for Better Results\n",
    "\n",
    "1. **More data is better**: Aim for 100+ high-quality examples\n",
    "2. **Consistency matters**: Keep response style consistent across examples\n",
    "3. **Cover edge cases**: Include examples of tricky scenarios\n",
    "4. **Iterate**: Start small, test, then expand your dataset\n",
    "5. **Monitor metrics**: Track loss during training for signs of overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
