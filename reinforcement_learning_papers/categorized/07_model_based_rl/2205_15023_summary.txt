Here is the extracted information:

**Paper Information**

* Title: Scalable Multi-Agent Model-Based Reinforcement Learning
* Authors: Vladimir Egorov, Alexei Shpilman
* arXiv ID: 2205.15023v1
* Research Method: 07_model_based_rl

**Method Description**

The paper proposes a new method called MAMBA (Multi-Agent Model-Based Approach) that utilizes Model-Based Reinforcement Learning (MBRL) to leverage centralized training in cooperative environments. MAMBA uses a world model to sustain a world model for each agent during execution phase, and imaginary rollouts can be used for training, removing the necessity to interact with the environment.

**Key Contributions**

* MAMBA achieves good performance while reducing the number of interactions with the environment up to an order of magnitude compared to Model-Free state-of-the-art approaches in challenging domains of SMAC and Flatland.
* MAMBA uses discrete messages to facilitate decentralization and account for message channel bandwidth limitations.
* MAMBA can scale to a large number of agents and learn disentangled latent space for agents, allowing for decentralized decision-making.
* MAMBA uses a reward-agnostic communication protocol, which is more suited for language that describes current environment, as opposed to goal-oriented communication, which is more suited for describing agent's task.
