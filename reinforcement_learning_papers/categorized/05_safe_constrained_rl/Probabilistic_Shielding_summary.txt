Here is the extracted information:

**PAPER:** Probabilistic Shielding for Safe Reinforcement Learning
**TITLE:** Probabilistic Shielding for Safe Reinforcement Learning
**RESEARCH_METHOD:** 05_safe_constrained_rl
**METHOD_DESCRIPTION:** The paper proposes a new method for safe reinforcement learning, called probabilistic shielding, which provides strict formal guarantees for safety throughout the learning phase. The method is based on state-augmentation of the Markov Decision Process (MDP) and the design of a shield that restricts the actions available to the agent.
**KEY_CONTRIBUTIONS:**
* The paper proposes a new approach for safe reinforcement learning that provides strict formal guarantees for safety.
* The approach is based on state-augmentation of the MDP and the design of a shield that restricts the actions available to the agent.
* The paper shows that the approach is theoretically sound and offers strict safety guarantees.
* The paper provides experimental results that demonstrate the viability of the approach in practice.
* The approach can significantly outperform state-of-the-art safe reinforcement learning algorithms.
