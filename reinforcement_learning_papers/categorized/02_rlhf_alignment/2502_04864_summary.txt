Here is the extracted information:

**PAPER:** Temporal-Agent Reward Redistribution (TAR²) for Multi-Agent Reinforcement Learning

**TITLE:** Temporal-Agent Reward Redistribution for Multi-Agent Reinforcement Learning

**ARXIV_ID:** 2502.04864v2

**RESEARCH_METHOD:** 02_rlhf_alignment (Reinforcement Learning with Human Feedback Alignment)

**METHOD_DESCRIPTION:** TAR² is a method for joint agent-temporal credit assignment in multi-agent reinforcement learning. It decouples credit modeling from constraint satisfaction, using a neural network to learn unnormalized contribution scores and a separate deterministic normalization step to construct the final rewards. This approach guarantees return equivalence by construction, ensuring the optimal policy is preserved.

**KEY_CONTRIBUTIONS:**

* Introduces TAR², a method for joint agent-temporal credit assignment in multi-agent reinforcement learning
* Provides a theoretical guarantee that the optimal policy is preserved, using Potential-Based Reward Shaping (PBRS)
* Demonstrates the effectiveness of TAR² in challenging SMACLite and Google Research Football environments
* Shows that TAR² outperforms state-of-the-art baselines in terms of sample efficiency and final performance
* Provides an ablation study to confirm the importance of each component in the TAR² architecture
