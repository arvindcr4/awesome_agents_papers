Paper: CQL_Conservative_Q_Learning.pdf
Category: 10_offline_rl

Category Definition:
Learning from fixed datasets without environment interaction (Batch RL).

Abstract Snippet:
arXiv:2006.04779v3 [cs.LG] 19 Aug 2020  Conservative Q-Learning for Offline Reinforcement Learning  Aviral Kumar1 , Aurick Zhou1 , George Tucker2 , Sergey Levine1,2 1 UC Berkeley, 2 Google Research, Brain Team aviralk@berkeley.edu  Abstract Effectively leveraging large, previously collected datasets in reinforcement learning (RL) is a key challenge for large-scale real-world applications. Offline RL algorithms promise to learn effective policies from previously-collected, static datasets without further interaction. However, in practice, offline RL presents a major challenge, and standard off-...

Specific Evidence for Classification:
- "arXiv:2006.04779v3 [cs.LG] 19 Aug 2020  Conservative Q-Learning for Offline Reinforcement Learning  Aviral Kumar1 , Aurick Zhou1 , George Tucker2 , Sergey Levine1,2 1 UC Berkeley, 2 Google Research, Brain Team aviralk@berkeley.edu  Abstract Effectively leveraging large, previously collected datasets in reinforcement learning (RL) is a key challenge for large-scale real-world applications."
- "Offline RL algorithms promise to learn effective policies from previously-collected, static datasets without further interaction."

Conclusion:
This paper is classified as 10_offline_rl because it explicitly discusses concepts such as offline, batch, dataset, matching the research direction's core themes.
