Here is the extracted information:

**PAPER:** Decentralized Multi-Agent Reinforcement Learning with Global State Prediction
**TITLE:** Decentralized Multi-Agent Reinforcement Learning with Global State Prediction
**ARXIV_ID:** 2306.12926v2 [cs.RO]
**RESEARCH_METHOD:** 03_multi_agent_rl
**METHOD_DESCRIPTION:** This paper presents two approaches to addressing non-stationarity in multi-agent reinforcement learning (MARL) without using global information. The first approach is based on implicit communication, where robots communicate through push-and-pull interactions. The second approach involves Global State Prediction (GSP), where a neural network predicts the future state of the system by aggregating partial local observations.
**KEY_CONTRIBUTIONS:**
* Proposed two approaches to addressing non-stationarity in MARL: implicit communication and Global State Prediction (GSP)
* Developed a neural network architecture for GSP that predicts the future state of the system by aggregating partial local observations
* Evaluated the performance of the proposed approaches using four well-known reinforcement learning algorithms (DQN, DDQN, DDPG, and TD3) in a collective transport scenario
* Showed that GSP outperforms a prior method that used global knowledge and increases the success rate over implicit communication
* Provided an in-depth analysis of the mechanisms driving coordination in MARL systems using GSP.
