PAPER: RL_with_Rubric_Anchors.pdf
TITLE: Reinforcement Learning with Rubric Anchors
RESEARCH_METHOD: 02_rlhf_alignment
METHOD_DESCRIPTION: This paper proposes a novel approach to reinforcement learning (RL) that extends the RLVR paradigm to incorporate open-ended tasks and non-verifiable data. The authors introduce the concept of "rubric anchors" as a way to define structured, interpretable criteria for assessment, enabling the automatic scoring of tasks with inherently subjective or multidimensional outputs. The method involves constructing a large rubric reward system, comprising over 10,000 rubrics generated by humans, LLMs, or a hybrid human-LLM collaboration. The authors demonstrate the effectiveness of their approach through experiments on various open-ended benchmarks, achieving notable gains in performance while preserving general and reasoning abilities.
KEY_CONTRIBUTIONS:
- Introduction of rubric anchors as a way to extend RLVR to open-ended tasks and non-verifiable data
- Development of a large rubric reward system with over 10,000 rubrics
- Demonstration of the approach's effectiveness on various open-ended benchmarks, with gains in performance and preservation of general and reasoning abilities
- Exploration of the importance of rubric diversity, granularity, and quantity in achieving high performance and token efficiency
- Discussion of the potential for combining RLVR and rubric-based RL to create a more comprehensive and effective training framework
