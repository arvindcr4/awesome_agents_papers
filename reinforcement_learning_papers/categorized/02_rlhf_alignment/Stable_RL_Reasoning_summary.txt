Here are the extracted information:

**PAPER:** Stable Reinforcement Learning for Efficient Reasoning
**TITLE:** Stable Reinforcement Learning for Efficient Reasoning
**RESEARCH_METHOD:** 02_rlhf_alignment
**METHOD_DESCRIPTION:** The paper proposes a simple yet effective modification to GRPO, namely GRPO-λ, which dynamically adjusts the reward strategy by monitoring the correctness ratio among completions within each query-sampled group. This approach prevents the imbalanced emphasis on efficiency over accuracy and ensures a controlled transition between accuracy and efficiency priorities.
**KEY_CONTRIBUTIONS:**
* Proposes a novel approach to balance efficiency and accuracy in reinforcement learning for efficient reasoning
* Introduces GRPO-λ, a stabilized and efficient variant of GRPO that adaptively optimizes sequence length within an appropriate range without sacrificing accuracy
* Demonstrates the effectiveness of GRPO-λ in achieving a superior accuracy-efficiency trade-off and enhancing training stability for RL of efficient reasoning
* Provides insights into the importance of carefully controlling the CoT length reduction rate to prevent premature reduction of reasoning paths and impairment of accuracy.
