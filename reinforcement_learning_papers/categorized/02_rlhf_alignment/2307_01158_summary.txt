Here is the extracted information:

**PAPER:** Theory of Mind as Intrinsic Motivation for Multi-Agent Reinforcement Learning
**TITLE:** Theory of Mind as Intrinsic Motivation for Multi-Agent Reinforcement Learning
**ARXIV_ID:** 2307.01158v2
**RESEARCH_METHOD:** 02_rlhf_alignment
**METHOD_DESCRIPTION:** This paper proposes a method for grounding semantically meaningful, human-interpretable beliefs within policies modeled by deep networks, and uses theory of mind (ToM) reasoning over the beliefs of other agents as intrinsic motivation in multi-agent scenarios. The approach involves modeling beliefs via concept learning, and using second-order belief prediction as an intrinsic reward signal.
**KEY_CONTRIBUTIONS:**
* Develops an information-theoretic residual variant to the concept bottleneck learning paradigm based on mutual information minimization.
* Utilizes this approach to model semantically meaningful belief states within RL policies.
* Proposes the prediction task of second-order prediction of these beliefs (i.e. ToM reasoning) as intrinsic motivation.
* Demonstrates preliminary results that show improved performance in a mixed cooperative-competitive environment.
