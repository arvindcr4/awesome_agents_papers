Here is the extracted information:

**PAPER:** Fully Decentralized Cooperative Multi-Agent Reinforcement Learning is A Context Modeling Problem
**TITLE:** Fully Decentralized Cooperative Multi-Agent Reinforcement Learning is A Context Modeling Problem
**ARXIV_ID:** 2509.15519v1
**RESEARCH_METHOD:** 03_multi_agent_rl
**METHOD_DESCRIPTION:** This paper proposes a novel method named Dynamics-Aware Context (DAC) to address the challenges of fully decentralized cooperative multi-agent reinforcement learning. DAC formalizes the task, as locally perceived by each agent, as a Contextual Markov Decision Process (CMDP) and models the step-wise dynamics distribution using latent variables. The method learns a context-based value function for each agent and derives an optimistic marginal value to encourage the selection of cooperative actions.
**KEY_CONTRIBUTIONS:**
* Proposes a novel method, DAC, to address the challenges of fully decentralized cooperative multi-agent reinforcement learning.
* Formalizes the task, as locally perceived by each agent, as a Contextual Markov Decision Process (CMDP).
* Models the step-wise dynamics distribution using latent variables.
* Learns a context-based value function for each agent and derives an optimistic marginal value to encourage the selection of cooperative actions.
* Evaluates the method on various cooperative tasks, including the matrix game, predator and prey, and the StarCraft Multi-Agent Challenge (SMAC).
