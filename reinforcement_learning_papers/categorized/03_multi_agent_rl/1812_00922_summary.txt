Here is the extracted information:

**PAPER:** Multi-agent Deep Reinforcement Learning with Extremely Noisy Observations
**TITLE:** Multi-agent Deep Reinforcement Learning with Extremely Noisy Observations
**ARXIV_ID:** 1812.00922v1
**RESEARCH_METHOD:** 03_multi_agent_rl
**METHOD_DESCRIPTION:** The authors propose a multi-agent deep deterministic policy gradient algorithm enhanced by a communication medium (MADDPG-M) to address the challenges of multi-agent reinforcement learning with extremely noisy observations. The algorithm enables concurrent learning of an optimal communication policy and the underlying task.
**KEY_CONTRIBUTIONS:**
* The authors introduce a hierarchical arrangement of communication policies and local agent policies that act on the environment, which must be learned concurrently.
* They propose a two-level, concurrent learning mechanism, where an agent's policy depends on its own private observations as well as those explicitly shared by others through a communication medium.
* The authors demonstrate the effectiveness of MADDPG-M in six highly non-stationary environments of progressively higher complexity, and show that it offers substantial performance gains compared to existing baselines.
